1	sgiwy	1	There are k lists of sorted integers. Make a min heap of size k containing 1 element from each list. Keep track of min and max element and calculate the range. In min heap, minimum element is at top. Delete the minimum element and another element instead of that from the same list to which minimum element belong. Repeat the process till any one of the k list gets empty. Keep track of minimum range.  For eg. List 1: [4, 10, 15, 24, 26] List 2: [0, 9, 12, 20] List 3: [5, 18, 22, 30]  Min heap of size 3. containing 1 element of each list Heap [0, 4, 5] Range - 6  Remove 0 and add 9 Heap [4, 9, 5] Range - 6  Remove 4 and add 10 Heap [5, 9, 10] Range - 6  and so on....  Finally you will yield the result.	2014-12-10 08:23:23		
2	mrjku	1	nice solution	2014-12-10 08:23:23		
3	mrjku	1	since the input lists are already sorted, we should take advantage of it rather than creating a new minHeap.	2014-12-10 08:23:23		
4	dkebi	1	can you please tell me how you are keep an account of minimum range in this. How you are going to find out which range is minimum because you going forward without keeping the record of range. for instance: If you are taking an array for tracking the records then each time you have to find the smallest element of the array and you have to compare it with current result and so on .... till you are getting minimum. I m taking array here only for explanation, for that you can use a heap also. but any how you have to provide extra code to keep track for ranges to find minimum range and the proper possession of each and ever combination with range, for that you require another data structure.	2014-12-10 08:23:23		
5	azmjc	1	When you are creating the heap for the first time, make a separate variable that keeps track of max number in the heap. Everytime you add a new element into the heap, check the new element against this variable. That way you can get the max-min range	2014-12-10 08:23:23		
6	wbqzu	1	Nice solution only one thing is missing which is how to make use of sorted nature of lists as rightly pointed by @Vinod K	2014-12-10 08:23:23		
7	rrmeu	1	nice idea!!!I have implemented it quickly. @Vinod K @aka, What do you mean "how to make use of sorted nature of lists" ?	2014-12-10 08:23:23		
8	cfzie	1		2014-12-10 08:23:23		
9	fowai	1		2014-12-10 08:23:23		
10	vanul	1	How can we prove the correctness of this algorithm? What if we remove the element from the heap which has next minimum value, instead of removing the minumum value itself? Which one would be correct? Both, or none?	2014-12-10 08:23:23		
11	dkebi	1	That a good idea. I also wrote the code. It will be better to use vectors instead of array in real applications.	2014-12-10 08:23:23		
12	rrmeu	1		2014-12-10 08:23:23		
13	mrjku	1		2014-12-10 08:23:23		
14	dgjji	1	It does use the sorted feature of K lists. If you try to prove the correctness of this algorithm, it does depend on the properties that "each element in the list is in increasing order"	2014-12-10 08:23:23		
15	dkebi	1	what is the time complexity of this algorithm?	2014-12-10 08:23:23		
16	nwkeg	1	This is based on a problem in CLRS. Read heap chapter, there is a problem that talks about how to sort k sorted lists. This problem is just extension of that.  Here java code,	2014-12-10 08:23:23		
17	qywrh	1		2014-12-10 08:23:23		
18	ufdxg	1		2014-12-10 08:23:23		
19	eucmc	1	This is how I reason about this solution.  Think of drawing points from k lists on a X axis line. We first consider the minimum point from all lists. Lets assume it is from list A. For any range involved this point, the minimum range is the range involving the other k-1 points, each of which is the minimum of the other k-1 different lists. Let use R to indicate this range. So the minimum range involving all k lists is among R and the minimum range involving the k-1 lists and list A with the minimum removed. Repeat this process until one of k lists is empty.	2014-12-10 08:23:23		
20	gilit	1	aasshishh's solution in Python:  def minRange(lll): import heapq heap = [] num_elts = 0 for k in range(0,len(lll)): li = lll[k] if len(li)==0: print 'none of the lists can be empty' return 0 num_elts += len(li) heapq.heappush(heap,(li[0],k)) oldrangemin = min(heap)[0] oldrangemax = max(heap)[0] oldheaprange = oldrangemax - oldrangemin for i in range(0,num_elts): heap_min_elt = heapq.heappop(heap) k = heap_min_elt[1] heap_new_elt = lll[k].pop(0) heapq.heappush(heap, (heap_new_elt,k)) rangemin = min(heap)[0] rangemax = max(heap)[0] newheaprange = rangemax - rangemin if newheaprange < oldheaprange: oldheaprange = newheaprange oldrangemin = rangemin oldrangemax = rangemax if len(lll[k])==0: break return [oldrangemin, oldrangemax]  >>>my_list_of_lists = [[2,50,60],[10,20,40],[2,3,100],[4,5,6]] >>>minRange(my_list_of_lists) >>>[2, 10]	2014-12-10 08:23:23		
21	plapd	1	This is the same as: merge all the N lists into one long array, then keep a sliding window of N.	2014-12-10 08:23:23		
22	eucmc	1	Here's my Python version of that. heapq.merge should be better than heappush, taking advantage of the already sorted lists.	2014-12-10 08:23:23		
23	rdfeo	1		2014-12-10 08:23:23		
24	ewigy	1		2014-12-10 08:23:23		
25	dkebi	1	What if the min or max appears multiple time. Say k = 6 current heap is 2 2 2 6 6 6 And a new element say 3 is replacing 2 in 1st list. Getting min is not an issue as its a minheap an still we will get 2 as a minm.  What if i replace last 6 with 5 ? I feel that somewhere we need to maintain the counts of elements in the heap.	2014-12-10 08:23:23		
26	azmjc	1	This can be solved easily as below. 1. initialize smallest_range as MAX_INT 2. keep 3 pointers/index p1, p2 and p3 which points to the first elements of lists L1, L2 and L3 respectively. 3. find the max value and min value pointed/indexed by p1, p2 and p3 4. difference of max value and min value discovered in step 3 is the current range. compare it with smallest_range and update it, if found smaller. 5. increment the pointer/index of min value found in step 3. 6. repeat step 3 to 5 until the pointer/index of min value is in range.  constant space and O(n) time.	2014-12-10 08:23:23		
27	vanul	1	Correct.... no doubt sol is fantastic..... I like the way of presenting your sol.... great job...	2014-12-10 08:23:23		
28	vanul	1		2014-12-10 08:23:23		
29	bjsiw	1		2014-12-10 08:23:23		
30	gilit	1	It is actually O(N*k) time with O(1) space.  Step 3: find the max value and min value pointed/indexed by p1, p2 and p3, will have O(k) time execution every time.  It is a nice solution!	2014-12-10 08:23:23		
31	wbqzu	1	@xint - time will be O(n) only.  I had taken an example of 3 lists above. we can generalize it.  Instead of 3 pointers, take an array of K pointers which initially points to the first elements of K lists. Now find the minValue and maxValue among this K pointers. Find the range and update smallest_range, if needed. Increment the pointer points to minValue and compare the value now pointed with minValue and maxValue and update it, if needed. so this will take only constant time.(no need to find the minValue and maxValue among K pointers each time since we are already tracking min and max among the K pointers ) repeat till end of list  time - O(n), space - O(k)	2014-12-10 08:23:23		
32	jippy	1	your code stop when one list reach the end, right? But in some case, the optimal solution need to look through all elements in every list. Let me know if I am wrong.	2014-12-10 08:23:23		
33	cfzie	1	I mean yogi.rulzz's code	2014-12-10 08:23:23		
34	admin	1	Oh, I think I know the problem. Once one of the list reach the end, other list's elems will always greater than current ones. Hence the min_range will not be affected. Sorry for the misunderstanding.	2014-12-10 08:23:23		
35	rrmeu	1	plz read the question again, it asks k lists. solution becomes O(nk)	2014-12-10 08:23:23		
36	dkebi	1	List 1: [1, 2, 3, 80] List 2: [1, 2, 3, 90, 200] List 2: [1, 2, 3, 99, 300] I think your approach doesn't work for this.	2014-12-10 08:23:23		
37	admin	1	First, combine all lists into one big list, for each item keeping track of the list it's from and the value of the item. You get a data structure that (conceptually) looks like this:	2014-12-10 08:23:23		
38	plapd	1		2014-12-10 08:23:23		
39	zeice	1		2014-12-10 08:23:23		
40	jippy	1	Now you start going through this new list item by item until you have the first item from each list (in this case 0,4,5), and you calculate the range (5). Now you move through the list one element at a time. Each time you find an element from a given list, you select that element (so you have three indices, and you always move the one to whose list the current element belongs to that element). So the first step is to replace the 4 by the 9, yielding (0,9,5) with a range of 9. If the range is smaller than the minimum range, remember it, else ignore it, so ignore the (0,9,5) range. The next couple of ranges: (10, 9, 5), (10,12,5), (15, 12, 5), (15, 12, 18), (15, 20, 18), (18,20,24), (18,20,26), (26, 20, 30).  Since you visit every element in every list once, complexity is O(N) where N is the number of elements in the lists all added up.	2014-12-10 08:23:23		
41	admin	1	I also thought of that method which looks correct, but the complexity looks O(N log k). When combining I think you have to decide form which list you are going to pick the next element(like k-way merging). So for each of N element it takes O(log k).	2014-12-10 08:23:23		
42	fowai	1	good solution. the issue is with the extra space. for keeping the actual index we need extra space. And if the input lists cannot be altered, then we weed an additional list to merge all 3 lists.	2014-12-10 08:23:23		
43	gilit	1	This algorithm doesn't work. Suppose the 5 were an 8 instead. Then the first valid range you get is (0,4,8), with a size of 8. Then you see the 9, consider (0,9,8), and ignore it because it has size 9. Next you see the 10 and consider (10,4,8), which you accept because it has size 6.  The algorithm has missed the better solution of (8,9,10).	2014-12-10 08:23:23		
44	krxlv	1	You don't ignore (0,9,8) but just do not update your current best solution (0,4,8). So when you see 10 you'll be considering (10,9,8).	2014-12-10 08:23:23		
45	huiqq	1	It is O(k) space and O(N*k) time solution. N : total no. of elements from all the the lists.	2014-12-10 08:23:23		
46	azmjc	1	since list are already ordered, you can in generate the sorted list of all of them fast, and keep an additional array with the original list they belonged to:  In the example	2014-12-10 08:23:23		
47	ethan	1		2014-12-10 08:23:23		
48	nwkeg	1		2014-12-10 08:23:23		
49	sqzqo	1	Once you have that, you just have to find the subsequence in the right column which contains K different symbols (at least length K). If there is more than one sequence of length K, just take the one with the minimum range in the right column  I've implemented the sorting in a customized python iterator	2014-12-10 08:23:23		
50	dkebi	1		2014-12-10 08:23:23		
51	sgiwy	1		2014-12-10 08:23:23		
52	gilit	1	It could be optimized for the case of disjoint intervals defined by the groups, where the sequence would be [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1] by not enlarging the list when adding 3+ items from the same original list.	2014-12-10 08:23:23		
53	krxlv	1	Keep three pointers to the beginning of each of the lists and advance the pointer on the list that has the next smallest value until you reach the end of one of the lists that has the lowest number out of the three. Store the smallest range along the way. So the iterations become (the current index of the pointer is shown in parentheses)	2014-12-10 08:23:23		
54	qywrh	1		2014-12-10 08:23:23		
55	rrmeu	1		2014-12-10 08:23:24		
56	gilit	1		2014-12-10 08:23:24		
57	sgiwy	1		2014-12-10 08:23:24		
58	bexbp	1		2014-12-10 08:23:24		
59	fowai	1		2014-12-10 08:23:24		
60	krxlv	1		2014-12-10 08:23:24		
61	sqzqo	1		2014-12-10 08:23:24		
62	fmzze	1		2014-12-10 08:23:24		
63	krxlv	1		2014-12-10 08:23:24		
64	nwkeg	1		2014-12-10 08:23:24		
65	ufdxg	1		2014-12-10 08:23:24		
66	ewigy	1		2014-12-10 08:23:24		
67	nwkeg	1		2014-12-10 08:23:24		
68	ethan	1		2014-12-10 08:23:24		
69	dgjji	1		2014-12-10 08:23:24		
70	sqzqo	1		2014-12-10 08:23:24		
71	huiqq	1		2014-12-10 08:23:24		
72	sgiwy	1	You can stop at this point since the lowest number in the range belongs to the list that has no more elements, which means you can't improve upon this.	2014-12-10 08:23:24		
73	xhgls	1	Instead of starting it from first element, we can start that same process with the median elements of all arrays. It will optimize the solution further.  BTW, its a simple and great approach!	2014-12-10 08:23:24		
74	azmjc	1	How can we prove the correctness of this algorithm? It is somewhat similar to the one with highest votes, except that it removes the element from the set which has next minimum value, whereas the other answer removes the element which itself is minumum.  So which one is correct? How to prove it?	2014-12-10 08:23:24		
75	sqzqo	1	We do not need to start from the beginning, as suggested here. Instead, start at tails. The smallest of the tails is the lower bound of the range guaranteed. The issue is to find the upper bound. Of course the upper bound cannot be more than the max of all tails.  So start with the max of tails as upper bound. To best this estimation, compare the next smaller number than this tail (in the same list as the max of tails, of course). If this number is greater than lower bound (which is fixed), then continue looking. Stop when your number is smaller than lower bound.  This way, you don't need search all the K lists. Here is the pseudo code:	2014-12-10 08:23:24		
76	wbqzu	1		2014-12-10 08:23:24		
77	ewigy	1		2014-12-10 08:23:24		
78	plapd	1	1 4 7 100 200 300 500 2 5 8 125 225 325 525 3 6 9 150 250 350 550  All of u guys, both who r starting from the begining of the list and those who r starting frm the end of the list jst check ur algo. for the above example and comment the correctness of ur algo...!!!	2014-12-10 08:23:24		
79	fowai	1	1.Do a k-way merge. Use k pointers to point to the start of each list. 2.Find the min and max elements among these k elements and find the difference as range (min and max are elements of range). If range is less than previous range, update it 3.Move to the next index in the list having the minimum value. Go to step 2	2014-12-10 08:23:24		
80	ewigy	1		2014-12-10 08:23:24		
81	plapd	1		2014-12-10 08:23:24		
82	bjsiw	1	As it is, this runs in O(n.k) where n is the total number of elements in all lists and k is the number of lists. To make it run in O(n.log k), use a heap to keep M sorted for min value.	2014-12-10 08:23:24		
83	ftfck	1		2014-12-10 08:23:24		
84	bexbp	1		2014-12-10 08:23:24		
85	eucmc	1	The merging and coloring solution is the general correct approach. Here's my implementation in Java, it takes O(n*log(k)) i believe, where n is the total number of elements in all k lists.	2014-12-10 08:23:24		
86	rdfeo	1		2014-12-10 08:23:24		
87	fowai	1		2014-12-10 08:23:24		
88	eucmc	1	This problem can be solved in O(nlogk)	2014-12-10 08:23:24		
89	dgjji	1		2014-12-10 08:23:24		
90	cfzie	1		2014-12-10 08:23:24		
91	wbqzu	1	Working solution	2014-12-10 08:23:24		
92	admin	1		2014-12-10 08:23:24		
93	huiqq	1		2014-12-10 08:23:24		
94	vanul	1		2014-12-10 08:23:24		
95	admin	1		2014-12-10 08:23:24		
96	zeice	1		2014-12-10 08:23:24		
97	ethan	1		2014-12-10 08:23:24		
98	rrmeu	1		2014-12-10 08:23:24		
99	mrjku	1		2014-12-10 08:23:24		
100	dkebi	1	Python code	2014-12-10 08:23:24		
101	wbqzu	1		2014-12-10 08:23:24		
102	zeice	1		2014-12-10 08:23:24		
103	bjsiw	1	output : [20, 24]	2014-12-10 08:23:24		
104	xhgls	1	Here is my solution written in C#	2014-12-10 08:23:24		
105	dkebi	1		2014-12-10 08:23:24		
106	tenuw	1		2014-12-10 08:23:24		
107	krxlv	1		2014-12-10 08:23:24		
108	wbqzu	1		2014-12-10 08:23:24		
109	admin	1	My idea is that the range's lower bound is the minimum of the largest element in the k lists, so it is range_lower_bound = min( 26, 20, 30 ) in the example. Then we try to find a set(call it smallest_larger_than_lower_bound_set, ={ 24, 22 } in the example ) of elements, who is the smallest element that is larger than the range_lower_bound in every array, if we find that the array contains range_lower_bound, we emit the array because it means the range will contain at least one element of the array(the range_lower_bound, actually), then range_upper_bound = max( smallest_larger_than_lower_bound_set ). The proof is simple, if lower bound v > range_lower_bound, then array that contains the range_lower_bound as largest element will not have a element in the range, so range_lower_bound is the optimal lower bound; if the upper bound v < range_upper_bound, and obviously v >= range_lower_bound, and the array contains the range_upper_bound will not have a element in the range, because the there're only two kinds of element in the array: elements < range_lower_bound and elements >= range_upper_bound > v, so no elements in the array will occurs in the range. And here is my code in C++, the time complexity is O(kn), where k is the number of lists, and n is the number of elements in the list:	2014-12-10 08:23:24		
110	nwkeg	1		2014-12-10 08:23:24		
111	vanul	1		2014-12-10 08:23:24		
112	eucmc	1	Just simple O(N) space and O(N) time can work. 1. Merge these array into one in O(N) time, 2. Initial two pointer L,R to cover first K minimum numbers. 4. Calculate the "Range". 3. Delete pointer L's number which belong to X array(we suppose), move R to right until meet a number also belong to X array. 5. repeat 3-4 until R beyond range  It's the idea of "window move". And it's O(N) time.	2014-12-10 08:23:24		
113	zeice	1		2014-12-10 08:23:24		
114	krxlv	1		2014-12-10 08:23:24		
115	rrmeu	1		2014-12-10 08:23:24		
116	fowai	1		2014-12-10 08:23:24		
117	zeice	1	Im not sure this is bugfree.... L(i) is the shorted list, then for each element in L(i), find the nearest element in other list, memory this range, then loop for other element in L(i). then according to the memory, find the shortest range	2014-12-10 08:23:24		
118	fowai	1	My solution: 1) Find the list with the least number of elements. Let's call that list K. 2) Loop through all elements of list K 3) For each element of K[i], find the closest range that can include K[i], using numbers from other lists. 4) Compare all the ranges we found in step 3: best range for K[0], best range for K[1],... . Pick the best range out of them all.  Example List 1: [4, 10, 15, 24, 26] List 2: [0, 9, 12, 20] List 3: [5, 18, 22, 30]  1) List 2 and List 3 both have same number of elems. We can pick List as the seed List. 2) Loop through all elements of List 2 3) For '0': best range that can represent '0' is [0,5] For '9': best range that can represent '9' is [5,10] For '12': best range that can represent '12' is [12,18] For '20': best range that can represent '20' is [20,24]  Out of those 4 ranges, [20,24] is the best	2014-12-10 08:23:24		
119	eucmc	1	JavaScript Solution:	2014-12-10 08:23:24		
120	nhibd	1		2014-12-10 08:23:24		
121	nwkeg	1		2014-12-10 08:23:24		
122	eucmc	1	For each integer in any list between the biggest small number and the largest number find the nearest number in each list and compute the range. You might of course find multiple solutions.	2014-12-10 08:23:24		
123	azmjc	1	Another js solution, does bruteforce, not optimal but works.	2014-12-10 08:23:24		
124	zeice	1		2014-12-10 08:23:24		
125	rdfeo	1		2014-12-10 08:23:24		
126	sqzqo	1	My solution: 1. Create an Item object for every value containing a min value, max value, and referenced lists 2. For every Item object, compare every list. - If the list is already referenced, return - If the value within the range of min & max, add this list as reference and return - If the value is greater than a temporary max for this item, update temporary max and continue - Update maxValue for item and reference this list, continue 3. For every item, call GetRange() and compare with temporary range, if its smaller, make it new temp  Here's my code in c#:	2014-12-10 08:23:24		
127	zeice	1		2014-12-10 08:23:24		
128	ufdxg	1		2014-12-10 08:23:24		
129	ftfck	1	My solution in C++, based on aasshishh idea. I use C++ STL priority_queue to maintain the smallest element.	2014-12-10 08:23:24		
130	ewigy	1		2014-12-10 08:23:24		
131	krxlv	1		2014-12-10 08:23:24		
132	cfzie	1	assume 3 lists of elements list1:(4,10,16,24,32} list2:{7,8,12,23,51} list3:{20,22,25,41,43}  -choose the max element of each list -max_element={32,51,43} -take the smallest value of max_element and use it as starting range, START=32. -so, eliminate list1 since we have one value from the list as a starting range. -Next, scan through list 1 and list 3 to find the smallest value which is bigger than START. -Example, list 2 is 51, list 3 is 41. so smalVal={51,41} -get the largest Value from smalVal as ending range, END=51  so, the answer will be 32-51.	2014-12-10 08:23:24		
133	nwkeg	1	"-Next, scan through list 1 and list 3 to find the smallest value which is bigger than START."  sorry, its suppose to scan list 2 and list3, not list1.	2014-12-10 08:23:24		
134	ufdxg	1	assume 3 lists of elements list1:(4,10,16,24,32} list2:{7,8,12,23,51} list3:{20,22,25,41,43}  -choose the max element of each list -max_element={32,51,43} -take the smallest value of max_element and use it as starting range, START=32. -so, eliminate list1 since we have one value from the list as a starting range. -Next, scan through list 2 and list 3 to find the smallest value which is bigger than START. -Example, list 2 is 51, list 3 is 41. so smalVal={51,41} -get the largest Value from smalVal as ending range, END=51	2014-12-10 08:23:24		
135	fmzze	1		2014-12-10 08:23:24		
136	nwkeg	1		2014-12-10 08:23:24		
137	nwkeg	1		2014-12-10 08:23:24		
138	jippy	1		2014-12-10 08:23:24		
139	bexbp	1		2014-12-10 08:23:24		
140	rdfeo	1		2014-12-10 08:23:24		
141	dgjji	1	// Worst case complexity O(mno) // But average case is much less	2014-12-10 08:23:25		
142	bexbp	1		2014-12-10 08:23:25		
143	zeice	1		2014-12-10 08:23:25		
144	fmzze	1	1)Find the minimum of all list's last index List 1: [4, 10, 15, 24, 26] List 2: [0, 9, 12, 20] List 3: [5, 18, 22, 30] which is 20 from List 2, take it as lower range. 2)Binary search in List 1 and List 3, and find its immediate greater value, which is 24 in List 1, and 22 in List 3. 3)Take the maximum of these two values as upper range(Which is 24). 4)Hence [20-24] is the required range.	2014-12-10 08:23:25		
145	bjsiw	1	I've not gone through all the solutions here but, but the ones I have gone through seem to be doing unnecessary things. Here's my solution, feel free to point out the error:  Find the minimum element from the list of last elements in each list. [20,26,30] minimum is 20. You can bet that 20 is the start of that smallest range (Range that we seek).  Now just find out the next element in the all other lists that are bigger than 20. Candidates are [22, 24] Maximum of this [22, 24] is the end of the smallest range.  so answer becomes [22, 24].  This is how you make use of the fact that lists are sorted already	2014-12-10 08:23:25		
146	sqzqo	1	Thank you! I was going crazy as to why this solution wasn't listed here. Running time is O(log n) I guess, where n is the size of the largest list.	2014-12-10 08:23:25		
147	azmjc	1	What happens if the lists are these? List 1: [1, 10, 15, 24, 26] List 2: [0, 9, 12, 18] List 3: [2, 18, 22, 30]  The smallest range should be [0, 2], while your algorithm would return [18, 24] right?	2014-12-10 08:23:25		
148	mrjku	1	We do not need to start from the beginning, as suggested here. Instead, start at tails. The smallest of the tails is the lower bound of the range guaranteed. The issue is to find the upper bound. Of course the upper bound cannot be more than the max of all tails.  So start with the max of tails as upper bound. To best this estimation, compare the next smaller number than this tail (in the same list as the max of tails, of course). If this number is greater than lower bound (which is fixed), then continue looking. Stop when your number is smaller than lower bound.  This way, you don't need search all the K lists. Here is the pseudo code:	2014-12-10 08:23:25		
149	rrmeu	1		2014-12-10 08:23:25		
150	nwkeg	1		2014-12-10 08:23:25		
151	ewigy	1	1)Find the minimum of all list's last index List 1: [4, 10, 15, 24, 26] List 2: [0, 9, 12, 20] List 3: [5, 18, 22, 30] which is 20 from List 2, take it as lower range. 2)Binary search in List 1 and List 3, and find its immediate greater value, which is 24 in List 1, and 22 in List 3. 3)Take the maximum of these two values as upper range(Which is 24). 4)Hence [20-24] is the required range. Kindly correct me, if i am wrong.	2014-12-10 08:23:25		
152	zeice	1	what if the lists are as following? List 1: [1, 2, 3, 80] List 2: [1, 2, 3, 90, 200] List 2: [1, 2, 3, 99, 300]  In that case, your algorithm chooses [80, 99]. the range is 99-80 = 19. However the answer is [1, 2] where range is 1 ; i.e. 2-1.  that is why your algorithm won't work.	2014-12-10 08:23:25		
153	xhgls	2	This is a recursive version, alternatively it can be done using DP.	2014-12-10 08:23:27		
154	ftfck	2		2014-12-10 08:23:27		
155	wbqzu	2		2014-12-10 08:23:27		
156	ftfck	2	yeah, dp classical problem. in O(n^2)	2014-12-10 08:23:27		
157	bexbp	2	Check the recurrence within the solution. Formulate it within a 2-D DP structure.	2014-12-10 08:23:27		
158	eucmc	2	Can you explain the logic ?	2014-12-10 08:23:27		
159	plapd	2	For player A : he can pick up coin in first place or last place, for each of these case player B can further pick from first or last place from remaining coins. But for A to win/maximize coins, coins collected by B should be minimum while that of A should be maximized.  If A selects coin[i], then B can choose coin[i+1] or coin[array_size]  If A selects coin[array_last], then B can choose coin[i] or coin[array_last-1]  We will simulate such that every function call will start from A's turn. This will give us the given recursive function.	2014-12-10 08:23:27		
160	bjsiw	2	Add DP to it by using map (or you can use 2-D array too)	2014-12-10 08:23:27		
161	rdfeo	2		2014-12-10 08:23:27		
162	bexbp	2		2014-12-10 08:23:27		
163	xhgls	2	this solution does not scale. what happens if n is too large? recursion is practically impossible.  this problem is similar to the problem of finding 'perfect' chess strategy. Only that it is a reduced version. At each turn you only have to consider 2 choices, where as in chess it is many.  when n is large, the best you can do is some kind of 'look-ahead' algorithm to make sure by kth move you are not in a worse off position.	2014-12-10 08:23:27		
164	plapd	2	i take back my comment. Just read Mihail's solution below and it is ingenious. This game does have a best strategy!  When n is even, it is true who ever moves first can choose the odd-pot series or the even-pot series, so whoever moves first wins.  When n is odd, whoever first is guaranteed to lose unless the first pot can be big enough to offset the difference between odd-pot series and even-pot series!	2014-12-10 08:23:27		
165	mrjku	2	Quick question: most (if not all) of the answers above follow this guideline: "for each move I make, calculate the minimum possible profit of the opponent, and select the move that yields the greatest profit", i.e.:	2014-12-10 08:23:27		
166	jippy	2		2014-12-10 08:23:27		
167	cfzie	2		2014-12-10 08:23:27		
168	cfzie	2	But shouldn't it be the other way around? "for each possible move I make, calculate the *maximum* possible profit of the opponent, and choose the move that yields minimum losses"? i.e.:	2014-12-10 08:23:27		
169	krxlv	2		2014-12-10 08:23:27		
170	eucmc	2		2014-12-10 08:23:27		
171	krxlv	2	??	2014-12-10 08:23:27		
172	eucmc	2	the thing is, you calculate the max profit of the opponent. suppose you take it from the front, your opponent can choose from F(a+2, b), F(a+1, b-1) , and since the opponent plays optimally, he/she would choose max(F(a+2, b), F(a+1, b-1)), which left you min(F(a+2, b), F(a+1, b-1));  same logic, if you choose from the end, your opponent can choose from F(a, b-2), F(a+1,b-1), and he/she would choose max(F(a, b-2), F(a+1,b-1)), which left you min(F(a, b-2), F(a+1,b-1))  so you actually need the max left-over so you max whatever your opponent left to you, which is the first formula above.	2014-12-10 08:23:27		
173	fowai	2	F(i, j) = Max { pot[i] + Min { F(i+2, j), F(i+1, j-1) }, pot[j] + Min { F(i, j-2), F(i+1, j-1) } }	2014-12-10 08:23:27		
174	wbqzu	2	Say we start with an even number of pots  1 2 3 4 5 6 ... 2*n  Player A can choose the pots in such a way that he has X = 1st + 3rd + + (2n-1)th pots' gold and the player B has Y = 2nd + 4th + ... + (2n)th or vice versa. Since player A can choose whether to end up with X or Y, player A always wins.  In case the number of pots is odd, player B can follow the same strategy right after player A makes first move, so the result depends on the exact amount of gold in the pots, so no 100% winning strategy in this case.	2014-12-10 08:23:27		
175	sqzqo	2	This is right, but the question asks for _the_ optimal winning solution (i.e. which maximizes the sum assuming best play from both sides). What you have here is _a_ winning position.  Very nice proof though...	2014-12-10 08:23:27		
176	sqzqo	2	It may not be the case as the pot can be picked from either end of the line. So 1st , 2nd , 3rd pot is possible as well.	2014-12-10 08:23:27		
177	plapd	2	It seems the question ask for __a__ winning strategy for player A, and not for __the__ winning position for player A, actually it may happen that player A has no way to win the game if player B plays optimally.	2014-12-10 08:23:27		
178	bjsiw	2	@Mihail: If the question was asking for _a_ winning strategy, why even talk about maximizing and optimal solutions?  If it was as you say, this will become a purely mathematical problem, and an AHA question, not suitable for a tech-interview.  On the other hand, trying to maximize/finding optimal will be a good algorithmic problem.	2014-12-10 08:23:27		
179	plapd	2	This answer does not deserve a downvote.	2014-12-10 08:23:27		
180	xhgls	2	this is nice Mihail!  When n is even, it is true who ever moves first can choose the odd-pot series or the even-pot series, so whoever moves first wins.  When n is odd, whoever first is guaranteed to lose unless the first pot can be big enough to offset the difference between odd-pot series and even-pot series!	2014-12-10 08:23:27		
181	rrmeu	2	hugh.hn, if the post is a strategy, it's not a winning one. Consider a four-pot game with the following pots:  6, 3, 1, 4  The first player can indeed choose to receive the first and third pots, but it results in a tie. The player can win, however, by choosing to receive the first and second pots.	2014-12-10 08:23:27		
182	ufdxg	2		2014-12-10 08:23:27		
183	ethan	2		2014-12-10 08:23:27		
184	krxlv	2		2014-12-10 08:23:27		
185	xhgls	2		2014-12-10 08:23:27		
186	fowai	2	IMO in such games it is a norm to assume that number of moves made by both players is the same and no one is at advantage by having extra moves. The fact that you have odd number of pots violates this essential condition. My small thought. Any comments?	2014-12-10 08:23:27		
187	cfzie	2	Not necessary that A Win... Consider the below example..... in any case A will lose...  Ex 1: 26, 70 ,11 Ex 2: 26,25,78,12,17  BR, Asheesh Goyal	2014-12-10 08:23:27		
188	mrjku	2	IMO in such games it is a norm to assume that number of moves made by both players is the same and no one is at advantage by having extra moves. The fact that you have odd number of pots violates this essential condition. My small thought. Any comments?	2014-12-10 08:23:27		
189	ewigy	2	we should assume A and B both want to win. In example (26, 1, 70 ,11) there is no way an 'A' can win. For 'A' to win B has to choose (11,1) or (26,1). But given problem statement that B also wants to win, he will definitely select (1,70). There is no way 'A' can restrict 'B' from selecting '1,70'.	2014-12-10 08:23:27		
190	nhibd	2	@sagar: In the case of (26, 1, 70, 11), A can win as follows:  1. A selects 26 2. Now B has to select either 1 or 11 from (1, 70, 11). 3. B selects either 11 or 1. 4. A selects 70. 5. B gets the other one.  So A can make a decision which forces B to not be able to choose 70. I think you probably read the question wrong.	2014-12-10 08:23:27		
191	rrmeu	2	Guys I need bit more explanation here. As per the given question, player's don't have any benefit or restriction. I mean, how can a player A choose ?? as it is certain he must have to pick a pot and that too present in a certain position.. Is there any option for him to skip a pot if he did not wish to collect it ?? How can the decision is been generated ? without that the game is straight forward and is totally depends upon arrangement of pots rather than player	2014-12-10 08:23:27		
192	azmjc	2	If they allowed players to "pass" on a turn, an algorithm could be written such that the game would never end.	2014-12-10 08:23:27		
193	admin	2		2014-12-10 08:23:28		
194	bexbp	2		2014-12-10 08:23:28		
195	eucmc	2	A - input array. S(x,y) - sum of element from x to y. We can get it for O(1) with O(n) preproccesing using 2 array. Of course, with solution with Max of two Min of two F(...) is a bit faster (no need to calculate sum), but as for me - this is simple to understand.  F(x, x) := A[x] F(x, y) := Max( A[x] + S(x+1, y) - F(x+1, y), A[y] + S(x, y-1) - F(x, y-1) )  We get first or last: A[x] or A[y] Then see how many can get opponent in new array: F(x+1, y) or F(x, y-1) Because of constant amount of points: S(x+1, y) - F(x+1, y) or S(x, y-1) - F(x, y-1)	2014-12-10 08:23:28		
196	qywrh	2	Obviously, this is reqursion/dynamic problem. So we need formula.  Let's say, that F(i, j) - is max possible coins that 'first' player can collect on board with packets from i to j. And by 'first' player I mean player whos turn now. F(0, n-1) - will be the answer.  Ok, now for F(i, j), first player can take v[i] or v[j].	2014-12-10 08:23:28		
197	qywrh	2		2014-12-10 08:23:28		
198	rdfeo	2		2014-12-10 08:23:28		
199	ethan	2	And he will collent x or y coints. Of course he will choose the maximum option:	2014-12-10 08:23:28		
200	krxlv	2		2014-12-10 08:23:28		
201	nwkeg	2		2014-12-10 08:23:28		
202	cfzie	2	Why (Sum[i+1, j ] - F(i+1, j ) )? Thats simply. After the first player took the coins, the turn passes to the second. And he also wnat to win. And now he is the first player but on the board (i+1, j) or (i, j-1). The Sum is fixed, so all that he will not take - is our coins. _________________________________________________ But do we really need to calculate Sum? No! Lets go deeper! in recursion : ) I skip here computing. In two words: If we 'open' F(i+1, j ) and F( i, j-1) - sum will be reduced and using that	2014-12-10 08:23:28		
203	nhibd	2		2014-12-10 08:23:28		
204	eucmc	2		2014-12-10 08:23:28		
205	sgiwy	2	and we will get:	2014-12-10 08:23:28		
206	dgjji	2		2014-12-10 08:23:28		
207	cfzie	2		2014-12-10 08:23:28		
208	cfzie	2	On each iteration size of board will be reduced on 2. _________________________________________________ To avoid re-computation, we need to store all done computation:	2014-12-10 08:23:28		
209	tenuw	2		2014-12-10 08:23:28		
210	sqzqo	2		2014-12-10 08:23:28		
211	ftfck	2	ArrayInfo can be simply int[n][n]. if you don't care about the amount of memory used. But we'll get to that later.  First, we need to initialize the smallest boards answers. There are two different situation. If N is odd, then F(i, j) = F(i, i) = v[i]	2014-12-10 08:23:28		
212	xhgls	2		2014-12-10 08:23:28		
213	fowai	2		2014-12-10 08:23:28		
214	ethan	2	If N is even, then F(i, j) = F(i, i+1) = MAX(v[i], v[i+1])	2014-12-10 08:23:28		
215	eucmc	2		2014-12-10 08:23:28		
216	fowai	2		2014-12-10 08:23:28		
217	azmjc	2	And now, we increasing the size of the board for 2 and calculate answers for all possible boards:	2014-12-10 08:23:28		
218	dgjji	2		2014-12-10 08:23:28		
219	rdfeo	2		2014-12-10 08:23:28		
220	ewigy	2	_________________________________________________ Returning to the ArrayInfo. There is only 1 sub-board starting fron i=n-1. (n-1, n-1) There are only 2 sub-board starting fron i=n-2. (n-2, n-2) and (n-2, n-1) ... Additionaly, we have only odd or only even lenght sub-boards, because we reduce it on 2 each time. So we don't need N*N space. We can impliment ArrayInfo such way:	2014-12-10 08:23:28		
221	fowai	2		2014-12-10 08:23:28		
222	qywrh	2		2014-12-10 08:23:28		
223	sgiwy	2	And it will used	2014-12-10 08:23:28		
224	bjsiw	2		2014-12-10 08:23:28		
225	xhgls	2		2014-12-10 08:23:28		
226	ftfck	2	that's in 4 time less.  working code: http://ideone.com/ZzbMRt	2014-12-10 08:23:28		
227	rrmeu	2	HERE ARE A SIMULATION:	2014-12-10 08:23:28		
228	ewigy	2		2014-12-10 08:23:28		
229	bexbp	2		2014-12-10 08:23:28		
230	ftfck	2	mafafito@mafafito-Aspire-4752:~/programming$ java Amazon  100 , 1 , 20 , 30 , 40 , 10 , 20 , 30 , 90 , Taking the first one: A WINS PLAYER A 100 + 30 + 10 + 30 + 1 + = 171 PLAYER B 90 + 20 + 40 + 20 + = 170 Taking the Last one: B WINS PLAYER A 90 + 30 + 10 + 30 + 1 + = 161 PLAYER B 90 + 20 + 40 + 20 + 100 + 20 + 40 + 20 + = 350 Recursive call result: : 171	2014-12-10 08:23:28		
231	bexbp	2	Upvoting yourself doesn't work axeliux	2014-12-10 08:23:28		
232	bjsiw	2	why it doesnt work?	2014-12-10 08:23:28		
233	ewigy	2	Oh. you are not taking about my code.  about the upvoting thing, of course I know it does not work. ( or at least it shouldn't work) But I wonder, how do you know that I did try anyway?	2014-12-10 08:23:28		
234	sqzqo	2	we are all in love with ourselves that's what careercup is for broken egos finding a playground to repair egos	2014-12-10 08:23:28		
235	bexbp	2	you havent break my ego anyway. But lets go back to bussiness:  What do you think about my program?  What about print the wining path inside the recursive call, do you think It could be interesting?	2014-12-10 08:23:28		
236	krxlv	2	This is a wrong question: 1, 3, 1. A cannot win. B wins.	2014-12-10 08:23:28		
237	huiqq	2	Implemented a solution using the minimax algorithm in C++ on github: github.com/benmurrell/PotsOfGold	2014-12-10 08:23:28		
238	cfzie	2	Here is a java program that solves this question and has a simulation of the moves (prints out players moves and coin sums along with remaining gold pots)  The main answer to this question is in the maxCoins function at the bottom. It's a little bit cluttered because I'm returning a MaxCoinResults object instead of just an int (has additional info stored in it such as the choice that was made (start or end).  I'm doing a recursive function and caching results (so DP). Similar to a lot of other suggested answers:	2014-12-10 08:23:28		
239	tenuw	2		2014-12-10 08:23:28		
240	qywrh	2		2014-12-10 08:23:28		
241	rrmeu	2	Here is some sample output: SIMULATION -- 2 -- --------------------------- Initial Coins:5,5,10,5,9,9,3,9,5,1 Expected A Winnings:33 Player A chooses the first coin with a value of:5 Player A now has a sum of 5 RemainingCoins:5,10,5,9,9,3,9,5,1 Player B chooses the last coin with a value of:1 Player B now has a sum of 1 RemainingCoins:5,10,5,9,9,3,9,5 Player A chooses the first coin with a value of:5 Player A now has a sum of 10 RemainingCoins:10,5,9,9,3,9,5 Player B chooses the first coin with a value of:10 Player B now has a sum of 11 RemainingCoins:5,9,9,3,9,5 Player A chooses the first coin with a value of:5 Player A now has a sum of 15 RemainingCoins:9,9,3,9,5 Player B chooses the last coin with a value of:5 Player B now has a sum of 16 RemainingCoins:9,9,3,9 Player A chooses the last coin with a value of:9 Player A now has a sum of 24 RemainingCoins:9,9,3 Player B chooses the last coin with a value of:3 Player B now has a sum of 19 RemainingCoins:9,9 Player A chooses the last coin with a value of:9 Player A now has a sum of 33 RemainingCoins:9 Player B chooses the last coin with a value of:9 Player B now has a sum of 28 RemainingCoins: Final Results ------------- Player A:33 Player B:28 END GAME.	2014-12-10 08:23:28		
242	plapd	2	Many people A always win, this is not the case. It depends on the randomness of the gold distribution, we can only maximize. Here is a test run with 100 pots each time, and run 10000 times. B consistently wins around 35% of the time, I did 10 different runs, so that's 100,000 times.  The actual % depends many variables, including, number of integers, and the random range of each integer.  Here is a prove: 1 3 1, A loses no matter what.  Here is the full code you can run it yourself, have fun.	2014-12-10 08:23:28		
243	admin	2		2014-12-10 08:23:28		
244	xhgls	2		2014-12-10 08:23:28		
245	zeice	2	Your optimalPick function is not actually always optimal. For example consider: 5,7,20,24,6,3 According to your optimal pick function 5 - max (7, 3) = -2 3 - max (6, 5) = -3  So A would choose the pot with 5 coins. Then according to your algorithm, B would choose 3 next. Because: (7 - 20 )= -13 < (3 - 6) = -3 But if you think for a second it would be a better move for B to choose the pot with 7 coins (because if A chooses the pot with 20 coins on B's next turn, then B can then take the pot with 24 coins).  So if A chose 5 at the beginning, and B chose 7, depending on what A did on their next turn this game would end up: A = 5 + 3 + 24 = 32 OR 5 + 20 + 6 = 31 B = 7 + 20 + 6 = 33 OR 7 + 24 + 3 = 34  As you can see B won in both instances.  It actually would have been optimal for A to choose the pot with 3 coins in the beginning. With both players playing optimally the results would have been: A = 3 + 24 + 7 = 34 B = 6 + 5 + 20 = 31  This is an example of why you need to recurse deeper to get the optimal solution rather than just peak at the next move.  You are right however, that with an odd number of pots B has a chance of winning depending on how the coins are set up.  But if there are an even # of coins I believe A has an optimal strategy that will help him/her to win or tie every time.	2014-12-10 08:23:28		
246	huiqq	2		2014-12-10 08:23:28		
247	wbqzu	2		2014-12-10 08:23:28		
248	wbqzu	2	Output for 1k pots : 7726 brute took 454 7711 algo took 0  N.B. The fast algo is pretty damn close and very fast but it's not accurate. Times are in milliseconds.	2014-12-10 08:23:28		
249	bjsiw	2	If you need the values as well {{ def mc(l): if len(l) <= 2: return sorted(l, reverse=True) v1 = mc(l[1:]) v2 = mc(l[:-1]) if (l[0] + sum(v1[i] for i in range(1, len(v1), 2))) > \ (l[-1] + sum(v2[i] for i in range(1, len(v2), 2))): return [l[0]] + v1 else: return [l[-1]] + v2  def wsa(l): v = mc(l) return [v[i] for i in range(len(v)) if i % 2 == 0]  print wsa([13, 25, 20, 12, 3]) }}	2014-12-10 08:23:28		
250	eucmc	2	- If number of pots of gold is odd: There's no optimal strategy that makes A win knowing that B is playing optimally as well. (Ex: [1,3,1]);  - Else: Player A must always pick the pot which produces the larger result for the equation (Number - Immediate Neighbor).  Ex: pots = [1,1,10,15,1,2]  A: picks pot[5] (2-1 > 1-1); B: picks pot[0] (1-1 > 1-15); So on...	2014-12-10 08:23:28		
251	rdfeo	2	DP implementation in C lang. for recursive algo. stated by Cerberuz ===================================================	2014-12-10 08:23:28		
252	ufdxg	2		2014-12-10 08:23:28		
253	bjsiw	2		2014-12-10 08:23:28		
254	dgjji	2	I hope the code is self explanatory in the meaning.	2014-12-10 08:23:28		
255	ufdxg	2	max_coin_R() method is a recursive method:	2014-12-10 08:23:28		
256	eucmc	2		2014-12-10 08:23:28		
257	ethan	2		2014-12-10 08:23:28		
258	sqzqo	2	dp:	2014-12-10 08:23:28		
259	azmjc	2		2014-12-10 08:23:28		
260	bjsiw	2		2014-12-10 08:23:28		
261	vanul	2	Python Recursive algorithm with Caching.	2014-12-10 08:23:28		
262	sgiwy	2		2014-12-10 08:23:28		
263	krxlv	2		2014-12-10 08:23:28		
264	bexbp	2		2014-12-10 08:23:28		
265	azmjc	2		2014-12-10 08:23:28		
266	xhgls	2		2014-12-10 08:23:29		
267	ftfck	2		2014-12-10 08:23:29		
268	ewigy	2	given {12,60,28,4} and the condition that A picks first, the algorithm mentioned in the first comment makes A lose. but A can win if it picks 4 and then 60. clarify this for me please	2014-12-10 08:23:29		
269	sgiwy	2	I believe that this does the trick... simple recursion using golang, could be optimized to suit various requirements...	2014-12-10 08:23:29		
270	qywrh	2		2014-12-10 08:23:29		
271	xhgls	2		2014-12-10 08:23:29		
272	dgjji	2		2014-12-10 08:23:29		
273	ethan	2		2014-12-10 08:23:29		
274	fmzze	2	Please check if this is correct. Thanks! :D	2014-12-10 08:23:29		
275	sqzqo	2	ALGO:Take the best of left and right of the line.This should be done by A as he gets to choose first and B will choose what is left of the line after A has picked.	2014-12-10 08:23:29		
276	gilit	2		2014-12-10 08:23:29		
277	sgiwy	2		2014-12-10 08:23:29		
278	sqzqo	2	TODO:Add memoization.	2014-12-10 08:23:29		
279	ftfck	2	If the input is {1, 10, 1000, 10}, then the optimal strategy is to pick the 1. Picking the best of left and right doesn't work.	2014-12-10 08:23:29		
280	ewigy	2	google search for minimax algorithm. That's the answer to this problem. Given all the information, one can say that person who plays first will ALWAYS win...	2014-12-10 08:23:29		
281	dgjji	2	Consider the pot's structure  1 3 1  Player A ends up with 2, and player B with 3 no matter how player A performs.	2014-12-10 08:23:29		
282	ftfck	2	I was wondering why non one mentioned minimax? Not everything HAS to be solved by DP!	2014-12-10 08:23:29		
283	dgjji	2		2014-12-10 08:23:29		
284	dgjji	2	I added some more comments to the question, however it was pretty much just that :-(	2014-12-10 08:23:29		
285	zeice	2	It may not be the case as the pot can be picked from either end of the line. So 1st , 2nd , 3rd pot is possible as well.	2014-12-10 08:23:29		
286	tenuw	3	The question asks if we can transform the given string S into its reverse deleting at most K letters. We could modify the traditional Edit-Distance algorithm, considering only deletions, and check if this edit distance is <= K. There is a problem though. S can have length = 20,000 and the Edit-Distance algorithm takes O(N^2). Which is too slow.  (From here on, I'll assume you're familiar with the Edit-Distance algorithm and its DP matrix)  However, we can take advantage of K. We are only interested *if* manage to delete K letters. This means that any position more than K positions away from the main diagonal is useless because its edit distance must exceed those K deletions.  Since we are comparing the string with its reverse, we will do at most K deletions and K insertions (to make them equal). Thus, we need to check if the ModifiedEditDistance is <= 2*K Here's the code:	2014-12-10 08:23:30		
287	ewigy	3		2014-12-10 08:23:30		
288	krxlv	3		2014-12-10 08:23:30		
289	zeice	3	We only process 2*K+1 columns per row. So this algorithm works in O(N*K) which is fast enough.	2014-12-10 08:23:30		
290	nwkeg	3	Killer thinking, +1. Fresh out of college? Just kidding... :-)	2014-12-10 08:23:30		
291	fowai	3	sort of, but I love these kind of questions/problems :)	2014-12-10 08:23:30		
292	sgiwy	3	It says by "removing at most k characters", not inserting, which makes it simpler.	2014-12-10 08:23:30		
293	ewigy	3	ce we are comparing the string with its reverse, we will do at most K deletions and K insertions (to make them equal).  why insertions ??	2014-12-10 08:23:30		
294	sqzqo	3	Like I said in the post, we're making the string and its reverse equal. They have both N characters so if we remove K characters, we need to insert K as well to get to size N.	2014-12-10 08:23:30		
295	admin	3	Clever aproach, but I don't think it works. FIrst, there should be a correspondece between the characters inserted and deleted, which you are not controlling. Second, You can do (1 insertion + 1 deletion)*n times, and you will still be in the main diagonal	2014-12-10 08:23:30		
296	dkebi	3	The correspondence between characters inserted and deleted is done because we're transforming the input string into its reverse. So those operations will lead to a palindrome.  "You can do (1 insertion + 1 deletion)*n times, and you will still be in the main diagonal" Sure, but the cost will be 2*N. As explained above, the final step is to compare DP[N][N] with 2*K. only then we decide the answer.	2014-12-10 08:23:30		
297	wbqzu	3	I'm not sure this works.  Edit distance between 'abax' and 'xaba' is 2. However, to edit 'abax' to be a palindrome, we need just 1 delete.	2014-12-10 08:23:30		
298	wbqzu	3	My bad. Please ignore my earlier comment.  I missed the '<= 2*K ' part.	2014-12-10 08:23:30		
299	huiqq	3	@Keith, that was explained before. The code answers 2 because it is transforming the string into its reverse. If we need 1 delete in the original string, we need another delete in the reversed string to make them equal. That's why we compare it with 2*K	2014-12-10 08:23:30		
300	vanul	3	@- Miguel Oliveira why not we just run it only till half of the string and save the rest half of the problem i dont have the complete code but if we are able to match the 1st half and 2nd half we dont need to do the vice-versa operation  btw nice solution indeed	2014-12-10 08:23:30		
301	huiqq	3	memset the entire dp array takes O(N^2), so your implementation is actually O(N^2).	2014-12-10 08:23:30		
302	rrmeu	3	Eric, a N^2 table also wouldn't fit in memory. Refer to the comment in the code  // for simplicity. we should use only a window of size 2*k+1 or // dp[2][MAX] and alternate rows. only need row i-1	2014-12-10 08:23:30		
303	admin	3	Also, I think the correct outcome for your second case should be 'Yes'(delete x).	2014-12-10 08:23:30		
304	sqzqo	3	OOops, ignore the previous comment. It is correct.	2014-12-10 08:23:30		
305	ufdxg	3	in edit distance algorithm we are changing only one of the string and Why are you trying to keep the length constant here...insertions are not allowed at all....please clarify	2014-12-10 08:23:30		
306	qywrh	3	It doesnt work for ModifiedEditDistance("abc", "cba", 1).  Here the edit distance would be 2 (which is <=2*1), but wont form a palindrome for k=1 deletions.	2014-12-10 08:23:30		
307	krxlv	3	This is not a normal edit distance. I do not allow substitutions. If you run the code, you'll see that ModifiedEditDistance("abc", "cba", 1) returns 4 which is larger than 2*K	2014-12-10 08:23:30		
308	jippy	3	Nice idea but it actually is different from the classical edit distance problem where the first string is transformed into the second. Here we need to perform adjustments on both strings but it works because the cost is the same for delete and add. Otherwise the algorithm should be slightly modified.	2014-12-10 08:23:30		
309	xhgls	3	Shouldn't the following:	2014-12-10 08:23:30		
310	rrmeu	3		2014-12-10 08:23:30		
311	xhgls	3		2014-12-10 08:23:30		
312	dkebi	3	be:  if (a[i] == b[j]) // same character dp[i][j] = dp[i-1][j-1];	2014-12-10 08:23:31		
313	eucmc	3	No. Notice than both i and j are 1-indexed (1..n) due to the DP table. Hence the -1 to get the correct characters.	2014-12-10 08:23:31		
314	fmzze	3	I made a recursive algorithm	2014-12-10 08:23:31		
315	huiqq	3		2014-12-10 08:23:31		
316	dgjji	3		2014-12-10 08:23:31		
317	nhibd	3	I made a similar one in java, but I'm not sure if it works... If it doesn't, could you let me know why?	2014-12-10 08:23:31		
318	gilit	3		2014-12-10 08:23:31		
319	eucmc	3		2014-12-10 08:23:31		
320	mrjku	3	There are two approaches you may apply. The first one is to reverse the input string and find the LCS of the input string, and it's reversal. This gives you the lenght of the longest palindrom. Now you substract the LCS value from the lenght of the string and you get the k - so just check if it matches.  The second approach just looks for a palindrom. Let's say p[n] is a palindrom with lenght n. Let l will be begining, end e the end of a palindrom. Then we can see that: 1) p[l] == p[h], then we need to check p[l+1] == p[h - 1], i.e abcba, where p[l] == a == p[h] 2a) p[l] != p[h], then we need to check p[l+1],p[h] (we removed p[l]) 2b) p[l] != p[h], then we need to check p[l], p[h-1], (we removed p[h])  Now simply use this in your dynamic programming aproach. If you have a problem with that, I am more than glad to help you more.  As I was bored, I typed the code for the second solution:)	2014-12-10 08:23:31		
321	dkebi	3		2014-12-10 08:23:31		
322	rrmeu	3		2014-12-10 08:23:31		
323	nhibd	3	This roughly equals to choose 30 from 20000, takes way toooooooo much time!	2014-12-10 08:23:31		
324	jippy	3	Does not work. LCS of reverse and and string need not be largest palindrome.	2014-12-10 08:23:31		
325	tenuw	3	I think the LCS method works. Annonymous, can you give a counter-example?	2014-12-10 08:23:31		
326	fmzze	3	The problem is that LCS works in O(N^2) so it will be too slow with those limits. There should be another solution taking advantage of k.	2014-12-10 08:23:31		
327	dkebi	3	@Miguel. Try proving that it works.	2014-12-10 08:23:31		
328	rrmeu	3	(A web search should reveal a counter-example, though)	2014-12-10 08:23:31		
329	mrjku	3	right, it's not necessarily a palindrome. there are ways to make a LCS based approach work though (just found on the web but can't link it here due to this site restrictions).  anyway, i've given an efficient solution to this problem based on edit-distance	2014-12-10 08:23:31		
330	dkebi	3	I think that the LCS approach should work fine. The longest subset in this case would be a base of a palindrom, as we are comparing the same set, just in a different order. Please give a real counter example.	2014-12-10 08:23:31		
331	vanul	3	@joe_kidd: does this work for {"malayalxam"} with k=1?	2014-12-10 08:23:31		
332	xhgls	3	It looks like. The reversal is maxlayalam, so the longest common subsequence is: malayalam, the lenght difference 1, so it works.	2014-12-10 08:23:31		
333	gilit	3	@joe for the purpose of this problem, the simple LCS approach works. It would not work if we wanted to find out the palindromic string instead of just its length. Check the page wcipeg . com / Longest_palindromic_subsequence The longest palindromic subsequence is one of the LCSes but it's not guaranteed that every LCS is palindrome. "afala" and "alafa" are LCSes of "alfalfa" and its reverse, yet neither is palindromic.	2014-12-10 08:23:31		
334	nhibd	3	Thanks, the page seems to be very cool not only for this particular case.	2014-12-10 08:23:31		
335	ftfck	3	@joe_kidd : I thought of the same solution as yours before I looked at posted solutions ! I am glad that you also came up that. Well, what do you think is complexity of the algorithm? I think it's O(n). Is that right?	2014-12-10 08:23:31		
336	jippy	3	@Parin, it's O(N^2) which is too slow	2014-12-10 08:23:31		
337	azmjc	3	I think this question can be solve by following idea. I define the function like this : bool isKPalindrom(string s, int start, int end, int k)  The input is string s , its begin position, its end position and k.  If s[start:end] is palindrome then return true else if k < 0 return false else if s[start] == s[end-1] then recursively call isKPalindrome(s,start+1,end-1,k) else return isKPalindrome(s,start+1,end,k-1 ) || isKPalindrome(s,start,end-1,k-1)  We can also use a array to record the result of whether s[start,end] is palindrome  The time complxity is (n^2)	2014-12-10 08:23:31		
338	vanul	3	I would use recursion to solve this problem:	2014-12-10 08:23:31		
339	fowai	3		2014-12-10 08:23:31		
340	eucmc	3		2014-12-10 08:23:31		
341	dkebi	3	Given that array.subArray() is O(1). This also runs in O(n) doesn't it?	2014-12-10 08:23:31		
342	zeice	3	subArray does not run in O(1) but O(N). anyway this recursive approach runs in exponential time	2014-12-10 08:23:31		
343	sqzqo	3	@joe_kidd : I thought of the same solution as yours before I looked at posted solutions ! I am glad that you also came up that. Well, what do you think is complexity of the algorithm? I think it's O(n). Is that right?	2014-12-10 08:23:31		
344	ufdxg	3	@joe_kidd : I thought of the same solution as yours before I looked at posted solutions ! I am glad that you also came up that. Well, what do you think is complexity of the algorithm? I think it's O(n). Is that right?	2014-12-10 08:23:31		
345	vanul	3	This is a recursive approach, and works for all possible cases.  This is a back tract approach. Maximum matches can be n (n is the size of input array) and minimum matches can be n-k.	2014-12-10 08:23:31		
346	zeice	3		2014-12-10 08:23:31		
347	fmzze	3		2014-12-10 08:23:31		
348	azmjc	3	Python code:  def isPalindrome(String): stringSize = len(String) start = 0 end = stringSize - 1 while start < end and String[start] == String[end]: start += 1 end -= 1 if start < end: return False else: return True  def isKPalindrome(String, k): if k > 0: for i in range(len(String)): subString = String[:i] + String[i+1:] if isKPalindrome(subString, k-1) == True: return True return False elif k == 0: return isPalindrome(String) else: print 'Error number k' return False   Testing Set: print isPalindrome('1') print isPalindrome('11') print isPalindrome('11111') print isPalindrome('11211') print isPalindrome('13231') print isPalindrome('1221') print isPalindrome('133121331')  print isPalindrome('11221') print isPalindrome('13211') print isPalindrome('23') print isPalindrome('123')  print isKPalindrome('abxa', 1) print isKPalindrome('abxa', 2) print isKPalindrome('abdxa', 2) print isKPalindrome('abdxa', 1)	2014-12-10 08:23:31		
349	wbqzu	3	How could I indent?	2014-12-10 08:23:31		
350	ufdxg	3		2014-12-10 08:23:31		
351	eucmc	3		2014-12-10 08:23:31		
352	bexbp	3	Correction to previous python solution:	2014-12-10 08:23:31		
353	bjsiw	3		2014-12-10 08:23:31		
354	cfzie	3		2014-12-10 08:23:31		
355	fmzze	3	#include<stdio.h> #include<conio.h> int main() { int k,i=0,j,flag=1,count=0; char a[20]; printf("ENTER THE VALUE OF K"); scanf("%d",&k); printf("ENTER THE STRING"); scanf("%s",a); j=strlen(a); j=j-1; while(i<j) { if(a[i]!=a[j]) { if(a[i+1]==a[j]) { count++; } else if(a[i]==a[j-1]) { count++; } else { flag=0; break; } } if(count>k) { flag=0; break; } i++; j--;  } if(flag==0) printf("NO"); else printf("YES"); getch(); }	2014-12-10 08:23:31		
356	nhibd	3		2014-12-10 08:23:31		
357	qywrh	3		2014-12-10 08:23:31		
358	rdfeo	3	I think this piece of code should work and pretty much self descriptive. I'm still questioning what would be the complexity it's definitely O(n^2), but I think there is better estimation and should be lower, many branches will be cut by checking if k < 0 condition.  Does anybody have an idea?	2014-12-10 08:23:31		
359	azmjc	3		2014-12-10 08:23:31		
360	bjsiw	3		2014-12-10 08:23:31		
361	zeice	3	@maks - this does not work	2014-12-10 08:23:31		
362	jippy	3	What about this one?  def palin_k(str, k): if k == 0 or str == str[::-1]: return str == str[::-1] l_index = 0 r_index = len(str) - 1 while str[l_index] == str[r_index]: l_index = l_index + 1 r_index = r_index - 1 return palin_k(str[l_index:r_index], k-1) or palin_k(str[l_index+1:r_index+1], k-1)	2014-12-10 08:23:31		
363	tenuw	3	you can do something like that :	2014-12-10 08:23:31		
364	sgiwy	3		2014-12-10 08:23:31		
365	bexbp	3		2014-12-10 08:23:31		
366	ewigy	3	and call the function with : palindromeK(word, k, 0, word.length()-1, (char) 0);  Basically you successively look at the beginning / the end of your word, and you remove a character when you know you can't using it to make a palindrome. The cost if O(n2)	2014-12-10 08:23:31		
367	bexbp	3		2014-12-10 08:23:31		
368	vanul	3		2014-12-10 08:23:31		
369	bexbp	3	This is in javascript, I measure the distance of the palindrome of the string and divide it by 2, since it each extra character will appear twice	2014-12-10 08:23:31		
370	wbqzu	3		2014-12-10 08:23:31		
371	ethan	3		2014-12-10 08:23:31		
372	rrmeu	3	@miguel - great solution! i used the dp / edit distance approach like you suggested and i think it works.. not sure if i did it exactly like you said... but same general idea..	2014-12-10 08:23:31		
373	wbqzu	3		2014-12-10 08:23:31		
374	jippy	3		2014-12-10 08:23:31		
375	cfzie	3	never mind. i found a bug in my above code. it does not work for this input isKPalindrome("sbandanarb", 5)	2014-12-10 08:23:31		
376	dkebi	3		2014-12-10 08:23:31		
377	ftfck	3		2014-12-10 08:23:31		
378	fowai	3	Hmm that's pure backtracking. Dynamic programming implies that you're saving subproblems results somewhere (like a table) and reusing them later.	2014-12-10 08:23:31		
379	huiqq	3	I agreed! :) Modified comments accordingly.	2014-12-10 08:23:31		
380	bjsiw	3		2014-12-10 08:23:31		
381	vanul	3		2014-12-10 08:23:31		
382	mrjku	3	LCS should work, the worst case is O(N^2) when there is no match. But we would be able to return early when this is match with K.	2014-12-10 08:23:31		
383	mrjku	3		2014-12-10 08:23:31		
384	bjsiw	3		2014-12-10 08:23:31		
385	ufdxg	3	There is another DP solution: Firstly I will present a simple quadratic solution dp[l][r] - state where we hold minimum number of removes in order to transform the segnment s[l]...s[r] into palindrome. Transitions will be as follows: if(s[l] == s[r]) dp[l][r] = min(dp[l][r], dp[l + 1][r - 1]); else dp[[l][r] = min(dp[l][r], min(dp[l + 1][r], dp[l][r - 1]) + 1); But the problem is in that it works too slowly, therefore we can convert our solution by the following way: dp[l][k] - will hold the rightmost position in S where we can reach removing exactly k characters and starting from l; if(S[dp[l + 1][k]] == s[l]) dp[l][k] = max(dp[l][k], dp[l + 1][k] + 1); else dp[l][k] = max(dp[l][k], dp[l + 1][k - 1] + 1); The implementation demands to go through from right to left; At the end it is enough just to look at states dp[0][i], where 0<=i <= k; if(dp[0][i] == s.length()) then "yes" else "no";	2014-12-10 08:23:32		
386	ftfck	3	Solution in java-  Take an array R of size 26.  Loop through each character of the string and increment the index of R for that character.  If a string is palindrome then the count of each character in R %2 will give 0 and if string length is odd then except one character rest of character's count %2 will be 0.  Now, if you want to calculate k-palindrom add the k to the comparison as shown below.	2014-12-10 08:23:32		
387	ethan	3		2014-12-10 08:23:32		
388	mrjku	3		2014-12-10 08:23:32		
389	krxlv	3		2014-12-10 08:23:32		
390	dkebi	3		2014-12-10 08:23:32		
391	ftfck	3	Quick explanation:  Start at the borders and collapse, if borders are equal, then continue with the rest of the string, otherwise, check if you can take one border out so that you can still form a valid palindrome with the other border, if not, take out both borders.  O(n) since you only traverse the string once.	2014-12-10 08:23:32		
392	fmzze	3	find the longest palindromic subsequence. get its difference with length of string , say diff. if diff <= k , then its a k-pali string.	2014-12-10 08:23:32		
393	plapd	3	Below are my solutions in C++. The first one is a recursive function which gives a good idea of how to tackle the problem. This solution has a huge complexity (something like O(L * 2^K) though I cannot prove an exact formula - L is the length of the string).  The second one is a solution which uses a matrix of size 2*L*K^2 and which fills it step by step (a change of indices is used to avoid building a L * L * K matrix). This solution has O(L*K^2) complexity which is quite acceptable with the given parameters.	2014-12-10 08:23:32		
394	huiqq	3		2014-12-10 08:23:32		
395	mrjku	3		2014-12-10 08:23:32		
396	eucmc	3	Line 6 is	2014-12-10 08:23:32		
397	ethan	3		2014-12-10 08:23:32		
398	gilit	3		2014-12-10 08:23:32		
399	krxlv	3	actually.	2014-12-10 08:23:32		
400	ufdxg	3	Couldn't help adding a Scala solution. I believe that this runs in O(n/2 + 2*K)	2014-12-10 08:23:32		
401	tenuw	3		2014-12-10 08:23:32		
402	dgjji	3		2014-12-10 08:23:32		
403	ewigy	3	To prep:	2014-12-10 08:23:32		
404	sgiwy	3		2014-12-10 08:23:32		
405	rdfeo	3		2014-12-10 08:23:32		
406	mrjku	3	Runs:	2014-12-10 08:23:32		
407	dkebi	3		2014-12-10 08:23:32		
408	ftfck	3		2014-12-10 08:23:32		
409	ewigy	3	Couldn't help adding a Scala solution. I believe that this runs in O(n/2 + 2*K)	2014-12-10 08:23:32		
410	sgiwy	3		2014-12-10 08:23:32		
411	eucmc	3		2014-12-10 08:23:32		
412	xhgls	3	To prep:	2014-12-10 08:23:32		
413	bexbp	3		2014-12-10 08:23:32		
414	rdfeo	3		2014-12-10 08:23:32		
415	jippy	3	Runs:	2014-12-10 08:23:32		
416	dgjji	3		2014-12-10 08:23:32		
417	eucmc	3		2014-12-10 08:23:32		
418	ewigy	3	Here is a naive solution in python, the time complexity is not acceptable for the input bounds but it may help you if you are stuck before moving to a faster solution posted above.  {{def isPalindrome(str): if (str == str[::-1]): return True else: return False  def isKPalindrome(str, k): if (len(str) <= 1 or k < 0): return False elif(isPalindrome(str)): return True  for i in range(len(str)): smallerStr = str[:i] + str[i+1:] if (isKPalindrome(smallerStr, k-1)): return True return False  print isKPalindrome("aaybbaxa", 2) print isKPalindrome("aaybbaxa", 1)}}	2014-12-10 08:23:32		
419	dkebi	3	Here is a naive solution in python, the time complexity is not acceptable for the input bounds but it may help you if you are stuck before moving to a faster solution posted above.	2014-12-10 08:23:32		
420	sqzqo	3		2014-12-10 08:23:32		
421	gilit	3		2014-12-10 08:23:32		
422	cfzie	3	Here's a recursive solution in Objective-C, with a complexity of `O(n)`, where `n` is the number of characters in the string.	2014-12-10 08:23:32		
423	rrmeu	3		2014-12-10 08:23:32		
424	krxlv	3		2014-12-10 08:23:32		
425	fmzze	3		2014-12-10 08:23:32		
426	ftfck	3		2014-12-10 08:23:32		
427	vanul	3		2014-12-10 08:23:32		
428	ufdxg	3		2014-12-10 08:23:32		
429	eucmc	3	Here's a solution in JavaScript:	2014-12-10 08:23:32		
430	qywrh	3		2014-12-10 08:23:32		
431	fmzze	3		2014-12-10 08:23:32		
432	eucmc	3	A working version at - codepen.io/yusufnb/pen/veDBx?editors=001	2014-12-10 08:23:32		
433	dkebi	3		2014-12-10 08:23:32		
434	wbqzu	3		2014-12-10 08:23:32		
435	cfzie	3	Not sure if this will work...you guys critique. Written in Python3:	2014-12-10 08:23:32		
436	krxlv	3		2014-12-10 08:23:32		
437	dgjji	3		2014-12-10 08:23:32		
438	jippy	3	I made a C# method for it. This appears to work and I BELIEVE it'll cover cases that result from larger strings also. Little bit lengthy, but recursive method seemed most logical to handle the total number of removed characters. There's obviously driver code, but its not all that important.	2014-12-10 08:23:32		
439	vanul	3		2014-12-10 08:23:32		
440	plapd	3		2014-12-10 08:23:32		
441	huiqq	3	I tested it, you are right it will not work with "axxba". So I am removing it.	2014-12-10 08:23:32		
442	ethan	3	This code does not work. Counter-example: "axxbababa", k = 2. Answer is True, but your code gives False	2014-12-10 08:23:32		
443	mrjku	4	An O(n) solution is possible.  We consider all "split points", i.e. points such that one subarray lies to the left of it, and one to the right, and compute the best for each possible split point.  Dynamic programming works.  Given Array A[1,...n]  Using the standard dynamic programming algorithm, we can compute for a given i, the maximum and minimum sum subarrays in A[1...i] and A[i+1 ... n]. Note that the point between i and i+1 is a split point.  This can be done by making two passes once from 1 to n, and other from n to 1 and give us four arrays with the max and min sub-array sums.  Now given the above four arrays, for split point between i and i+1, we can take the max and min combinations (max from right, min from left and max from left, min from left), and get the combination which gives the better result.  Once we have the max for each split point, we get the global optimum.  O(n) time, O(n) space.	2014-12-10 08:23:43		
444	ewigy	4	Nice solution Loler. I think it will work	2014-12-10 08:23:43		
445	krxlv	4		2014-12-10 08:23:43		
446	admin	4		2014-12-10 08:23:43		
447	qywrh	4		2014-12-10 08:23:43		
448	wbqzu	4		2014-12-10 08:23:44		
449	admin	4	@loler: so let's run it on [4, -1, 7] For i:1 so we divide array as [0] & [1,2] [max 4 min 4] [max 7 min 6] For i:2 so we divide array as [0,1] & [2] [max 4 min 3] [max 7 min 7] so let's compare all the min and max arrays for each i i.e. split point. So we get 3 as the answer(7-3) Is this what you mean?	2014-12-10 08:23:44		
450	tenuw	4	Looks like you got tricked into answering a live competition question: codechef.com/JUNE13/problems/DELISH	2014-12-10 08:23:44		
451	gilit	4	@Loler: the solution which you presented is still O(n^2). Because for each split point you are finding max & min sub arrays in either sides in O(i) and O(n-i), for split at i. So, for all split points, the order comes out to O(n^2).	2014-12-10 08:23:44		
452	wbqzu	4	@frager +1. I agree this is a quadratic algorithm. @Loler, can you post the code?	2014-12-10 08:23:44		
453	rrmeu	4	@frager: but you can do it (computing the max/min) subarrays for each split point in O(n) if you cache previous results (hence O(n) space complexity). When you are at A[i] the max subarray is either max A[i-1] extended with A[i] or if this extension goes below 0 then the max subarray is the same subarray as for A[i-1].  Tell me if I'm wrong.	2014-12-10 08:23:44		
454	mrjku	4	@oOZz: I came up with the same algorithm as @Loler. Below is the code (ugly but I did it during my lunch break). It is O(n) time and O(n) space and passes the dreaded {4,-1,7} ;) But didn't test it extensively. P.S. I am full of respect for people who can come up and code it within 45mins, without a compiler and during an interview (stress). Took me 1hours with a compiler.	2014-12-10 08:23:44		
455	bexbp	4		2014-12-10 08:23:44		
456	nhibd	4		2014-12-10 08:23:44		
457	xhgls	4	If we want more - like exactly the subarrays we need to store the start/end indices for each split too (doesn't change the time complexity order, only the constant)	2014-12-10 08:23:44		
458	ewigy	4	@Up: two things: 1) noticed I copied my solution with a bug, while calculating the "revMax/Min" there should be revMin[0] = A[len]; instead of min[0] = A[len]; 2) depending on how we interpret the question there might be needed a slight change in the code. For instance what should be the output for [-1,-2,-3]. Should it be 4 (as abs( (-3-2) - (-1) )) or should we take the whole array and treat an empty array as the second one which would give us abs( (-3-2-1) - 0) = 6?	2014-12-10 08:23:44		
459	tenuw	4	@Anonymous. Respect my friend! The code mostly works (see below), but it's still impressive to come up with a DP solution in 1 hour during lunch. (+1) I also agree with you that the DP problems are hard to solve in 45 mins without a compiler and therefore, they're better suited for coding competitions than job interviews.  Your code for input [-1,-2,-3] fails. It outputs 1, but neither 4 nor 6. I've asked the same question to @LAP for clarification whether the empty set is a valid subarray and its sum is 0, but he/she didn't answer. I'd assume that it is. Then IMO, [-1,-2,-3] should return (0 - (-1,-2,-3)) = 6 and [4,-1,7] should return ((4,-1,7) - 0) = 10.  I've also just made a small change to the code that I posted above. It works with the empty set assumption. Though it's a O(N) time and O(1) space and only 20 lines, no one seems to not like it LOL Happy coding!	2014-12-10 08:23:44		
460	plapd	4	@oOZz: the [-1,-2,-3] result is incorrect because I pasted my code with a bug to this site (long story short I couldn't do a ctrlc/ctrlv :). I mentioned it above.  Also I agree with that DP problems suck for interviews. Hopefully I will not have one (or at least a hard one) during my G interview today :))	2014-12-10 08:23:44		
461	rrmeu	4	@aka: Yes something like that.  @eugene: Oops. Well played by LAP I suppose :-), and looks like it might be too late to delete now.  @frager/oOZz: It is O(n). Just store the intermediate results of Kadane's algorithm... (Kadane's is what I mean by "standard dynamic programming algorithm".)  @oOZz: During an interview they don't expect perfect code which will compile at the get go. If you want to use some library method, you can just assume it. I would say it is easier to write code in an interview, than using a compiler: you won't get bogged down by the useless details (like does strcpy take dst first or src?) and can concentrate on the parts that matter.  @Anonymous: I don't see a problem asking DP questions. The point of the questions is not to see whether you get the answer or not, but to see how you tackle it. You will be judged relative to other candidates on the same question (at least in Google), so everyone is in the same boat.  Sorry if I missed responding to someone.	2014-12-10 08:23:44		
462	rrmeu	4	@Loler: Do you work for Google? Wonderful!	2014-12-10 08:23:44		
463	bjsiw	4	@Dumbo. The information about the judging relative to other candidates is public. Gayle has herself said it multiple times. Even the recruiters tell you that, I believe.	2014-12-10 08:23:44		
464	mrjku	4	@Loler: Wonderful Loler, nice to know that great talent is around. Wanted to ask you for a favor - I have been working on question?id=12708671. Thought hard on the problem for days together and came up with a solution. Could you kindly verify if my idea works? [Kindly excuse my trumpeting there]. Apologies to all who find my post irrelevant to the current context - btw any other way of 1-1 communication possible here?	2014-12-10 08:23:44		
465	rrmeu	4	There is some issue with this DP approach, because the max/min sum of A[1..i] can not be generated from A[1..i-1]. Here are two examples: {-6 5 -7 6} => Min: {-6 5 -7 } = -8, Min = {6} = 6, Diff= 14 {-6 5 -7 2} => Min: {-7}, Max = {5}; Diff = 12 The Min for {-6 5} is {-6}, but from this Min, we cannot get Min for {-6 5 -7} = -8 Also @oOZz's code always assumes the min/max running sum continuing decrease/increase. They may decrease, increase and then decrease.  The split point approach is still valid.	2014-12-10 08:23:44		
466	huiqq	4	@Dumbo: Try freenode IRC channel #algorithms if you have any doubts in algorithms.	2014-12-10 08:23:44		
467	dkebi	4	For the reverse max/min, we don't even need to store the result in array. We can simply make a reverse pass and at every point, we have the max and min. Using these two variables, we can simply calculate the absolute difference. The largest different would be the answer.	2014-12-10 08:23:44		
468	ufdxg	4	@Anonymous. There are lots of bug in your code, apart from the one you already know. 1) Take input [-4,5], in this case your code will find max as -4+5=1 which is wrong, max should be 5, same for the min case. 2)I think your logic for calculating the min array is also wrong, recheck it one. Apart from these bugs, nice solution :) . Do post about your G interview :)	2014-12-10 08:23:44		
469	ufdxg	4	@sniper: about [-4,5] I think it should be |5-(-4)| = 9 and that's how my code acts :) But you are right I wasn't 100% sure how to interpret the question for instance what should be the result for [1,5]. Should it be |(5+1)-0| = 6 or |5-1|=4? It all depends is an empty subarray an array. I assumed no.  About the min array I still didn't find a counterexample that would give me an incorrect solution but indeed there might be bugs :)  The G interview was good, will post the question soon but it was very easy :)	2014-12-10 08:23:44		
470	fowai	4	@Anyonymous who just gave Google interview. Please do post the questions and what your answers were. And please also tell us if you got the job.	2014-12-10 08:23:44		
471	jippy	4	@oOZz's solution does work for an array containing only positive numbers. For example, [8, 1, 1, 1].	2014-12-10 08:23:44		
472	jippy	4	I come up with the same algorithm as @Loler. I implement it in Python. Here is the code:	2014-12-10 08:23:44		
473	dgjji	4		2014-12-10 08:23:44		
474	xhgls	4		2014-12-10 08:23:44		
475	qywrh	4		2014-12-10 08:23:44		
476	fowai	4		2014-12-10 08:23:44		
477	mrjku	4	I agree this is the best answer on the board, but I think it is still wrong.  Consider: -10 7 -3 2 2 -20 1  The best split point considering everything left and right is between -20 and 1, where the best solution is -20 and 7.	2014-12-10 08:23:44		
478	azmjc	4	Why does this answer have so many likes? It doesn't take into account that the first array can start not from the beginning but rather from any other positions and the same is true for the second array. Actually there are three split points in this task. So, if we have an array {2, -4, -5, 3, 6, -1}, our split point will be: Split point 1 goes after 2 Split point 2 goes after -5 Split point 3 goes after 6 And the solution will be {-4, -5} and {3, 6}	2014-12-10 08:23:44		
479	cfzie	4	Use dp with kadane's algorithm for solving above problem...:-)  import java.io.*; public class Main {  public static void main(String args[]) throws IOException { BufferedReader br=new BufferedReader(new InputStreamReader(System.in)); long a[]=new long[10000]; long b[]=new long[10000]; long max1[]=new long[10000]; long min1[]=new long[10000]; long max2[]=new long[10000]; long min2[]=new long[10000]; int n=Integer.parseInt(br.readLine()); String arr[]=br.readLine().split(" " ); int i=0; for(String s:arr) { a[i]=Integer.parseInt(arr[i]); b[i]=-a[i]; i++; }  long maxsofar=a[0],maxendinghere=a[0];max1[0]=a[0]; for(i=1;i<n;i++) { //maxendinghere=maxendinghere+a[i]>0?maxendinghere+a[i]:0; maxendinghere=maxendinghere+a[i]; maxendinghere=maxendinghere>a[i]?maxendinghere:a[i]; maxsofar=maxsofar>maxendinghere?maxsofar:maxendinghere; max1[i]=maxsofar; } max2[n-1]=maxendinghere=maxsofar=a[n-1]; for(i=n-2;i>=0;i--) { //maxendinghere=maxendinghere+a[i]>0?maxendinghere+a[i]:0; maxendinghere=maxendinghere+a[i]; maxendinghere=maxendinghere>a[i]?maxendinghere:a[i]; maxsofar=maxsofar>maxendinghere?maxsofar:maxendinghere; max2[i]=maxsofar;  } maxendinghere=maxsofar=b[0]; min1[0]=-b[0]; for(i=1;i<n;i++) { //maxendinghere=maxendinghere+b[i]>0?maxendinghere+b[i]:0; maxendinghere=maxendinghere+b[i]; maxendinghere=maxendinghere>b[i]?maxendinghere:b[i]; maxsofar=maxsofar>maxendinghere?maxsofar:maxendinghere; min1[i]=-maxsofar; } maxendinghere=maxsofar=b[n-1]; min2[n-1]=-b[n-1]; for(i=n-2;i>=0;i--) { //maxendinghere=maxendinghere+b[i]>0?maxendinghere+b[i]:0; maxendinghere=maxendinghere+b[i]; maxendinghere=maxendinghere>b[i]?maxendinghere:b[i]; maxsofar=maxsofar>maxendinghere?maxsofar:maxendinghere; min2[i]=-maxsofar; } long globalmax=0; /* for(i=0;i<n;i++) { System.out.println(a[i]+" "+b[i]+" "+min1[i]+" "+max1[i]+" "+min2[i]+" "+max2[i]); } */ for(i=1;i<n;i++) { long m1=max1[i-1]-min2[i]; m1=Math.abs(m1); long m2=max2[i]-min1[i-1]; m2=Math.abs(m2); m1=m1>m2?m1:m2; globalmax=globalmax>m1?globalmax:m1; } System.out.println(globalmax); }  }	2014-12-10 08:23:44		
480	ftfck	4	So abstract the list of ints to a list of three subsets.  list of numbers= {a, b, c} where a,b,c are sums of contiguous numbers in the array and a,b,c are contiguous.  Each of those subsets represents the sum of contiguous numbers in the array. We are looking for the highest and lowest. Note that it is impossible for A or C to have the same signage (positive or negative) as B. Also, if either A or C is the empty set, then the positive subset is the highest and the negative subset is the lowest. If both A and C are the empty set, then B is either the high subset or low subset based off of B's signage. Also lets specify that, B can never be an empty set unless both A and C are empty sets. Now the important thing to note here is that we are going to try to maximize the absolute value of B. This is important because it will allow us to take the highest absoulute value of either A or C and get the highest combined difference.  So let's take a look at some real numbers n = {a, b, c}	2014-12-10 08:23:44		
481	rdfeo	4		2014-12-10 08:23:44		
482	nwkeg	4		2014-12-10 08:23:44		
483	fmzze	4	so n = {100, -506, 305}  So here we can see we should grab the array that adds up to -506 (-500, 2, -7, 50, -51) and the array that adds up to 305 (3, -2, 4, 300).  So basically the algorithm is this 1) Pass through the array and calculate the sums 2) Figure out the largest absolute value the sub array B can be 3) Figure out if either A or C should be the other array   Here is some code that I wrote that does what I outlined above. It was written before I really understood why the codeworks so it could be prettied up, but I am too lazy to do so :)	2014-12-10 08:23:44		
484	bexbp	4		2014-12-10 08:23:44		
485	fmzze	4		2014-12-10 08:23:44		
486	xhgls	4	NOTE: the second array is a SUBSET of either A or C if B is I-j, you should start with I-1 as the end of one of the potential arrays and j+1 as the start of one of the potential arrays.	2014-12-10 08:23:44		
487	zeice	4	This solution in python is short, O(n), I hope this will help u.	2014-12-10 08:23:44		
488	wbqzu	4		2014-12-10 08:23:44		
489	qywrh	4		2014-12-10 08:23:44		
490	ftfck	4	I forgot comments in my code, invert just multiply each element in the array by -1, The idea is to use find_max_sum also to find the minimun sum interval in a[i:].	2014-12-10 08:23:44		
491	zeice	4	Started throwing some numbers at it. Seems to have some issues.  >>> solve([0, 0, 100, -5, 50]) [145, 145, 145, 45, 50, -inf] 150 >>> solve([0, 0, 100, -5, 50, -1000]) [145, 145, 145, 45, 50, -1000, -inf] 1145 >>> solve([1, 100, -5, 50, -1000]) [146, 145, 45, 50, -1000, -inf] 1145	2014-12-10 08:23:44		
492	vanul	4	Will the following solution work?  1. Find maxsubsequence sum M1 (using Kadane's algorithm) 2. Negate the whole array and find again maxSubsequenceSum M2 3. M1 + M2 should be the absolute max difference. [M1 and M2 must be appearing in disjoint contiguous subarrays, for if they overlap, M1 and -M2 cannot be maximum +ve and maximum -ve values respectively]. and we have a proof by contradiction below]	2014-12-10 08:23:44		
493	azmjc	4	dumbo there can be numbers in the subarrays which are common to both hence they can overlap so I dont think it will work Can you please explain your algo using the example given above	2014-12-10 08:23:44		
494	rdfeo	4	It wont work with the following eg - [4,-1,7] => 1.-> (4,-1,7) 2. -> (1) . But the two subsets overlap	2014-12-10 08:23:44		
495	zeice	4	@LAP, Nice test case. You are right, the range of minimum sum is completely within the range of maximum sum. When I checked using my java code below, the solution I proposed is working fine for the data given in the example. However, I need to think more about your test case.	2014-12-10 08:23:44		
496	dkebi	4		2014-12-10 08:23:44		
497	ethan	4		2014-12-10 08:23:44		
498	bjsiw	4	@LAP, I think the degenerate cases of the minimum sum completely contained in the maximum sum or the maximum sum completely contained in the minimum sum can be handled separately.  Suppose Min is completely contained in Maximum subsum, the the maximum subsum would appear something like  P1 + N + P2, Where P1 is the +ve sum that is to the left of the the minimum sum M and P2 is the +ve sum that is to the right of N.  If P1 > P2 then |P1-N| should give the max absolute diff else it would be |P2-N|  if max subsum is completely contained in min subsum, then the min subsum would appear as  N1 + P + N2. Where N1 is the -ve sum that is to the left of the the maximum sum P and N2 is the -ve sum that is to the right of P.  if N1 > N2 then |N1-P| should be the maximum sum else |N2-P|  The min and max subsums can't overlap, for if they overlap, you can arrive at a proof by contradiction by splitting the sum of numbers into three parts: N + O + M Where N is the sum of the minimum subset excluding the overlapping part. O is the sum of the overlapping part S is the sum of the maximum subset excluding the overlapping part  For N+O to be minimum O has to be -ve M + O to be maximum O has to be +ve, a contradiction.	2014-12-10 08:23:44		
499	wbqzu	4	He is expecting O(n) time algorithm	2014-12-10 08:23:44		
500	bexbp	4	1. Find the max continues sum 2. Find the continues min sum 3. return 1-2	2014-12-10 08:23:44		
501	bexbp	4		2014-12-10 08:23:44		
502	qywrh	4		2014-12-10 08:23:44		
503	krxlv	4	Running time is O(n).	2014-12-10 08:23:44		
504	tenuw	4	Making same mistake as others: [4, -1, 7]	2014-12-10 08:23:45		
505	ufdxg	4	Correct. I missed that edge case. I updated the code, how about now? the code above will return 10 for [4,-1,7]	2014-12-10 08:23:45		
506	qywrh	4	Does not work for [2,-1,-2,12,453,-9,2,8]	2014-12-10 08:23:45		
507	rrmeu	4	this is not disjoint	2014-12-10 08:23:45		
508	eucmc	4	What about this: Must the two subarrays be adjacent? Yes, because the part "in between", unless it is 0, can contribute to either subarray, making it more optimal.  If so, then let's find a split point defining subarrays A[0,i] and A[i+1,n], such that the maximal subarrays (spanning together over whole A) give the optimal absolute difference of sums, that can be easily done O(n).  Now, here comes an interesting bit. You can prove that the optimal global solution are possibly trimmed subarrays found in the first step. In other words, you cannot find the global optimal solution by trimming subarrays, which do not optimize the first step criterion.  And so, without further ado, to find the optimum solution we have to possibly trim one or both of the subarrays, or "expanding" subarrays starting from one-element subarrays on the left hand side and right hand side of a split point found in the first step, and this is done in O(n).  So final time complexity O(n), space complexity O(1).	2014-12-10 08:23:45		
509	ftfck	4	can u give an example where an element is making both the subsets optimal?	2014-12-10 08:23:45		
510	cfzie	4	won't work for [-6,5,-7,2]. the split point between 5 and -7 won't be found because with out trimming it less than other split points.	2014-12-10 08:23:45		
511	wbqzu	4	-4 3 -1 1 2 2 2	2014-12-10 08:23:45		
512	plapd	4	#include<stdio.h> void main() { int a[]={2,-1,-2,1,-4,2,8},n=sizeof(a)/sizeof(int),max[n],min[n],max_max,min_min,i=0; max[0]=min[0]=max_max=min_min=a[0]; for(i=1;i<n;i++) { max[i]=(max[i-1]+a[i])>a[i]?max[i-1]+a[i]:a[i]; max_max=max[i]>max_max?max[i]:max_max; min[i]=(min[i-1]+a[i])<a[i]?min[i-1]+a[i]:a[i]; min_min=min[i]<min_min?min[i]:min_min; } printf("%d\n",max_max-min_min); } Is this ok? it will work in O(n). Are we supposed to identify the subsets also or need to print the difference only?	2014-12-10 08:23:45		
513	dkebi	4	@Anonymous: check for input [4,-1,7]	2014-12-10 08:23:45		
514	bjsiw	4	this wont work for [4 -1 7]	2014-12-10 08:23:45		
515	qywrh	4	An O(n) solution by finding maximum subsequences using Kadane's algorithm  1. Find maxsubsequence sum M1 2. Negate the whole array and find again maxSubsequenceSum M2 3. M1 + M2 should be the absolute max difference. [M1 and M2 must be appearing in disjoint contiguous subarrays, for if they overlap, M1 and -M2 cannot be maximum +ve and maximum -ve values respectively. and we have a proof by contradiction above] 4. Separately handle degenerate cases such as 1) the maximum subsum being contained in the minimum subsum and 2) vice versa  Full working implementation in java is below. Provide Input to the program as: 4 -1 7 -4 1 -7 -9 -4 1 2 -5 -7 -8 9 4 -1 -2 5 7 8	2014-12-10 08:23:45		
516	zeice	4		2014-12-10 08:23:45		
517	zeice	4		2014-12-10 08:23:45		
518	sqzqo	4	doesnt work for 1, 2, 3, 4, 5	2014-12-10 08:23:45		
519	nwkeg	4	@Anonymous  What result do you expect for this test case?	2014-12-10 08:23:45		
520	nwkeg	4	2+3+4+5-1=13	2014-12-10 08:23:45		
521	admin	4	Haha. Ain't the difference (2+3+4+5+1) - 0 = 15 greater than 13? Lol.	2014-12-10 08:23:45		
522	dkebi	4		2014-12-10 08:23:45		
523	nhibd	4		2014-12-10 08:23:45		
524	xhgls	4	The code for this problem is given below.You can consider the following approach: a.Find maximum continuous sub-array sum using kadane's algorithm. b.Similarly find minimum continuous sub-array sum using the same approach. c.Find the difference between the maximum and minimum element.	2014-12-10 08:23:45		
525	vanul	4		2014-12-10 08:23:45		
526	bexbp	4		2014-12-10 08:23:45		
527	fowai	4	Hi  this wont work for numbers which are all negative {-1,-3,-5,-2,-1,-4}	2014-12-10 08:23:45		
528	bexbp	4	@DashDash i have edited the code it will work now..	2014-12-10 08:23:45		
529	huiqq	4	I think it will not work for this, try it out {2, -3, 5} and is 5 but your maxSumArray will give 4,	2014-12-10 08:23:45		
530	tenuw	4	It is working for every possible case..you can paste it and check it gives 5 not 4..and plzz first test it then you can comment for the correction..	2014-12-10 08:23:45		
531	rdfeo	4	For handling with only negative numbers in an array I have added a seperate function for that you can check it..	2014-12-10 08:23:45		
532	rrmeu	4	you check your program for : {1,1,-1,-1} it gives 1, not 4.. :)	2014-12-10 08:23:45		
533	huiqq	4	So this is what I got, there are no error checking which is obviously bad but I assume we are all coding and making suggestions for valid entries primarily so keep that in mind:	2014-12-10 08:23:45		
534	wbqzu	4		2014-12-10 08:23:45		
535	ethan	4		2014-12-10 08:23:45		
536	admin	4	O(n) solution can be found at sites.google.com/site/spaceofjameschen/home/array/find-two-disjoint-contiguous-sub-arrays-such-that-the-absolute-difference	2014-12-10 08:23:45		
537	rdfeo	4	this does not give right answer for [4 -1 7]	2014-12-10 08:23:45		
538	jippy	4	While thinking over this problem I just realized that maximum and minimum subarrays can overlap in only two scenarios: 1) When sum of the common numbers is zero. If sum of common sequence would have been +ve then it would have been part of maximum subarray and not of minimum subarray. Vice verse for -ve sum for common subarray. 2) One subarray is part of other. For example 10, 9, -1, -2, 10 10  Based on the above two possiblilities 1) Find maximum subarray 2) Find minimum subarray 3) If common subarray is zero then it can go either on maximum or minimum side. 4) If one subarray is part of other then find left and right part (non overlapping) of larger subarray and find the difference between this larger part and common elements.  Hence the complexity of this algo is same as finding maximum/minimum subarray problem.	2014-12-10 08:23:45		
539	admin	4	4) is not a possibility. The min and max subarrays can either share only 0 as a common boundary or either of them can be present entirely in the other. See my proof by contradiction up in the post.	2014-12-10 08:23:45		
540	zeice	4	I could not get your point. As I understand, you are saying that point 4 is not correct. You say that max and min subarrays share only 0 as a common boundary or one of them is completely part of other. Even I am saying the same thing as you can see from the example I mentioned previously : 10, 9, -1, -2, 10, 10  Where max subarray is 10, 9, -1, -2, 10, 10 ans min subarray is -1, -2 which is part of max subarray.  If I misunderstood you point please provide me example here.	2014-12-10 08:23:45		
541	tenuw	4	#include <algorithm> using namespace std; int computMaxDiff(int *array,int len) { int *maxarray=new int[len]; int *minarray=new int[len]; maxarray[0]=array[0]; minarray[0]=-array[0]; int currentmax=maxarray[0]>0?array[0]:0; int currentmin=minarray[0]>0?minarray[0]:0; for(int i=1;i<len;i++) { currentmax+=array[i]; //max maxarray[i]=max(currentmax,maxarray[i-1]); if(currentmax<0) currentmax=0;  currentmin+=-array[i]; // max of -array minarray[i]=max(currentmin,minarray[i-1]); if(currentmin<0) currentmin=0; }  for (int i=0;i<len;i++) //min of array minarray[i]=-minarray[i];   int *revmaxarray=new int[len]; int *revminarray=new int[len]; revmaxarray[len-1]=array[len-1]; revminarray[len-1]=-array[len-1]; int revcurrentmax=revmaxarray[len-1]>0?revmaxarray[len-1]:0; int revcurrentmin=revminarray[len-1]>0?revminarray[len-1]:0; for(int i=len-2;i>=0;i--) { revcurrentmax+=array[i]; revmaxarray[i]=max(revcurrentmax,revmaxarray[i+1]); if(revcurrentmax<0) revcurrentmax=0;  revcurrentmin+=-array[i]; revminarray[i]=max(revcurrentmin,revminarray[i+1]); if(revcurrentmin<0) revcurrentmin=0; }  for (int i=0;i<len;i++) revminarray[i]=-revminarray[i];  int maxdiff=0; for (int i=0;i<len;i++) { int currMax=max(abs(maxarray[i]-revminarray[i]),abs(minarray[i]-revmaxarray[i])); if(currMax>maxdiff) maxdiff=currMax; }  return maxdiff; } int _tmain(int argc, _TCHAR* argv[]) { int array[5]={-3,4,-1,4,5}; int maxdiff=computMaxDiff(array,5); return 0; }	2014-12-10 08:23:45		
542	wbqzu	4	step 1 : find the sum of whole array. assign it TotalSum O(n) step 2 : Lets have a few variables SumFromBegining=0, SumFromEnd=TotalSum, MaxDifference=0, MaxDifferenceSplitIndex=0. all these are integers or long ---O(1) step 3 : Iterate through the array from beginning to end. for each iteration you need need to do the following 1. add the current array element ie. array[i] to SumFromBegining 2. subtract the current array element ie. array[i] from SumFromEnd 3. Difference=absolute(SumFromEnd-SumFromBegining) 4. if Difference > MaxDifference then MaxDifference=Difference and MaxDifferenceSplitIndex=i  now this process is of O(n)  After the iteration array[0 to MaxDifferenceSplitIndex ] and array[MaxDifferenceSplitIndex+1 to n] are the answer.  this is a solution with O(n)  hope i did not make a mistake..:-)	2014-12-10 08:23:45		
543	sgiwy	4	I've been through all of these solutions and correct me if i'm wrong, but i think absolutely none of them work for all possible cases. There's one or two which work, but they aint 0(n).	2014-12-10 08:23:45		
544	bjsiw	4	Loler's solution should work in O(n) and for all possible cases if implemented correctly.  The code posted in a comment to that answer was posted by someone else, and I have not verified it. People seem to have found some issues with it. But these are implementation issues, not problems with the idea.	2014-12-10 08:23:45		
545	huiqq	4	for this problem finding maximum and minimum contiguous don't work. for example consider this two test case: 1)array=[-6, 3, 5, 4, -1, -7, 17, 8] in this case maxSum=25 and minSum=-8 if we search disjoint contiguous subarray. so the absolute difference is equal 33. however, the max difference is 35 if we separate [-6] and [3, 5, 4, -1, -7, 17, 8]. sum1=-6, sum2=29 so difference is 35. 2)array=[4, -1, 5] the same above maximum absolute difference between two disjoint contiguous subarray is 6.[-1] and [5].	2014-12-10 08:23:45		
546	zeice	4	1. Given an array, find the following max/min continuous array: - left_min_array: continuous max array - left_max_array: continuous min array - right_min_array: reverse the array, calculate the continuous max array, reversed again - right_max_array: reverse the array, calculate the continuous min array, reversed again 2. Iterate the array, find the maximum among the following four integers: - abs(left_min_array[i]) + abs(right_min_array[i+1]) - abs(left_min_array[i]) + abs(right_max_array[i+1]) - abs(left_max_array[i]) + abs(right_min_array[i+1]) - abs(left_max_array[i]) + abs(right_max_array[i+1]) And store the largest result in an array, let's call result 3. The maximum difference is the max element in the result array  Code is attached at the end, following are the test cases: - {2,-1,-2,12,453,-9,2,8} - {7,-1,4} - {1,2,3,4,5} - {-1,-3,-5,-2,-1,-4}	2014-12-10 08:23:45		
547	zeice	4		2014-12-10 08:23:45		
548	ewigy	4		2014-12-10 08:23:45		
549	ftfck	4	step 1 : find the sum of whole array. assign it TotalSum O(n) step 2 : Lets have a few variables SumFromBegining=0, SumFromEnd=TotalSum, MaxDifference=0, MaxDifferenceSplitIndex=0. all these are integers or long ---O(1) step 3 : Iterate through the array from beginning to end. for each iteration you need need to do the following 1. add the current array element ie. array[i] to SumFromBegining 2. subtract the current array element ie. array[i] from SumFromEnd 3. Difference=absolute(SumFromEnd-SumFromBegining) 4. if Difference > MaxDifference then MaxDifference=Difference and MaxDifferenceSplitIndex=i  now this process is of O(n)  After the iteration array[0 to MaxDifferenceSplitIndex ] and array[MaxDifferenceSplitIndex+1 to n] are the answer.  this is a solution with O(n)	2014-12-10 08:23:45		
550	xhgls	4	here's a O(n) solution:	2014-12-10 08:23:45		
551	huiqq	4		2014-12-10 08:23:45		
552	admin	4		2014-12-10 08:23:45		
553	krxlv	4	finished going through all the posts on here. :) Seems like my implementation is closest to what Loler suggested in C. Only difference is I am using two DA and each maintains structure that keeps track of max and min for the interval.	2014-12-10 08:23:45		
554	nhibd	4	Can anybody comment on my approach . 1. find the max sum subsequence using DP. Store the sum and store the subsequence. Replace those elements by INT_MAX. 2. find the min sum subsequence using DP. store the sum and subsequence 3. Now calculate the difference, and print those sets. I think there is no way this subsets will overlap.  This is O(n) solution since steps 2 and 3 takes O(n) in DP.	2014-12-10 08:23:45		
555	zeice	4	WTH are you talking about	2014-12-10 08:23:45		
556	xhgls	4		2014-12-10 08:23:45		
557	zeice	4		2014-12-10 08:23:45		
558	nwkeg	4		2014-12-10 08:23:45		
559	xhgls	4		2014-12-10 08:23:45		
560	ethan	4	}	2014-12-10 08:23:45		
561	fowai	4	I came across this problem and thought about this and came up with the possible solution. I am unable to find cases in order to fail this solution. Can someone please enumerate a set for the same?  My algorithm:  1.Calculate the continuous sum of all elements while going from 1 to n and store them in an array . Do the same while going from n to 1 2. In the first array mark a point which has minimum value and which has maximum value . Do the same for the second array 3. Check for four scenarios. a) Break array just after array 1 has hit a minimum value b) Break array just before array 1 has hit a max value c) Break array just before array 2 has hit a minimum value d) Break array just after array 2 has hit a max value 4. Max of (a,b,c,d) from above is the answer  Example: Array : 10,1,3,-10,2  Array 1: 10,11,14,4,6 Max: 14 Min: 4 Array 2: 6,-4,-5,-8,2 Max: 6 Min: -8 a) Break after Min:4 i.e Break after -10 in Array . Absolute Diff is 2 b) Break before Max:14 i.e Break before 3 in Array . Absolute Diff is 16 c) Break after Max:6 i.e Break after 10 in Array . Absolute Diff is 14 d) Break before Min: -8 i.e Break before -10 in Array . Absolute diff is 22  Max(a,b,c,d) = 22  Solution complexity is O(n)	2014-12-10 08:23:45		
562	xhgls	4	I came across this problem and thought about this and came up with the possible solution. I am unable to find cases in order to fail this solution. Can someone please enumerate a set for the same?  My algorithm:  1.Calculate the continuous sum of all elements while going from 1 to n and store them in an array . Do the same while going from n to 1 2. In the first array mark a point which has minimum value and which has maximum value . Do the same for the second array 3. Check for four scenarios. a) Break array just after array 1 has hit a minimum value b) Break array just before array 1 has hit a max value c) Break array just before array 2 has hit a minimum value d) Break array just after array 2 has hit a max value 4. Max of (a,b,c,d) from above is the answer  Example: Array : 10,1,3,-10,2  Array 1: 10,11,14,4,6 Max: 14 Min: 4 Array 2: 6,-4,-5,-8,2 Max: 6 Min: -8 a) Break after Min:4 i.e Break after -10 in Array . Absolute Diff is 2 b) Break before Max:14 i.e Break before 3 in Array . Absolute Diff is 16 c) Break after Max:6 i.e Break after 10 in Array . Absolute Diff is 14 d) Break before Min: -8 i.e Break before -10 in Array . Absolute diff is 22  Max(a,b,c,d) = 22  Solution complexity is O(n)	2014-12-10 08:23:45		
563	cfzie	4	I think Loler is right, the algorithm could be implemented in O(n), and here is my code:	2014-12-10 08:23:45		
564	eucmc	4		2014-12-10 08:23:45		
565	nwkeg	4		2014-12-10 08:23:45		
566	krxlv	4	sites.google.com/site/spaceofjameschen/home/array/find-two-disjoint-contiguous-sub-arrays-such-that-the-absolute-difference	2014-12-10 08:23:45		
567	huiqq	4	i am assuming the minimum sum of a sub array is negative or empty. and that the maximum sum of a sub array is positive or empty. the problem can be defined as follow: 1. Find the max sub sum 2. Find the min sub sum  if they do not intersect return their difference; otherwise check if the min sub sum is starting after the max sub sum:  [maxSubSumStart ---------- minSubSumStart ----------------MinSubSumEnd--------maxSubSumEnd]  I want to prove that if intersection is not allowed then either the left max sub sum or the right sub sum is the largest sub sum. In this case each side of minSubSumArray is larger than the absolute value of minSubSumArray (otherwise their sum is below 0 and we would have taken only one part). assume the left sub array is the bigger one. That implies that it is also the biggest sub array in the array (because any other max sub array that wasn't added to the current max array, wasn't added because it is smaller (absolute value)than some minimum sub array, and therefore it is smaller then the minimum sub array and therefor smaller then the left and right parts of the maxsub array.  Therefore the result would be: max sub is the left side of the max array, and the min sub is the minimum sub array.  the same logic is true also in case the max array start in the middle of the min array  this is the code , i still need to do some re-factoring and also I might have some indexing issues:	2014-12-10 08:23:46		
568	mrjku	4		2014-12-10 08:23:46		
569	fmzze	4		2014-12-10 08:23:46		
570	azmjc	4	1. Find the cumulative sum for 0<=i<n and store sum in cumulative[ ] 2. Find j, such that abs(cumulative[ j ] - cumulative [n-1]) is maximum 3. 0 to j is one subarray and j+1 to n-1 is the other subarray	2014-12-10 08:23:46		
571	admin	4	This solution should work for cases: 1 - compute kadane as follow: var kadane = function (arr, k, j, isMin) which should return min/max sum (according to isMin flag) for the arr elements starting at k index and end (inclusive) at j index. return value should be an object that includes the sum, start index, end index. 2 - find max when k==0 and j==arr.length-1. let's call it MAX and assume it has startIndex==si and endIndex==ei; 3 - find min when k==0 and j==arr.length-1. let's call it MIN and assume it has startIndex==si and endIndex==ei; 4 - for the output of 2 MAX - find min on the right side of it using k==MIN.endIndex+1 and j==arr.length and on the left side of it using k==0 and j==MIN.startIndex-1 (if possible and out of arr indexes). 5 - do the as in 4 step for the MIN (find max on both sides of it). 6 - out of the result in 4 and 5 take the highest and lowest among the two and calculate the range of them with MAX and MIN respectively. 7 - among the two pairs from step 6 - MIN and a max on its left/right and MAX and a min on its left/right choose the pair with the higher range and return it.	2014-12-10 08:23:46		
572	nhibd	4		2014-12-10 08:23:46		
573	dgjji	4		2014-12-10 08:23:46		
574	fmzze	4	My solution in C++ (based on the same idea as some other answers with O(n) running time) :	2014-12-10 08:23:46		
575	bjsiw	4		2014-12-10 08:23:46		
576	ethan	4		2014-12-10 08:23:46		
577	ufdxg	4	If there are 2 elements in the array, or all the elements are zero, the solution is really trivial. If there are less than 2 elements, there is no solution.  If all the numbers are non-negative, the problem is completely different from if you have both signs, all positive is somewhat easier. The smaller sub-array will contain only 1 element, and the larger subarray will contain either the front or the back. Start with the front of the array being the 'large' value and the second item being 'small', we store this as our 'current optimum'. Now add the 2nd item to 'large' and call the next element 'small'; if this is better than our first solution, we store it as our current optimum. We go through the array forwards the whole way through, then we do the same thing going backwards. The optimal solution we find after both passes is the optimal solution. This solves in order n (3 passes through n elements). The same logic works if all the elements are 0 or negative.  If we have both positive and negative numbers, create a 2nd array (partioned array) 'partitioning' every positive and negative sequence: 2 -1 -2 1 -4 2 8 becomes [2] [-3] [1] [-4] [10]. I am pretty sure this is the right direction, but from here on out, I bet someone (possibly me with more time) comes up with something better than I have following.   Now create yet another array combining all the negative elements if and only if their sum is less than the number between them. Repeat this process until you cannot. So you get [-6] in this example. Now create yet another array doing this with the positive values, giving you [2][1][10]. The largest of the positive and smallest negative are the solution if we can ignore the requirement the arrays do not overlap, and the solution if they do not overlap. So far, we've done nothing beyond order n. If they overlap, we can find a place to split the segment that overlaps fairly easily, and this is almost always the correct solution, but you can come up with examples where it is not. I think going back to our partioned array and finding other combinations is the trick, but cannot think of better than n^2 way to do that.   Of course, you need to store a bit more to go back and find the array indexes, but that is trivial so I left it out.	2014-12-10 08:23:46		
578	xhgls	4	Based upon comments above, I have written following code.  { public class DisjointSubarraysLinearTime { public static void main(String[] args) { int[] input = {2, -1, -2, 1, -4, 2, 8}; System.out.println("diff: " + getDifference(input)); } public static int getDifference(int[] a) { int[] MAX = new int[a.length]; int[] MIN = new int[a.length]; int result = Integer.MIN_VALUE; setMinMaxArrays(a, MIN, MAX); for (int i = 0; i < a.length-1; i++) { result = Math.max(result, Math.abs(MAX[i] - MIN[i+1])); } for (int i = 0; i < a.length; i++) { a[i] = -a[i]; } setMinMaxArrays(a, MIN, MAX); for (int i = 0; i < a.length-1; i++) { result = Math.max(result, Math.abs(MAX[i] - MIN[i+1])); } return result; } public static void setMinMaxArrays(int[] a, int[] MIN, int[] MAX) { MAX[0] = a[0]; int maxEndingHere = a[0]; for (int i = 1; i < a.length; i++) { if (maxEndingHere < 0) { maxEndingHere = a[i]; } else { maxEndingHere += a[i]; } MAX[i] = Math.max(maxEndingHere, MAX[i-1]); } MIN[a.length-1] = a[a.length-1]; int minEndingHere = a[a.length-1]; for (int i = a.length - 2; i >= 0; i--) { if (minEndingHere > 0) { minEndingHere = a[i]; } else { minEndingHere += a[i]; } MIN[i] = Math.min(minEndingHere, MIN[i+1]); } } } }	2014-12-10 08:23:46		
579	dgjji	4	Based upon comments above, I have written following code(formatted):	2014-12-10 08:23:46		
580	ethan	4		2014-12-10 08:23:46		
581	cfzie	4		2014-12-10 08:23:46		
582	rrmeu	4	I won't prove it, but it's true that you can find the max or min subsequence of an array in O(n) time and space.  Assuming that's true, compute the max and min subarrays. If they don't overlap, then you have your answer.  What if they do overlap?  If they overlap in the middle (e.g. [1, 5], [3, 10] overlap at [3, 5]), observe that if we remove the overlapping part from both (max and min) subarrays, that that will not change the absolute value of the difference of their sums.  WLOG, assume the min sequence contains the max sequence. Then, our disjoint max sequence will be *the* max sequence, and our disjoint min sequence will be either the left or right part that borders the inner max--return the side with smaller (more negative) sum.  It's a bit more involved to prove that the smaller side of the containing subsequence will still be the right one, but if you try and fail to find a counterexample, you'll see why.	2014-12-10 08:23:46		
583	bexbp	4		2014-12-10 08:23:46		
584	sqzqo	4		2014-12-10 08:23:46		
585	zeice	4	This solution in python is short, O(n), I hope this will help u.	2014-12-10 08:23:46		
586	plapd	4		2014-12-10 08:23:46		
587	vanul	4		2014-12-10 08:23:46		
588	mrjku	4		2014-12-10 08:23:46		
589	wbqzu	4		2014-12-10 08:23:46		
590	sgiwy	4	the sets must consist of consecutive integers.	2014-12-10 08:23:46		
591	bjsiw	4	This problem can be divided into 2 subproblems: 1. Find a subset whose sum is maximum, it is O(n) algorithm 2. Find a subset whote sum in min, it is O(n) algorithm. 3. Also verify that solution from step 1 and step 2 dont overlap (they will not). Find the absolute difference between subsets find in steps1 and steps2 and take their absolute difference.	2014-12-10 08:23:46		
592	ewigy	4	Proof of the assertion that they will not overlap is missing from this post...  Example:  [-1 0 1]  One subarray with minimum sum is [-1 0] and one with maximum sum is [0 1], and yet they overlap.  Note: You talked about finding "a" subset and do not give a method to choose [-1] over [-1 0].	2014-12-10 08:23:46		
593	jippy	4	[4, -1, 7]  max - [4, -1, 7] and min [-1]. It completely overlaps.	2014-12-10 08:23:46		
594	zeice	4	@Anonymous: First off, a decent algorithm would never include 0 in the subsets if 0 is a boundary of interval, so the minimum sum and maximum sum subsets would be {-1} and {1} respectively and not {-1,0} and {0, 1}.  Secondly. the minimum sum subarray and maximum sum subarray can't overlap. they can however contain in each other completely. Proof: Proof is by contradiction: Suppose that they overlap: split the sum of numbers into three parts: N + O + M Where N is the sum of the minimum subset excluding the overlapping part. O is the sum of the overlapping part S is the sum of the maximum subset excluding the overlapping part  For N+O to be minimum O has to be -ve M + O to be maximum O has to be +ve, a contradiction.	2014-12-10 08:23:46		
595	rrmeu	4	@Dumbo: Huh? What is the definition of "decent"? Even the wiki page on max-sum subarray problem has C++ code which will return [0, 1] and [-1, 0]. Check it out. (the code to give the exact subarray is commented).  Didn't read the rest of your post, but [4, -1, 7] is good enough to smash googlybhai's assertions (noted elsewhere in this thread).	2014-12-10 08:23:46		
596	nhibd	4	@LAP what is the correct answer for [4, -1, 7]?  Is it (7) - (-1) = 8 or (4, -1, 7) - (empty set) = 10?	2014-12-10 08:23:46		
597	admin	4	I can be done using kandane. For maximum difference we need to find minimum contiguous sub array and maximum contiguous sub array. Then find the start and end index of both array and make sure they both are not colliding with each other if they are colliding then take maximum difference by including it into minimum subset and maximum subset.	2014-12-10 08:23:46		
598	rrmeu	4	It can be done using kandane. For maximum difference we need to find minimum contiguous sub array and maximum contiguous sub array. Then find the start and end index of both array and make sure they both are not colliding with each other if they are colliding then take maximum difference by including it into minimum subset and maximum subset.	2014-12-10 08:23:46		
599	nwkeg	4	onestopinterviewprep.blogspot.com/2014/03/namespace-arrayproblem-write-function.html	2014-12-10 08:23:46		
600	azmjc	4	Is the exhaustive algo O(2^n * n) where n is # of digits in original set? Thats because you could make 2^n different pairs of subsets, and for each pair, you do sums of O(n).  I wonder if you could sort the origianal set and then walk up the sorted list, splitting it at each of the N points (forming the two subsets) and computing the difference of each of these subsets at each step, looking for the max? If so, you could optimize the sum, as you are just adding one new value to the sum of the first and removing it from the sum of the second.	2014-12-10 08:23:46		
601	dkebi	5	This can be done in O(nlogn) using divide and conquer scheme. Before starting the algorithm, please see the following observation:  Observation: given an array A, say [1, -2, ..., 4], with n elements, we can get the inverse of A, denoted as A (4, ..., -2, 1), in \theta(n) time with O(1) space complexity.  The basic idea of the algorithm is as follows: 1. We recursively sort two smaller arrays of size n/2 (here sort is defined in the question) 2. Then we spend \theta(n) time merging the two sorted smaller arrays with O(1) space complexity. How to merge? Suppose the two sorted smaller array is A and B. A1 denotes the negative part of A, and A2 denotes positive part of A. Similarly, B1 denotes the negative part of B, and B2 denotes positive part of B. 2.1. Compute the inverse of A2 (i.e., A2) in \theta(|A2|) time; compute the inverse of B1 (i.e., B1) in \theta(|B1|) time. [See observation; the total time is \theta(n) and space is O(1)] Thus the array AB (i.e., A1A2B1B2) becomes A1A2B1B2. 2.2. Compute the inverse of A2B1 (i.e., B1A2) in \theta(|A2|) time. [See observation; the total time is \theta(n) and space is O(1)] Thus the array A1A2B1B2 becomes A1B1A2B2. We are done.  Time complexity analysis: T(n) = 2T(n/2) + \theta(n) = O(nlogn)	2014-12-10 08:23:59		
602	ftfck	5	Time: O(N), Space O(N)	2014-12-10 08:23:59		
603	gilit	5		2014-12-10 08:23:59		
604	ftfck	5		2014-12-10 08:23:59		
605	rrmeu	5	@Jason, I like this. Simple and O(n log n). I researched web and nobody claims to have O(n) time and O(1) space algorithm.	2014-12-10 08:23:59		
606	eucmc	5	Why O(nlogn) solution when you are using O(N) extra space? If you are given O(N) extra space then you can do it in O(N) time.  1. Scan the input array and count no. of positive elements (countP) and negative elements (countN). 2. Populate output array (extra space) . scan input array from left to right for i = 0 to i = size-1. 3. if arr[i] > 0 then output[countN] = arr[i]; countN++ 4. if arr[i] < 0 then output[countP] = arr[i]; countP++  Please take care of boundary cases when there are no -ve or +ve elements in the array.	2014-12-10 08:23:59		
607	ewigy	5	@Jason. I like your three-reversion solution.	2014-12-10 08:23:59		
608	azmjc	5	Time O(N) and space O(1)	2014-12-10 08:23:59		
609	jippy	5		2014-12-10 08:23:59		
610	xhgls	5		2014-12-10 08:23:59		
611	rrmeu	5	@doug, if you have an array like this {1, 2, 3, 4, 5, -5, -4, -3, -2, -1}  Time is (N^2) for worse case, but still a good solution.	2014-12-10 08:23:59		
612	eucmc	5	please let me know if this has any prob ?  /* ============================================================================ Author : novice_programmer  Description : Given an array which has n integers. It has both positive and negative integers.Now you need to sort this array in such a way that,the negative integers should be in the front,and the positive integers should at the back.Also the relative position should not be changed. eg. -1 1 3 -2 2 ans: -1 -2 1 3 2.Required running time complexity is O(N) and the space complexity is O(1) Created Date : 26-JAN-2014 =========================================================================== */ #include<stdio.h>   void sort_array(int arr[],int n) { int count =0; int temp1=0; int pos_to_fill_with_positive_num=0; int pos1=0; int pos2=0; int just_moved =0; int num_remaining=0;  for(int i=0;i<n;i++) { if(arr[i]<;0) { count++; } } pos1 = count; num_remaining=count; for(int i=0;i<n;i++) { if(arr[i]<;0) { temp1=arr[pos2]; arr[pos2]=arr[i]; arr[i]=temp1; pos2++; if(pos1>=i && i>count) {pos1++; just_moved=1; }  num_remaining--; } else { if(pos2==count) break; else if((i>=count) && (i<pos1) &&(!just_moved)) continue; else if(just_moved) { just_moved=0; temp1=arr[i]; arr[i]=arr[pos2]; arr[pos2]=temp1; } else {  if(i<count) { temp1=arr[pos1]; arr[pos1]=arr[i]; if((pos_to_fill_with_positive_num>=pos2)&&(pos_to_fill_with_positive_num<count)) arr[pos_to_fill_with_positive_num]=temp1; else if(pos_to_fill_with_positive_num<count) arr[++pos_to_fill_with_positive_num]=temp1; else { pos_to_fill_with_positive_num=pos2; arr[pos_to_fill_with_positive_num]=temp1; } pos_to_fill_with_positive_num++; pos1++; } else { temp1=arr[pos1]; arr[pos1]=arr[pos_to_fill_with_positive_num]; arr[pos_to_fill_with_positive_num]=temp1; pos_to_fill_with_positive_num++; pos1++; } } }  if(num_remaining==0) break; } }  void main() { int n = 9; int arr[9]={-1,1,3,4,6,-3,1,-2,2}; //int arr[7]={-1,3,-2,4,5,-5,9}; //int arr[5]={-1,1,3,-2,2}; printf("\input array:"); for(int i=0;i<n;i++) printf(" %d ",arr[i]); sort_array(arr,n); printf("\noutput array"); for(int i=0;i<n;i++) printf(" %d ",arr[i]);  }	2014-12-10 08:23:59		
613	vanul	5	There is a paper showing O(n) time and O(1) space algorithm "Stable minimum space partitioning in linear time." This shouldn't be an interview question.  diku.dk/hjemmesider/ansatte/jyrki/Paper/KP92b.pdf	2014-12-10 08:23:59		
614	jippy	5	You shouldn't use recursion otherwise the required space won't be O(1). If you implement the same method iteratively it would be O(1) space though.	2014-12-10 08:23:59		
615	sgiwy	5	@varun merge can be done in place, so this is a O(1) space solution if we do not consider function call stack.	2014-12-10 08:23:59		
616	sgiwy	5	public int[] negSort(int[] data) { int negCount = 0; int[] sorted = new int[data.Length];  for (int i = 0; i < data.Length; i++) { if (data[i] < 0) { sorted[negCount++] = data[i]; } }  for(int i=0; i< data.Length; i++) { if (data[i] > 0) sorted[negCount++] = data[i]; }  return sorted; }	2014-12-10 08:23:59		
617	mrjku	5	If there is no repetitions then binary search tree with pre-order traversal will deliver. Again space is the con.	2014-12-10 08:23:59		
618	admin	5	I really like your idea of divide and conquer. However, instead of your merging algorithm I used bubbling of positive integers from the left part to the right. I believe the space complexity is O(1), however, I really don't know the time complexity.	2014-12-10 08:23:59		
619	jippy	5		2014-12-10 08:23:59		
620	sgiwy	5		2014-12-10 08:23:59		
621	dkebi	5	O(nlogn) average case time, O(1) space solution:	2014-12-10 08:23:59		
622	zeice	5		2014-12-10 08:23:59		
623	ufdxg	5		2014-12-10 08:23:59		
624	zeice	5	I didn't analyze it any further, anyone with an idea about worst case complexity?	2014-12-10 08:23:59		
625	vanul	5	I think it is o(nlogn) time.En...this solution is the best here.	2014-12-10 08:23:59		
626	sqzqo	5	Worst case time complexity is O(n^2), where n is the input size.	2014-12-10 08:23:59		
627	tenuw	5	why the worst is o(n^2),Could you give a sample.	2014-12-10 08:23:59		
628	wbqzu	5	Can some one explain what does it mean "relative position should not be changed."? Please also can some one give multiple examples to show how the output should be since the Question is not very clear.  Thanks	2014-12-10 08:23:59		
629	fowai	5	if NlogN, why not using variation of the merge sort?	2014-12-10 08:23:59		
630	krxlv	5	@Rocky, or quicksort for that matter...	2014-12-10 08:23:59		
631	rdfeo	5	merge sort is an option, but how you do stable quicksort without additional space?	2014-12-10 08:23:59		
632	wbqzu	5	@uruk_hai: Stable in-place merge sort exists. Search the web.	2014-12-10 08:23:59		
633	gilit	5	@anonymous: true, but I was referring to quicksort	2014-12-10 08:23:59		
634	zeice	5	Unfortunately, the time complexity in worst case is O(n^2). The formula is: T(n) = O(n) + T(k) + T(n - k), where k is the number of the negatives. So, if there is only one negative, the formula will change to T(n) = O(n) + T(n - 1) + O(1) = T(n -1) + O(n) = O(n^2). eg. 1 2 3 4 5 6 -1	2014-12-10 08:23:59		
635	qywrh	5	This is O(nlogn). but it can be modified in such a way that one part of the recursive tree is already sorted and you have again repeat same algo for another part. for better performance sort longest array(+ve or -ve ) and put in recurrence the other array. eg. if negative count is smaller startSearch = 0; i = first positive index j = first positive index where it supposed to be swap(a[i][, a[j]); if(a[i] < 0){ startSearch = i+1 a[i] = -a[i]; } i = next positive index; j++; if(i == first index positive supposed to){ i = startSearch; }  after this code positive array will be stable in order with only +ve numbers. repeat same for another array where only negative should be but still not in order. the number in this array is again -ve and +ve. use same algo.  thus only one tree computation is happening same as finding nth element in randomized partition.	2014-12-10 08:23:59		
636	nhibd	5	The original uruk post doesn't make sense to me. Could someone explain why it works?	2014-12-10 08:23:59		
637	tenuw	5	Method 1: O(n log(n)) for arrays Too complicated to code but leads to O(n log n) for arrays Start with an array A = [a1 b1 a2 b2 a3 b3 a4 b4 .... ak bk] where ai and bi are subarrays of positive and negative numbers. assume ni = len(ai) and mi = len(bi) Observation: [a1 b1] --> [b1 a1] in O(max(ni, mi)) which is obtained by repeatedly swaping the first, second, ... elements. For ni = mi it is obvious. For ni > mi, do it for the first mi, then ignore the first mi since they are in place, do it [ni - mi, mi] positive ones and put them in order. Repeat until you finish after ni swaps.  So recursively do this: Take [a1 b1 a2 b2] -> [b1 a1 a2 b2] -> [b1 b2 a1 a2] this is done in max(n1, m1) + max(n1 + n2, m2) < 2n1 + n2 + m1 + m2 For k pairs of [ai bi], we find k / 2 new pairs pairs. Reapeat the procedure. Note that in the second run, your new value of n1 is (n1 + n2) from previous step. The same for m1. For k pairs we need the time complexity T(k) = k / 2 * (2n1 + n2 + m1 + m2) + T(k / 2). Put averages here: (E[ni] = E[mi] = n / k. ET(k) = k / 2 * (5 n / k) + ET(k / 2) = 2.5 n + ET(k / 2). For k / 2, the sizes of ni and mi are doubled. So we have ET[k] = 2.5 n + 2.5 n + .... + 2.5 log2(k) times. Then ET[k] = O(nlog(k)). Finally, average over "k". Note that k is O(n) for random arrays. Therefore, the overall complexity = O(n log(n)) Repeat it for all the k / 2 pairs.	2014-12-10 08:24:00		
638	nhibd	5		2014-12-10 08:24:00		
639	fmzze	5		2014-12-10 08:24:00		
640	fmzze	5	Method 2: For arrays, simple code O(n^2)	2014-12-10 08:24:00		
641	eucmc	5		2014-12-10 08:24:00		
642	ufdxg	5		2014-12-10 08:24:00		
643	krxlv	5	Method 3: Data stored in linked list O(n)	2014-12-10 08:24:00		
644	sqzqo	5		2014-12-10 08:24:00		
645	xhgls	5		2014-12-10 08:24:00		
646	gilit	5	import java.util.Arrays;  public class NegativeAndPositive {  private static final int[] array = new int[] { 100, -1, 5, 4, -7, 11, 12, 0, -2, -1, -10, 11, -2 };  public static void main(String[] args) {  for (int i = 0, j = array.length - 1; i < j;) {  if (array[i] < 0) { i++; continue; }  if (array[j] > 0) { j--; continue; }  swap(i, j);  }  System.out.println(Arrays.toString(array));  }  private static void swap(int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; }  }	2014-12-10 08:24:00		
647	bjsiw	5		2014-12-10 08:24:00		
648	ethan	5		2014-12-10 08:24:00		
649	vanul	5	wrong code.. for input array { -1, 1, 3, -2, 2 }, the result is [-1, -2, 3, 1, 2]. Expected result: [ -1, -2, 1, 3, 2, ]	2014-12-10 08:24:00		
650	ftfck	5	Do an in-place partition (i.e. from the quick sort algorithm) on the pivot value 0. However, the partition algorithm is not stable, but we can fix that without too much extra work and constant overhead.  Example:	2014-12-10 08:24:00		
651	rrmeu	5		2014-12-10 08:24:00		
652	nhibd	5		2014-12-10 08:24:00		
653	azmjc	5	By the way, a stable_partition is already implemented in STL if using C++ that does exactly what this question is asking.	2014-12-10 08:24:00		
654	huiqq	5		2014-12-10 08:24:00		
655	bjsiw	5		2014-12-10 08:24:00		
656	zeice	5	If you have to implement the stable_partition manutally, you can always use the STL rotate for the last step!	2014-12-10 08:24:00		
657	fowai	5		2014-12-10 08:24:00		
658	ufdxg	5		2014-12-10 08:24:00		
659	ewigy	5	LOL. "Easy"? Have you even tried doing it yourself, rather than fanning yourself while waving your hands?	2014-12-10 08:24:00		
660	zeice	5	And yeah, -100.	2014-12-10 08:24:00		
661	ewigy	5	O(n) and O(n)	2014-12-10 08:24:00		
662	jippy	5		2014-12-10 08:24:00		
663	dgjji	5		2014-12-10 08:24:00		
664	gilit	5	Nice! This is quite possibly the best solution possible, as doing it with O(1) memory is impossible.	2014-12-10 08:24:00		
665	bexbp	5	Coding with O(n) space and O(n) time is too easy. Let's use A to the original array. Create a new array B.	2014-12-10 08:24:00		
666	tenuw	5		2014-12-10 08:24:00		
667	ufdxg	5		2014-12-10 08:24:00		
668	sqzqo	5	O(n) O(1)!	2014-12-10 08:24:00		
669	sgiwy	5		2014-12-10 08:24:00		
670	azmjc	5		2014-12-10 08:24:00		
671	jippy	5	Nice! Best yet!	2014-12-10 08:24:00		
672	fowai	5	Just Kidding! That's O(n^2) :P	2014-12-10 08:24:00		
673	dkebi	5	right, memmove is O(n) while being in T(n) cycle, so overall is O(n^2).	2014-12-10 08:24:00		
674	rdfeo	5	The n^2 solution would be:  Keep trace of a first met positive number = P. If you find a negative number = N, and P is set, then store P into T, insert value of N into positon P, shift the table right from P to N positon, insert T into P+1.  Can we really do it in O(n) without extra space?	2014-12-10 08:24:00		
675	ftfck	5		2014-12-10 08:24:00		
676	fowai	5	I thought rather bout a single variable.	2014-12-10 08:24:00		
677	gilit	5		2014-12-10 08:24:00		
678	dgjji	5		2014-12-10 08:24:00		
679	huiqq	5	It works fine, but This is n^2. consider the case when all +ve are at front and all -ve are at end	2014-12-10 08:24:00		
680	nhibd	5	This should work. how to compute the time complexity ?	2014-12-10 08:24:00		
681	jippy	5		2014-12-10 08:24:00		
682	ftfck	5		2014-12-10 08:24:00		
683	xhgls	5	That's O(n^2)	2014-12-10 08:24:00		
684	plapd	5	Thanks. But can you please tell me how did you arrive at it ? I always struggle at it.	2014-12-10 08:24:00		
685	wbqzu	5	Take this [1, -1, 2, -2,...,k, -k]  In order to move the first negative to the first position you need to shift 1 positive to the right. Now you get [-1, 1, 2, -2,...k, -k]  To move the second negative to the second postition you need to shift 2 positives to the right. Finally, to shift the kth negative to the kth position you need to shift k positives to the right. In total that is 1 + 2 +... + k = k*(k-1)/2 = O(k^2) = O(n^2) (since k = n/2 ) operations.	2014-12-10 08:24:00		
686	vanul	5	thanks	2014-12-10 08:24:00		
687	azmjc	5	@fire It's very easy for general cases. If u have a single level loop in ur program then it is o(n). If there is a loop inside the loop(2 level), then its O(n^2). If inner loop executes only log n times(approx) then it is O(nlogn). If u hav loop inside loop inside loop then its O(n^3) and so on.	2014-12-10 08:24:00		
688	rrmeu	5	//Author : A.Nasimunni #include<stdio.h> main() { int n; printf("\n\tEnter the length of the array : "); scanf("%d",&n); int a[n],b[n]; int i=0; printf("\n\n\tEnter the elements into array \n"); for(i=0;i<n;i++) {printf("\t\t Enter : "); scanf("%d",&a[i]); } int k=0; for(i=0;i<n;i++) { if(a[i]<0) { b[k]=a[i];k=k+1; } else {k=k;} }   for(i=0;i<n;i++) { if(a[i]>0){b[k]=a[i];k++;}else{k=k;} }  for(i=0;i<k;i++) { printf(" %d",b[i]); } }	2014-12-10 08:24:00		
689	xhgls	5	//Author : A.Nasimunni #include<stdio.h> main() { int n; printf("\n\tEnter the length of the array : "); scanf("%d",&n); int a[n],b[n]; int i=0; printf("\n\n\tEnter the elements into array \n"); for(i=0;i<n;i++) {printf("\t\t Enter : "); scanf("%d",&a[i]); } int k=0; for(i=0;i<n;i++) { if(a[i]<0) { b[k]=a[i];k=k+1; } else {k=k;} }   for(i=0;i<n;i++) { if(a[i]>0){b[k]=a[i];k++;}else{k=k;} }  for(i=0;i<k;i++) { printf(" %d",b[i]); } }	2014-12-10 08:24:00		
690	xhgls	5	import java.util.ArrayList;   class Test {   public static void main(String[] args){  int[] arr = {-1, 1, 3, -2, 2,5,-7,-6}; ArrayList<Integer> list = new ArrayList<Integer>();  for(int i=0;i<arr.length;i++){  if(arr[i]<0){  list.add(arr[i]); } }  for(int i=0;i<arr.length;i++){  if(arr[i]>0){  list.add(arr[i]); } }  System.out.println(list); } }	2014-12-10 08:24:00		
691	zeice	5	space ??? you are using arraylist	2014-12-10 08:24:00		
692	dgjji	5	So you only have to swap the last item in a run of positives or negatives. So you only have to keep an index of the last index of the previous signage run. The following code is O(N) and has O(1) space.  I don't handle the 0 case, because it is unclear what to do with that case.	2014-12-10 08:24:00		
693	zeice	5		2014-12-10 08:24:00		
694	plapd	5		2014-12-10 08:24:00		
695	azmjc	5	Doesn't work for { 11, 1, 3, -2, -5, 2 }; Original: [11, 1, 3, -2, -5, 2] Output: [-2, -5, 3, 11, 1, 2]	2014-12-10 08:24:00		
696	sqzqo	5	public int[] sortInOrder(int[] data){  int pos=0; int negPos=0; for (pos=0;pos<data.length;) {  if(data[pos]>=0){ while(negPos<data.length && data[negPos]>=0 ){ negPos++; }  if(negPos==data.length) break; while(negPos>pos){ int temp=data[negPos]; data[negPos]=data[negPos-1]; data[negPos-1] = temp; negPos--; } } negPos++; pos++;  }  return data; }	2014-12-10 08:24:00		
697	eucmc	5		2014-12-10 08:24:00		
698	ufdxg	5		2014-12-10 08:24:00		
699	jippy	5		2014-12-10 08:24:01		
700	mrjku	5		2014-12-10 08:24:01		
701	fmzze	5	Works but O(n^2). You are swapping each negative value with all positives before it. So, potentially you will do it for all negatives in the input. So, worst case: O(n^2)	2014-12-10 08:24:01		
702	cfzie	5	If 0 exists, partition around it..Otherwise, insert a 0 and then partition around it. Please confirm if it's possible to add a 0 to the array in O(1) space.	2014-12-10 08:24:01		
703	tenuw	5	You don't need to physically add the zero. But it won't work. Remember that this is an array and insertion not possible. You can only swap. Ex: {1 -1 2 -2} turns into {-1 -2 2 1}	2014-12-10 08:24:01		
704	cfzie	5	The conventional partition algorithm isn't stable, so you'll end up ruining the original order of elements, which is a necessary condition for solving this problem. You can make partition stable by using an extra O(n) memory, but that also isn't permitted here.	2014-12-10 08:24:01		
705	nwkeg	5	Code on C#, I think this is O(n)	2014-12-10 08:24:01		
706	plapd	5		2014-12-10 08:24:01		
707	xhgls	5		2014-12-10 08:24:01		
708	fowai	5	Last loop should be	2014-12-10 08:24:01		
709	fmzze	5		2014-12-10 08:24:01		
710	ethan	5		2014-12-10 08:24:01		
711	sqzqo	5	Memory O(n), but O(1) was requested.	2014-12-10 08:24:01		
712	fmzze	5	int main() { int arr[7] = {-1,-1,-3,-3,-2,-2,-8}; int size = sizeof(arr)/sizeof(*arr); cout<<size<<endl; int n=0; for(int i=0;i<size;i++) { if(arr[i]<0) { int temp = arr[i]; int j=i; while(j>n){ arr[j] = arr[j-1]; j--;} arr[n++]= temp;}} for(int i=0;i<size;i++) { cout<<arr[i]<<" "; }  return 0;}	2014-12-10 08:24:01		
713	zeice	5		2014-12-10 08:24:01		
714	xhgls	5		2014-12-10 08:24:01		
715	huiqq	5	you are taking extra space O(n)	2014-12-10 08:24:01		
716	tenuw	5		2014-12-10 08:24:01		
717	cfzie	5		2014-12-10 08:24:01		
718	tenuw	5	The idea here is when we encounter a positive number in the slot we're examining, we find the next negative number, store it in a temp variable, then shuffle over all the positives. Finally, insert the saved negative number into the current slot.  i.e. if we had: [ -1, <1>, 2, 3, 4, -2, ..]  When we encounter the 1, we search forward til we find the index of the -2, and we store that value. We then copy between our current index and that index:  [ -1, <1>, 1, 2, 3, 4, ....]  Then finally insert the saved number into our current location.  [-1, <-2>, 1, 2, 3, 4, ...]  Then we move onto examining the next index.  <strike>This is O(n) in the worst case, because in [3,2,1,-3,-2,-1], we perform n/2 shuffles, where each shuffle swaps at most n/2 elements. n/2 * n/2 = O(n).</strike>  It's actually O(n^2), thanks for the correction lxduan.	2014-12-10 08:24:01		
719	azmjc	5		2014-12-10 08:24:01		
720	dkebi	5		2014-12-10 08:24:01		
721	sqzqo	5	shouldn't it be O(n^2)?	2014-12-10 08:24:01		
722	rrmeu	5	Yep you're right. It's O(n) if you store an extra array with all the indices of negative numbers, but then that's O(n) space. My bad.	2014-12-10 08:24:01		
723	bexbp	5	Same as I thought, actually it can be optimized, the current_index can jump directly to the next_negative_index previously found. For example: [ -1, <1>, 2, 3, 4, -2, -3, ..] suppose after first iteration, we get: [ -1, -2 , 1, 2, 3, 4, -3 ..] then we can let current_index jump to <4> (the position of -2 before swap) directly instead of starting from <1> , and then repeat the iteration.  This is O(n) regardless of the swapping part...	2014-12-10 08:24:01		
724	nhibd	5	we need two arrays ary1, ary2 ; both size of n, for positive values and negative values	2014-12-10 08:24:01		
725	mrjku	5		2014-12-10 08:24:01		
726	bjsiw	5		2014-12-10 08:24:01		
727	azmjc	5	The fact that ary1 and ary2 are built up as we read the target array from bgn to end guarantees that relative positions between values of the same sign would not change	2014-12-10 08:24:01		
728	jippy	5	1.arrange the first half as negative and second half as negative 2.then call quick sort for first half of the array check for abs(i) pos with abs(j) 3.then call quick sort for the second half of the array  the complexity is O(n) for arranging positive and negative numbers and O(nlogn)+O(nlogn) for sorting... still can we have better solution :)	2014-12-10 08:24:01		
729	jippy	5	In worst case quick sort takes o(n^2) time if the recurrence formulae is T(n) = T(n-1) + o(n) so the worst case timing is O(n^2) not O(nlogn)	2014-12-10 08:24:01		
730	admin	5	public class google {  public static void main(String[] args) { int[] a={-1,1,3,-2,2}; int neg=0; int pos=0;  for(int i=0;i<a.length;i++){ if(a[i]<0) neg++; else pos++; }  int countneg=0; int i=0; int j=1; int k=0; int temp=0; while(countneg<neg){ if(a[i]<0){ countneg++; i++; } else{ j=i; k=i; while(a[k]>0){ k++; } temp=a[j]; a[j]=a[k]; for(int z=k;z>j;z--){ a[z]=a[z-1]; } a[j+1]=temp; countneg++; i++; } }  for(i=0;i<a.length;i++){ System.out.println(a[i]); } }  }	2014-12-10 08:24:01		
731	admin	5		2014-12-10 08:24:01		
732	rrmeu	5		2014-12-10 08:24:01		
733	ufdxg	5		2014-12-10 08:24:01		
734	plapd	5		2014-12-10 08:24:01		
735	jippy	5	How is this O(n)? Please explain.	2014-12-10 08:24:01		
736	bjsiw	5	This takes O(n^2) time. You are shifting O(n) positive numbers for each of O(n) negative numbers.	2014-12-10 08:24:01		
737	tenuw	5	#include <stdio.h>  void swapT(int* a,int* b, int *c){ int temp=*c; *c=*b; *b=*a; *a=temp; }  #define N 5  int main(){ int i, pos, mid, neg = 0; int a[] = {-1,1,3,-2,2}; for (i = 0; i < N; i++) printf (" %d ", a[i]); printf ("\n"); int totNeg = 0; for (i = 0; i < N; i++){ if (a[i] < 0) totNeg++; } mid = totNeg; pos = totNeg; while (totNeg > 0){ if (a[neg] < 0){ neg++; totNeg--; } else { while (a[pos] >= 0) pos++; swapT(&a[neg], &a[mid], &a[pos]); neg++; pos++; mid++; totNeg--; } }  for (i = 0; i < N; i++) printf (" %d ", a[i]); printf ("\n");  return 0; }	2014-12-10 08:24:01		
738	qywrh	5		2014-12-10 08:24:01		
739	ftfck	5		2014-12-10 08:24:01		
740	rdfeo	5	My apology, previous code is not work for some special test data, so i edit and add the second one.	2014-12-10 08:24:01		
741	tenuw	5		2014-12-10 08:24:01		
742	dkebi	5		2014-12-10 08:24:01		
743	fowai	5		2014-12-10 08:24:01		
744	ewigy	5		2014-12-10 08:24:01		
745	mrjku	5	} It's O(N) time and (N) memory , i can't find solution with less memory.	2014-12-10 08:24:01		
746	ufdxg	5	public void sortIntegers(int[] intarray) { for(int h=0;h<intarray.length;h++) System.out.print(intarray[h]+ " ");  int lastnegative = 0; for(int i=0; i< intarray.length;i++) { if(intarray[i]<0) { swap(intarray,lastnegative,i); lastnegative = lastnegative+1; } } System.out.println(); for(int m=0;m<intarray.length;m++) System.out.print(intarray[m]+ " ");  } void swap(int[] intarray, int lnegative, int j) { int temp = intarray[j]; for(int k = j-1;k>=lnegative;k--) { intarray[k+1] = intarray[k]; } intarray[lnegative] = temp; }	2014-12-10 08:24:01		
747	mrjku	5	we can also use queue data structure like this in Java public class Sort {  public static void sortArray(int[] a) { int N = a.length; Queue<Integer> q1 = new Queue<Integer>(); Queue<Integer> q2 = new Queue<Integer>();  for (int i = 0; i<N; i++) { if(a[i] < 0 ) q1.enqueue(a[i]); else q2.enqueue(a[i]); } int i = 0; while (!q1.isEmpty()) a[i++] = q1.dequeue(); while(!q2.isEmpty()) a[i++] = q2.dequeue();  }  public static void main(String[] args) { int[] a = {-1,1,3,-2,2}; sortArray(a); for (int i =0; i<a.length;i++) System.out.println(a[i]); }   }	2014-12-10 08:24:01		
748	rdfeo	5	NOT possible in o(n)time complexity and o(1) space complexity	2014-12-10 08:24:01		
749	rdfeo	5	Yes, if o(n) means small Oh of n, which completely different from O(n), BigOh of n.  If you did mean BigOh, whatever proof you have, is likely wrong.  There was a link to a paper which just does that, somewhere in the comments on this question.	2014-12-10 08:24:01		
750	rrmeu	5	If this wasn't an array it would be doable!  if you had a linked list you could easily do this in one pass!  Just link the negative list together then link the last item with the first positive.	2014-12-10 08:24:01		
751	dkebi	5		2014-12-10 08:24:01		
752	ethan	5		2014-12-10 08:24:01		
753	fmzze	5	Otherwise, I do not believe this problem is solvable.	2014-12-10 08:24:01		
754	tenuw	5	[ o(1) space, by time complexity is not o(n) :( ]	2014-12-10 08:24:01		
755	xhgls	5		2014-12-10 08:24:01		
756	sgiwy	5		2014-12-10 08:24:01		
757	mrjku	5	In O(n) time and O(1) space.	2014-12-10 08:24:01		
758	dkebi	5		2014-12-10 08:24:01		
759	tenuw	5		2014-12-10 08:24:01		
760	bjsiw	5	It uses O(1) space but time used is O(m^2) where m is number of negetive integers there.	2014-12-10 08:24:01		
761	ftfck	5	This is like merge sort with a twist. The best solution I can think of for an O(1) space complexity is O(nlogn) time complexity. The trick is to think in terms of merge sort and perform matrix rotation through reverse	2014-12-10 08:24:02		
762	sqzqo	5		2014-12-10 08:24:02		
763	zeice	5		2014-12-10 08:24:02		
764	gilit	5	T(n) = 2T(n/2)+o(n). o(n) being the rotation function. Then time complexity is O(nlogn). I dont really think any type of sorting can occur in O(n) but if someone come up with a solution, thatd be good.	2014-12-10 08:24:02		
765	wbqzu	5	Forgot to comment this on the code. The order function return the number of positive items in the array. So p1 is the positive items in the first half or the array. p2 is the positive items in the second half of the array.	2014-12-10 08:24:02		
766	qywrh	5		2014-12-10 08:24:02		
767	nwkeg	5		2014-12-10 08:24:02		
768	nhibd	5	ideone.com/jYtdmD	2014-12-10 08:24:02		
769	zeice	5		2014-12-10 08:24:02		
770	qywrh	5		2014-12-10 08:24:02		
771	ethan	5	I believe its in O(n) time and definitely O(1) space, Can some analyze for a worst case to prove otherwise.	2014-12-10 08:24:02		
772	zeice	5	I haven't figured out the O(N) solution given an array, but it'd be easy to do with a linked list. Then you could just keep track of pointers for the end of the positive and negative lists, and then connect them in the end, with O(1) space (all you'd need is three pointers, one for the current position, one for the start of the positive list and one for the start of the negative).	2014-12-10 08:24:02		
773	ewigy	5	This is the best I got keeping the space on O(1) and O(n) without zeros Wasn't sure by the description if the array has zeros in it so added code to handle but not without extra time	2014-12-10 08:24:02		
774	nhibd	5		2014-12-10 08:24:02		
775	wbqzu	5		2014-12-10 08:24:02		
776	jippy	5	function for the solution is given below,it solves the problem in O(n) time:	2014-12-10 08:24:02		
777	vanul	5		2014-12-10 08:24:02		
778	rdfeo	5		2014-12-10 08:24:02		
779	gilit	5		2014-12-10 08:24:02		
780	gilit	5		2014-12-10 08:24:02		
781	gilit	5	Nice, but doesn't maintain order. (Swapping makes it unstable.) Ex: Input: 1 -2 3 -3 2 -1 1 -2 3 -3 2 -1 Output: -2 -2 -3 -3 -1 -1 1 1 3 3 2 2 Expected: -2 -3 -1 -2 -3 -1 1 3 2 1 3 2	2014-12-10 08:24:02		
782	vanul	5		2014-12-10 08:24:02		
783	fowai	5		2014-12-10 08:24:02		
784	ufdxg	5	public static void sort(int[] array){  int cout_pos = 0; int count_neg = 0; int sum_pos = 0; int sum_neg = 0; int neg_co = 1; int pos_co = 1;  for(int i=0; i!=array.length; ++i){ if(array[i] < 0){ neg_co *= 10; count_neg++; sum_neg += -1 * array[i] * neg_co;  } else{ pos_co *= 10; cout_pos++; sum_pos += array[i] * pos_co;  } }  //put them back in the array for(int i = count_neg -1; i!=0; --i){ array[i] = -1*(sum_neg / neg_co); sum_neg -= array[i] * neg_co; neg_co /= 10;  }  for(int i = array.length-1; i!=count_neg-1; --i){ array[i] = sum_pos / pos_co; sum_pos -= array[i] * pos_co; pos_co /= 10;  } }	2014-12-10 08:24:02		
785	admin	5		2014-12-10 08:24:02		
786	wbqzu	5		2014-12-10 08:24:02		
787	azmjc	5		2014-12-10 08:24:02		
788	admin	5		2014-12-10 08:24:02		
789	jippy	5	1. Multiply all negative numbers by 10 and odd numbers by 10 and add 1 2. sort the array using stable sorting algorithm considering only the last digit of the number -10 -20 11 31 21 3. divide all elements by 10 -1 -2 1 3 2 This is O(N) and O(1) OR  2. O(NlogN) soln - sort using any standard algo considering only the last digit	2014-12-10 08:24:02		
790	vanul	5		2014-12-10 08:24:02		
791	xhgls	5		2014-12-10 08:24:02		
792	dgjji	5	This is linear time but also O(n) memory (for the hash map src_pos)	2014-12-10 08:24:02		
793	plapd	5	I know time complexity is O(n^2).	2014-12-10 08:24:02		
794	dgjji	5		2014-12-10 08:24:02		
795	rdfeo	5		2014-12-10 08:24:02		
796	vanul	5	Two Threaded solution: One thread starts from n direction left to right. Another thread from 1 right to left. LR thread stops if it encounters -ve and waits for RL to encounter positive. If so swap. Iteration breaks if two threads cross path. o(n), o(1).	2014-12-10 08:24:02		
797	dgjji	5		2014-12-10 08:24:02		
798	nhibd	5		2014-12-10 08:24:02		
799	sqzqo	5	I believe I have achieved O(n) time and O(1) extra space complexity:-  Let us maintain such an invariant at all times:   The first n numbers of the array are negative. The next p numbers of the array are positive. So let the array look like this:  -ve -ve -ve ... -ve; +ve +ve +ve ... +ve; -ve .... n times p times remaining   Now let us find n1 and p1 such that  -ve -ve -ve ... -ve; +ve +ve +ve ... +ve; -ve -ve -ve ... -ve; +ve +ve +ve .... +ve; -ve .... n times p times n1 times p1 times remaining  Now let us try to 'consume' the n1 and p1 elements in the n and p elements. We can do this by swapping the 2nd and 3rd blocks(p and n1 elements). If we can do this in O(p+n1) time, then increment n to be n+n1 and p to be p+p1 and keep doing this, we should be able to do this for the whole array in O(n) time.  So the challenge is this:  x1 x2 x3 ... xp; y1 y2 y3 ... yq has to be rearranged to form y1 y2 y3 ... yq; x1 x2 x3 ... xp in O(p+q) time.  If p==q, then it's easy. Just keep on swapping x1, y1; x2, y2 and so on. If p!=q, suppose p>q without loss of generality. Then swap the elements y1..yq and x1..xq to get  y1 y2 y3 ... yq xq+1 xq+2 ... xp x1 x2 x3 ... xq  and repeat the procedure for the subarray xq+1 xq+2 ... xp; x1 x2 x3 ... xq  This way, it is possible to swap an unequal number of elements in place in O(n) time and O(1) extra space.  Code:	2014-12-10 08:24:02		
800	mrjku	5		2014-12-10 08:24:02		
801	eucmc	5		2014-12-10 08:24:02		
802	qywrh	5	This code takes .325 seconds for 10,000 elements.	2014-12-10 08:24:02		
803	tenuw	5	Try proving it. It is likely wrong. (And don't ask for a counter-example).	2014-12-10 08:24:02		
804	zeice	5		2014-12-10 08:24:02		
805	nhibd	5		2014-12-10 08:24:02		
806	vanul	5	public static void reArrageArray(int []data) { int loopCount = 0; int nPos = -1; for (int i = 0; i < data.length; i++) { int nValue = data[i]; if (nValue < 0) { //2 if (nPos != i-1) { for (int j = i ; j > 0; j--) { if (data[j-1] >= 0) { data[j] = data[j-1]; data[j-1] = nValue; } else { nPos = j; } loopCount++; } } else { nPos = i; loopCount++; }  } else { loopCount++; } } System.out.println("Total loop count : " + loopCount); for (int i = 0; i < data.length; i++) { System.out.println(data[i]); }  }	2014-12-10 08:24:02		
807	nwkeg	5	How about do the "dividing" part of quicksort with the value 0 as the pivot. All values lesser than 0 will be on left and values greater than 0 will be on right.  Takes O(n) time.  Not sure about whether the relative positions are maintained.	2014-12-10 08:24:02		
808	ftfck	5		2014-12-10 08:24:02		
809	vanul	5		2014-12-10 08:24:02		
810	krxlv	5	It seems not that difficult, someone did mention 'mergesort' but no one mentioned how to make it O(N): So, how about using a special version of mergesort recursively, where "merge" involves inserting +ve and -ve parts of the 'right' sub-list into the 'left' sub-list, this "merge" will take O(1), leading to O(N) for the whole mergesort?	2014-12-10 08:24:02		
811	bjsiw	5	This is not possible in O(1) space, O(n) time is fine. I guess interviewer wanted to see if interviewee is confident enough to say this.	2014-12-10 08:24:02		
812	fmzze	5	He would be confident and wrong. I guess that puts him squarely in the arrogant bucket.	2014-12-10 08:24:02		
813	nwkeg	5	for O(1) space, can we not allocate max integer space and then fill it sequentially with occurred positive integers in given array, and then fill them back in original array from end of the array, here we will ensure that all -ve integers are pulled ahead. (filling up in original array should be easy). Help expand this logic if makes sense.	2014-12-10 08:24:02		
814	eucmc	5	<vector> A() algorithm group(A) { n<-- length(A) k=n+1 for i<-- 0 to n do { if(A[i]>0) { A[k]=A[i] A.erase(A.begin()+i) k=k+1 } } }	2014-12-10 08:24:02		
815	sgiwy	5	#include<iostream> using namespace std;  void swapp(int* a,int* b) { int t= *a; *a=*b; *b=t; }  int main() { int n; cin>>n; int* a=new int[n]; for(int i=0;i<n;i++) cin>>a[i];  int countneg=0,countpos=0; for(int i=0;i<n;i++) { if(a[i]<0)countneg++; else countpos++; } cout<<countneg<<" "<<countpos<<endl; int j=0,tempcount=countneg; for(int i=0;i<n;i++) { if(a[i]>0 && i<countneg) { swapp(&a[i],&a[tempcount]); tempcount++; } else if(a[i]<=0) { swapp(&a[i],&a[j]); j++;if(i>0) i--; } else continue;  } for(int i=0;i<n;i++) cout<<a[i]<<" "; delete []a; }	2014-12-10 08:24:02		
816	dgjji	5	Do an in-place partition (i.e. from the quick sort algorithm) on the pivot value 0. However, the partition algorithm is not stable, but we can fix that without too much extra work and constant overhead.  Example:	2014-12-10 08:24:02		
817	rrmeu	5		2014-12-10 08:24:02		
818	admin	5		2014-12-10 08:24:02		
819	qywrh	5	By the way, a stable_partition is already implemented in STL if using C++ that does exactly what this question is asking.	2014-12-10 08:24:02		
820	cfzie	5		2014-12-10 08:24:02		
821	vanul	5		2014-12-10 08:24:02		
822	cfzie	5	If you have to implement the stable_partition manutally, you can always use the STL rotate for the last step!	2014-12-10 08:24:03		
823	plapd	5		2014-12-10 08:24:03		
824	dgjji	5		2014-12-10 08:24:03		
825	fmzze	5	The quicksort partition swaps at most n times, and compares each element once with the pivot giving a running time O(n).  The partition is done in-place, so only O(1) memory overhead.	2014-12-10 08:24:03		
826	huiqq	5	With a singly linked list (instead of an array) you can obtain O(n) time complexity and O(1) space complexity:	2014-12-10 08:24:03		
827	jippy	5		2014-12-10 08:24:03		
828	eucmc	5		2014-12-10 08:24:03		
829	dgjji	5	O(n) time O(1) space solution:	2014-12-10 08:24:03		
830	bexbp	5		2014-12-10 08:24:03		
831	nhibd	5		2014-12-10 08:24:03		
832	sgiwy	5	forgot to copy the initialization of i and j	2014-12-10 08:24:03		
833	plapd	5		2014-12-10 08:24:03		
834	krxlv	5		2014-12-10 08:24:03		
835	rrmeu	5	I don't think this solution will maintain relative order. Can you give an example?	2014-12-10 08:24:03		
836	ufdxg	5	complexity is little more than (n)...	2014-12-10 08:24:03		
837	bjsiw	5		2014-12-10 08:24:03		
838	xhgls	5		2014-12-10 08:24:03		
839	sqzqo	5		2014-12-10 08:24:03		
840	ftfck	5		2014-12-10 08:24:03		
841	admin	5	O(n) :)	2014-12-10 08:24:03		
842	qywrh	5	I have a completly different approach.  What I would suggest is to use Godel numbering to hold the array. we will have 2 Godel numbering. one for the positive numbers, and one for the negative ones.  The godel numbers will be created based on the position of the numbers in the array.  there are some issues in the solution, such as Godel number might grow exponentially with n, and also that if the numbers are not in N, this method won't work.  but still this is a cool approach, maybe someone can develop it a bit more.	2014-12-10 08:24:03		
843	tenuw	5	Using double pointers. The first pointer is to head and the other one to tail.  If the first pointer value is less than zero, first pointer move one step forward. Otherwise, if first pointer greater than zero, waiting second pointer scan from tail till find the first one which is negative.  The complex is O(1) (the constant is 1) and space is O(1) .	2014-12-10 08:24:03		
844	sgiwy	5		2014-12-10 08:24:03		
845	bexbp	5		2014-12-10 08:24:03		
846	jippy	5	int negatifindex=0; int prevnegatifindex=-1; int pozitifindex=4; // array.length-1 int nextpozitifindex=-1; while (negatifindex<=pozitifindex) { if(array[negatifindex]<0) { if (prevnegatifindex!=-1) swap(array[prevnegatifindex],array[negatifindex]) prevnegatifindex=-1; negatifindex++;  } if(array[pozitifindex]>0) { if (nextpozitifindex!=-1) swap(array[nextpozitifindex],array[pozitifindex]) nextpozitifindex=-1; pozitifindex--; } if (array[pozitifindex]<0 & array[negatifindex]>0) { swap(array[pozitifindex],array[negatifindex]) prevnegatifindex=negatifindex;, pozitifindex--; nextpozitifindex=pozitifindex; negatifindex++; } }  Time complexity is O(n) and space is O(1)	2014-12-10 08:24:03		
847	dgjji	5	Let's solve this problem by diving it into two much simpler problems: A) We want negative numbers to be at the right positions; we don't care about the positive one B) We move the positive numbers at the right positions, not caring about the negative one C) We apply A B on copies of the array and then combine the result to get the final solution  A and B can be easily solve linearly.  Solution for A: {{ void solveA(int* a, int n) { int p = 0; for (int i = 0; i < n; i++) if (a[i] < 0) { a[p] = a[i]; p++ } } }}  For B the solution is similar.  C) is also quite easy. We just need to count how many negative and positive number we have in order to know how many values to copies from the two partial solution.  Complexity: O(n) both time and space	2014-12-10 08:24:03		
848	rdfeo	5		2014-12-10 08:24:03		
849	wbqzu	5		2014-12-10 08:24:03		
850	ewigy	5	O(n) and O(n)	2014-12-10 08:24:03		
851	dgjji	5		2014-12-10 08:24:03		
852	nwkeg	5		2014-12-10 08:24:03		
853	rrmeu	5	Here's the simple code, where you shift right everything when you encounter negative number.	2014-12-10 08:24:03		
854	wbqzu	5		2014-12-10 08:24:03		
855	wbqzu	5		2014-12-10 08:24:03		
856	eucmc	5	This works in O(n) time and O(1) space.  Algorithm:	2014-12-10 08:24:03		
857	azmjc	5		2014-12-10 08:24:03		
858	huiqq	5		2014-12-10 08:24:03		
859	dkebi	5	Here is my solution O(n) time and constant space complexity 1) count number of negative numbers in the array 2) set the index where positive number is supposed to start as pivot 3) count number of positive numbers before pivot and after pivot 4) iterate each number in the array until pivot a) if number is negative proceed b) if number if positive initiate rearrangment to place each number in its correct position until we come back to current position.  c++ code	2014-12-10 08:24:03		
860	sqzqo	5		2014-12-10 08:24:03		
861	krxlv	5		2014-12-10 08:24:03		
862	nwkeg	5	Instead of numbers we should work with segments of positive or negative numbers. Lets say the numbers are [1 2 -1 -2 -3 4 5 6 -7 -8 -9].  initial segments: [1 2], [-1 -2 -3]*, [4 5 6], [-7 -8 -9] step 1. [-1 -2], [1 2]*, [-3], [4 5 6], [-7 -8 -9] ... pushed right seg to left, 2 swaps step 2. [-1 -2 -3], [1 2 4 5 6]*, [-7 -8 -9] ... pushed left seg to right, 2 swaps step 3. [-1 -2 -3], [1 2], [-7 -8 -9]*, [4 5 6] ... pushed left seg to right, 3 swaps step 4. [-1 -2 -3 -7 -8], [1 2]*, [-9], [4 5 6] ... pushed right seg to left, 2 swaps step 5. [-1 -2 -3 -7 -8 -9], [1 2 4 5 6] ... pushed left seg to right, 2 swaps  Total 11 swaps.  Lets say the negative segment is N and the positive segment is P. Now, given a situation like "[all negative], P, N, [unknown]", we need to do the following.  1. If |N| >= |P|, send right segment to left, total swap needed |N|+|P| 2. If |N| < |P|, send left segment to right, total swap needed |N|+|P|  Amortized O(n).	2014-12-10 08:24:03		
863	qywrh	5	Please let me know if it has any problem? it is in O(N) time complexity and O(1) space.	2014-12-10 08:24:03		
864	dkebi	5		2014-12-10 08:24:03		
865	ethan	5		2014-12-10 08:24:03		
866	dgjji	5		2014-12-10 08:24:03		
867	jippy	5		2014-12-10 08:24:03		
868	sqzqo	5	public static void main(String[] arg) { int[] arr = { -1, 1, 3, -2, 2, -7, 8 }; System.out.println(Arrays.toString(arr)); for (int i = 0; i < arr.length; i++) { if (arr[i] < 0) { checkAndSwap(arr, i); } } System.out.println(Arrays.toString(arr)); } private static void checkAndSwap(int[] arr, int currIndex) { for (int i = currIndex - 1; i > 0; i--) { if (arr[i] > 0) { int temp = arr[i]; arr[i] = arr[currIndex]; arr[currIndex] = temp; currIndex = i; } else { break; } } }	2014-12-10 08:24:03		
869	mrjku	5	{ public static void main(String[] arg) { int[] arr = { -1, 1, 3, -2, 2, -7, 8 }; System.out.println(Arrays.toString(arr)); for (int i = 0; i < arr.length; i++) { if (arr[i] < 0) { checkAndSwap(arr, i); } } System.out.println(Arrays.toString(arr)); } private static void checkAndSwap(int[] arr, int currIndex) { for (int i = currIndex - 1; i > 0; i--) { if (arr[i] > 0) { int temp = arr[i]; arr[i] = arr[currIndex]; arr[currIndex] = temp; currIndex = i; } else { break; } } } }	2014-12-10 08:24:03		
870	rdfeo	5	public class TestLogic {  public static void main(String[] arg) { int[] arr = { -1, 1, 3, -2, 2, -7, 8 }; System.out.println(Arrays.toString(arr)); for (int i = 0; i < arr.length; i++) { if (arr[i] < 0) { checkAndSwap(arr, i); } } System.out.println(Arrays.toString(arr)); } private static void checkAndSwap(int[] arr, int currIndex) { for (int i = currIndex - 1; i > 0; i--) { if (arr[i] > 0) { int temp = arr[i]; arr[i] = arr[currIndex]; arr[currIndex] = temp; currIndex = i; } else { break; } } } }	2014-12-10 08:24:03		
871	rdfeo	5	public class TestLogic {  public static void main(String[] arg) { int[] arr = { -1, 1, 3, -2, 2, -7, 8 }; System.out.println(Arrays.toString(arr)); for (int i = 0; i < arr.length; i++) { if (arr[i] < 0) { checkAndSwap(arr, i); } } System.out.println(Arrays.toString(arr)); } private static void checkAndSwap(int[] arr, int currIndex) { for (int i = currIndex - 1; i > 0; i--) { if (arr[i] > 0) { int temp = arr[i]; arr[i] = arr[currIndex]; arr[currIndex] = temp; currIndex = i; } else { break; } } } }	2014-12-10 08:24:03		
872	dkebi	5	The problem can indeed be solved in O(n) time and with O(1) complexity.  Below is my solution:	2014-12-10 08:24:03		
873	admin	5		2014-12-10 08:24:03		
874	bjsiw	5		2014-12-10 08:24:03		
875	bjsiw	5	Approach:  Think of the array as continguous streaks of positive and negative integers: [n0 p1, n1, p2, n2, p3, n3, ...]  Each streak can have any number of integers in it.  We can ignore the leading streak of negative integers (if any) because they are already in the sorted position.  Now we need to find a solution to sort each [pi, ni] pair or a positive streak followed by a negative streak.  After sorting [pi, ni] we get [ni, pi] -- essentially swap/switch the locations of the streaks.  To do this, do the following steps  -- Reverse pi to get rev(pi) -- Reverse ni to get rev(ni) -- Reverse [ rev(pi), rev(ni) ] to get [ rev(rev(ni)), rev(rev(pi)) ] which is equal to [ni, pi]  This is very similar to reversing all the words within a sentence (not the whole sentence).  I would appreciate it if you could correct me if i am wrong anywhere.	2014-12-10 08:24:03		
876	ufdxg	5	My solution in C++ below. Running time is O(n) (two passes) and it's done in place (O(1) extra-space) :	2014-12-10 08:24:03		
877	zeice	5		2014-12-10 08:24:03		
878	vanul	5		2014-12-10 08:24:03		
879	wbqzu	5	There is a paper showing O(n) time and O(1) space algorithm "Stable minimum space partitioning in linear time." diku.dk/hjemmesider/ansatte/jyrki/Paper/KP92b.pdf	2014-12-10 08:24:03		
880	rrmeu	5		2014-12-10 08:24:04		
881	fmzze	5		2014-12-10 08:24:04		
882	ftfck	5		2014-12-10 08:24:04		
883	ethan	5		2014-12-10 08:24:04		
884	ufdxg	5	bool isNegative(int t) { return t < 0 ? true : false; }  void sort(int A[], int n) { std::stable_partition(A, A + n, isNegative); }	2014-12-10 08:24:04		
885	bexbp	5	bool isNegative(int t) { return t < 0 ? true : false; }  void sort(int A[], int n) { std::stable_partition(A, A + n, isNegative); }	2014-12-10 08:24:04		
886	krxlv	5	bool isNegative(int t) { return t < 0 ? true : false; }  void sort(int A[], int n) { std::stable_partition(A, A + n, isNegative); }	2014-12-10 08:24:04		
887	bjsiw	5	bool isNegative(int t) { return t < 0 ? true : false; }  void sort(int A[], int n) { std::stable_partition(A, A + n, isNegative); }	2014-12-10 08:24:04		
888	ethan	5	The following solution seems like O(n) time and O(1) to me. Comments?	2014-12-10 08:24:04		
889	sgiwy	5		2014-12-10 08:24:04		
890	dkebi	5		2014-12-10 08:24:04		
891	ethan	5		2014-12-10 08:24:04		
892	ftfck	5		2014-12-10 08:24:04		
893	jippy	5	}	2014-12-10 08:24:04		
894	xhgls	5		2014-12-10 08:24:04		
895	zeice	5		2014-12-10 08:24:04		
896	admin	5	}	2014-12-10 08:24:04		
897	nwkeg	5	void reOrder(final int[] a, final int n) { int j = 0; for (int i = 0; i < n; i++) { if (a[i] < 0) { int k = i; while (k - 1 >= j && a[k - 1] > 0) { final int temp = a[k]; a[k] = a[k - 1]; a[k - 1] = temp; k--; } j++; } } }	2014-12-10 08:24:04		
898	sqzqo	5	{ void reOrder(final int[] a, final int n) { // TODO Auto-generated method stub int j = 0; for (int i = 0; i < n; i++) { if (a[i] < 0) { int k = i; while (k - 1 >= j && a[k - 1] > 0) { final int temp = a[k]; a[k] = a[k - 1]; a[k - 1] = temp; k--; } j++; } } } }	2014-12-10 08:24:04		
899	qywrh	5	{code}  void reOrder(final int[] a, final int n) { // TODO Auto-generated method stub int j = 0; for (int i = 0; i < n; i++) { if (a[i] < 0) { int k = i; while (k - 1 >= j && a[k - 1] > 0) { final int temp = a[k]; a[k] = a[k - 1]; a[k - 1] = temp; k--; } j++; } } }	2014-12-10 08:24:04		
900	azmjc	5	This works.  void reOrder(final int[] a, final int n) { // TODO Auto-generated method stub int j = 0; for (int i = 0; i < n; i++) { if (a[i] < 0) { int k = i; while (k - 1 >= j && a[k - 1] > 0) { final int temp = a[k]; a[k] = a[k - 1]; a[k - 1] = temp; k--; } j++; } } }	2014-12-10 08:24:04		
901	jippy	5	This works.  void reOrder(final int[] a, final int n) { // TODO Auto-generated method stub int j = 0; for (int i = 0; i < n; i++) { if (a[i] < 0) { int k = i; while (k - 1 >= j && a[k - 1] > 0) { final int temp = a[k]; a[k] = a[k - 1]; a[k - 1] = temp; k--; } j++; } } }	2014-12-10 08:24:04		
902	dgjji	5	If anybody comes up with an O(1) space, O(n) time solution, we can work together and write a paper on in-place, stable, O(n logn) worst-case sorting algorithm.	2014-12-10 08:24:04		
903	krxlv	5	Here is the java implementation for O(n) time complexity, O(1) space complexity solution. Pretty sure others would have answered it already on this forum...I just did not take time to go through all the solutions.	2014-12-10 08:24:04		
904	dkebi	5		2014-12-10 08:24:04		
905	vanul	5		2014-12-10 08:24:04		
906	gilit	5	Can anyone find something wrong with this? It should be O(n)/O(1).	2014-12-10 08:24:04		
907	sqzqo	5		2014-12-10 08:24:04		
908	jippy	5		2014-12-10 08:24:04		
909	rdfeo	5	Below is basically a merge-sort implementation. I did this in Python but easy to port to C. It is O(N logN) I think (log N calls to sort, merge is O(n)), and could be farmed out to multiple machines too for each independent part for scale. Not sure how to evaluate space usage -- do you count the stack? Also, the Python tuple concatenation and list division is not ideal in memory usage of course but could easily be improved and done in-place in C.	2014-12-10 08:24:04		
910	admin	5		2014-12-10 08:24:04		
911	admin	5		2014-12-10 08:24:04		
912	xhgls	5	example: -1 , 1 , 3 , -2 , 2, -4 , 4 , 5 , -5  O(n) time O(1) space solution  Count the number of negative elements (k = 4 here) , as a first step try to get first 4 elements in correct order, every time you swap an element out record its index, let f be the encoding function for negatives and g for positives. Step1.1 : -1 , 1 , -4 , -5 , 2 , g(3,3), 4 , 5 , f(-2,4) Step1.2 ( f(x,y) will be in the order f(x1, y1), f(x2, y2), f(x3, y3) , ..., where y1 < y2 < y3 < .. , same property holds for g). But you have the rest of the negative elements in their final destinations, freeze these elements. Treat f(x,y) as your new negatives on an array, perform swaps similar to step1, let h be the encoding function for positives dislocated in this step: -1 , f(-2,4) , -4 , -5 , 2 , g(3,3) , 4 , 5 , h(1,2) Step2: Stable sort the unfrozen negative elements Step3: Now you are done with all the negatives. You have the property max(y / h(x,y)) < max(y / g(x,y)), again h(x,y) will appear in increasing order of y. Stable sort h union g relative to the other positives: <all negatives> , h(1,2) , g(3,3), 2 , 4 , 5  You can always pick to work on the positives first / negatives first based on the sizes of arrays appearing in the recursive step. So you would have T(n) = O(n) + T(a) + T(b) ( where a+b < 3n/4) so T(n) = O(n)  It is unreasonable to expect someone to solve this within 1 hour	2014-12-10 08:24:04		
913	bexbp	5		2014-12-10 08:24:04		
914	huiqq	5		2014-12-10 08:24:04		
915	rrmeu	5		2014-12-10 08:24:04		
916	qywrh	5		2014-12-10 08:24:04		
917	eucmc	5		2014-12-10 08:24:04		
918	admin	5		2014-12-10 08:24:04		
919	dkebi	5	Bubble sort, only a[i]>0&&a[i+1]<0 will exchange each other Code:	2014-12-10 08:24:04		
920	wbqzu	5		2014-12-10 08:24:04		
921	nhibd	5		2014-12-10 08:24:04		
922	azmjc	5	Bubble sort, only a[i]>0&&a[i+1]<0 will exchange each other Code:	2014-12-10 08:24:04		
923	zeice	5		2014-12-10 08:24:04		
924	admin	5		2014-12-10 08:24:04		
925	dgjji	5	Bubble sort, only a[i]>0&&a[i+1]<0 will exchange each other Code:	2014-12-10 08:24:04		
926	nwkeg	5		2014-12-10 08:24:04		
927	admin	5		2014-12-10 08:24:04		
928	bexbp	5	Bubble sort, only a[i]>0&&a[i+1]<0 will exchange each other Code:	2014-12-10 08:24:04		
929	krxlv	5		2014-12-10 08:24:04		
930	ethan	5		2014-12-10 08:24:04		
931	ufdxg	5	Bubble sort, only a[i]>0&&a[i+1]<0 will exchange each other Code:	2014-12-10 08:24:04		
932	bexbp	5		2014-12-10 08:24:04		
933	ewigy	5		2014-12-10 08:24:04		
934	rrmeu	5	Bubble sort, only a[i]>0&&a[i+1]<0 will exchange each other Code:	2014-12-10 08:24:04		
935	jippy	5		2014-12-10 08:24:04		
936	fowai	5		2014-12-10 08:24:04		
937	huiqq	5		2014-12-10 08:24:04		
938	qywrh	5		2014-12-10 08:24:04		
939	sqzqo	5		2014-12-10 08:24:05		
940	rrmeu	5		2014-12-10 08:24:05		
941	ewigy	5		2014-12-10 08:24:05		
942	vanul	5		2014-12-10 08:24:05		
943	eucmc	5	n 0 1 2 3 4 value -1 1 3 -2 2  1. define boolean inProcess = false;  2. From 0 to n, if value(n) = negative, continue  else inProcess = true; tempA = n;  while(inProcess) {  if(value[n] = negative) inProcess = false;  tempB = value(n+1) shift value(n) from n to n+1  increase n until find a negative value (m). }  value[tempA] = tempB;  {{ int[] array = {-1, 1, 3, 4, -2, 2}; boolean inProcess = false; while(i<array.length) { if(array[i] < 0) { i++; } else { inProcess = true; tempNo = i; while(inProcess) {  if(tempB == null) tempA = array[i]; else tampA = tempB; tempB = array[i+1]; if(array[i+1] < 0) inProcess = false;  array[i+1] = tempA; i++; } array[tempNo] = tempB; } } }}	2014-12-10 08:24:05		
944	cfzie	5	n 0 1 2 3 4 value -1 1 3 -2 2  1. define boolean inProcess = false;  2. From 0 to n, if value(n) = negative, continue  else inProcess = true; tempA = n;  while(inProcess) {  if(value[n] = negative) inProcess = false;  tempB = value(n+1) shift value(n) from n to n+1  increase n until find a negative value (m). }  value[tempA] = tempB;	2014-12-10 08:24:05		
945	mrjku	5		2014-12-10 08:24:05		
946	fowai	5		2014-12-10 08:24:05		
947	sqzqo	5		2014-12-10 08:24:05		
948	nwkeg	5		2014-12-10 08:24:05		
949	azmjc	5	I don't understand. Why not solving this problem in the simplest way? I think time is O(n) and space is O(l) a=[-1 1 3 -2 2] b=[] c=[] for _item in a: { if _item <0:} {{ b.append(_item)}} { else:} {{c.append(_item)}} print b.extend(c)	2014-12-10 08:24:05		
950	ufdxg	5	I dont understand. Why not trying the simplest way? I think the time is O(n) and space is O(l)  a=[-1 1 3 -2 2] b=[] c=[] for _item in a: {if _item <0:} {{b.append(_item)}} {else:} {{c.append(_item)}} print b.extend(c)	2014-12-10 08:24:05		
951	bjsiw	5		2014-12-10 08:24:05		
952	qywrh	5		2014-12-10 08:24:05		
953	ftfck	5		2014-12-10 08:24:05		
954	tenuw	5		2014-12-10 08:24:05		
955	cfzie	5	space complexity O(1), time complexity O(N) It seems quite easy, I don't understand why it should be done in O(Nlog(N)).	2014-12-10 08:24:05		
956	fowai	5		2014-12-10 08:24:05		
957	sqzqo	5		2014-12-10 08:24:05		
958	sgiwy	5	#include<stdio.h> main() { int n; scanf("%d",&n); int a[n],b[n]; int i=0; for(i=0;i<n;i++) { scanf("%d",&a[i]); } int k=0; for(i=0;i<n;i++) { if(a[i]<0) { b[k]=a[i];k=k+1; } else {k=k;} }   for(i=0;i<n;i++) { if(a[i]>0){b[k]=a[i];k++;}else{k=k;} }  for(i=0;i<k;i++) { printf(" %d",b[i]); } }	2014-12-10 08:24:05		
959	rrmeu	5		2014-12-10 08:24:05		
960	ufdxg	5		2014-12-10 08:24:05		
961	dgjji	5	how can you preserve the relative position???????????	2014-12-10 08:24:05		
962	mrjku	5	It cannot be done in O(n) . If it can done in O(n), then lower bound for comparision based sorting is O(n) which is false. So, the order is O(nlogn) and space is O(1)	2014-12-10 08:24:05		
963	sqzqo	5		2014-12-10 08:24:05		
964	cfzie	5		2014-12-10 08:24:05		
965	mrjku	5		2014-12-10 08:24:05		
966	eucmc	5		2014-12-10 08:24:05		
967	nhibd	5	Very bad code, see what happens with the array {-1,1,3,-2,2}	2014-12-10 08:24:05		
968	nwkeg	5	Part of the inplace quicksort algorithm?	2014-12-10 08:24:05		
969	zeice	5	The inplace quicksort doesn't remain the order.  -1 1 3 -2 2 and pivot 0 it would give -1 -2 3 1 2 instead of -1 -2 1 3 2	2014-12-10 08:24:05		
970	dkebi	5	Joe Kidd I said *part* of, not the whole sorting procedure, but the dividing part, which moves all negative numbers to the left and moves all the positive numbers to the right....	2014-12-10 08:24:05		
971	krxlv	5	Here is an O(n) solution without extra space.	2014-12-10 08:24:05		
972	rrmeu	5		2014-12-10 08:24:05		
973	ftfck	5		2014-12-10 08:24:05		
974	ftfck	5	Nice one!	2014-12-10 08:24:05		
975	plapd	5	Doesn't work, check this for example -1 ,1 ,3 ,-2, -5, 2	2014-12-10 08:24:05		
976	nwkeg	5	1,2,3,-1,-2. your code fail on tghis 123,-1,-2 213,-1,-2 312,-1,-2 -1,1,2,3,-2 -1,1,2,-2,3	2014-12-10 08:24:05		
977	fowai	5	1.Start counters i at 0th index and j at nth index of the array. 2.Increase i until arr[i]>=0 3.Decrease j until arr[j]<0 4.swap arr[i] ,arr[j] 5.repeat steps 2, 3,4 till i<j  time-O(n),space-O(1)	2014-12-10 08:24:05		
978	nwkeg	5	Please read the question again....relative position not keeping.	2014-12-10 08:24:05		
979	ewigy	5		2014-12-10 08:24:05		
980	cfzie	5	Its said in o (n) time & o (1) space....	2014-12-10 08:24:05		
981	tenuw	5	Man I 'm so sorry , here is the algo : e.g {-1,2,8,1,-2,4} is the array 1)start i as 0, j as 0 2)while j<n inc j by one if arr[j] is negative , make arr[i] as this neg number arr[j] inc i by 1 and shift all the elements from arr[i to j-1] by one position  but again i 'm afraid it is O(n^2) WC and O(1) space :| ,sorry for not having read the memory constraints above,,actually this shifting procedure is O(N) itself :/	2014-12-10 08:24:05		
982	huiqq	5		2014-12-10 08:24:05		
983	nwkeg	5		2014-12-10 08:24:05		
984	azmjc	5	Order not maintained...	2014-12-10 08:24:05		
985	bjsiw	5		2014-12-10 08:24:05		
986	dgjji	5	Aren't you using extra space ?? New array is being created here.....	2014-12-10 08:24:05		
987	dkebi	5		2014-12-10 08:24:05		
988	dkebi	5	Impossible? Don't make claims about which you have no clue.	2014-12-10 08:24:05		
989	plapd	5	This problem has a O(n) time and O(1) space complexity solution if relative ordering is not a factor. To keep space constant you have to use n^2 operations (swaps and compares) to rearrange the array. To keep operations constant you would need to allocate additional memory to keep track of where each positive/negative entry will need to land.  Also note that I am making the assumption that 0 is treated like a positive number, although I would clarify this point with the interviewer to ensure correctness.  O(n) time, O(1) space without ordering solution: 1. Start with two pointers, one at the front and one at the end ( i=0, j = array.length -1). While i is less than j repeat steps 2-4. 2. Evaluate i - if it is less than 0 increment it by 1 3. Evaluate j - if it is greater than or equal to 0 decrement it by 1 4. Evaluate i && j - if i is greater than or equal to zero AND j is less than 0 then swap the elements. Increment i and decrement j.  Here is a working sample:	2014-12-10 08:24:05		
990	azmjc	5		2014-12-10 08:24:05		
991	gilit	5		2014-12-10 08:24:05		
992	ufdxg	5	@masterjaso  I don't think your algorithm will ensure the relative positions of both +ve and -ve numbers. Will you algorithm work for [-1 1 -2 2 -3 3]?	2014-12-10 08:24:06		
993	fmzze	5	This paper:  "Stable minimum space partitioning in linear time"  by  Jyrki Katajainen, Tomi Pasanen   does it in O(n) time and O(1) space, and maintains the relative order (which is what makes the problem difficult), and hence the usage of the word "stable" as the very first word in the title of the paper.	2014-12-10 08:24:06		
994	bjsiw	5	Can you explain that paper? It's over my head.	2014-12-10 08:24:06		
995	ftfck	5	@ Erasmus  You are correct, my shown algorithm does not maintain the relative order (as disclosed in my comments). I do want to thank you for the sample, it helped me identify a bug and I have amended my post with updated and correct code.	2014-12-10 08:24:06		
996	huiqq	5	@Bryan. Don't worry if you don't understand, this is an impossible interview question.	2014-12-10 08:24:06		
997	bjsiw	6	1. XOR all the n numbers. 2. Result will be knocked out for all the even pairs as a^a=0 The result now contains only XOR of the two odd out numbers. 3. Find the first bit position in the result that is 1. Definitely this bit position both the odd numbers have different bit values. i.e. one has a 0 and another has a 1 at this position. Let this position be x 4. XOR the elements that have 1 at x bit position and XOR the elements that have 0 at x bit position. The two XOR results would give the two odd count numbers.	2014-12-10 08:24:07		
998	admin	6	last line of algorithm does not lead to result...so problem is, how could we find two numbers by knowing their XOR.	2014-12-10 08:24:07		
999	nwkeg	6	Hey Minku, The algo dfinitely leads us to result. You will be XORing two different sets and each of them will have the two numbers separately. I am posting my implementation.	2014-12-10 08:24:07		
1000	rdfeo	6		2014-12-10 08:24:07		
1001	ethan	6		2014-12-10 08:24:07		
1002	qywrh	6	Time Complexity: O(n) Space Complexity: O(1)	2014-12-10 08:24:07		
1003	sqzqo	6	Nice solution	2014-12-10 08:24:07		
1004	azmjc	6	Dude, Hats off to solution	2014-12-10 08:24:07		
1005	xhgls	6	It took me a few minutes to grasp how he dragged the numbers out of the XORed bits.  The trick to it is that because we're trying to find the two numbers that was set in an ODD number of times.  So, if the bit was a "1". 1 XOR 1 = 0 XOR 1 = 1 So if there is a 1 in the XORed bit set, and because the sum of two odd numbers is always even. Anything XORed an even number of times. = 0  Thus, for all 0's in the XORed bit set, there must have been 1 in the original bits. And for all 1's in the XORed bit set, both original bit sets have to contain a 0 or 1 respectively.	2014-12-10 08:24:07		
1006	rrmeu	6	What are the semicolons in "((x&;1)!=1)" and "x=x>>;1" ????? Are they typos?	2014-12-10 08:24:07		
1007	admin	6	Beautiful!	2014-12-10 08:24:07		
1008	qywrh	6		2014-12-10 08:24:07		
1009	ftfck	6		2014-12-10 08:24:07		
1010	nhibd	6	Time Complexity: O(n) Space Complexity: O(1)	2014-12-10 08:24:07		
1011	zeice	6	Simpler solution at the cost of space:  - Create a hash set - Loop the integers -- If the element is in the hash set, remove it -- Otherwise, add it (since it's not already present) - The answer is the contents of the hash set (which scales to any number of odd numbers)  Complexity: O(n) (due to an O(1) get/put hash set).	2014-12-10 08:24:07		
1012	eucmc	6	Correct... in case we do not want to us collections.... we can have an Array of size [unique occurrence of elements] with a simple logic to check 'If the element is not present in Array add it otherwise remove the occurrence in Array.	2014-12-10 08:24:07		
1013	ewigy	6	@PKT Your solution has a space complexity of O(n) and time complexity of O(n^2).	2014-12-10 08:24:07		
1014	vanul	6	@Eugene The comment was for PKT's solution where an array is being used and looked up every time.	2014-12-10 08:24:07		
1015	admin	6		2014-12-10 08:24:07		
1016	plapd	6		2014-12-10 08:24:07		
1017	qywrh	6	1. XOR all the n numbers. 2. Result will be knocked out for all the even pairs as a^a=0 The result now contains only XOR of the two odd out numbers. 3. Find the first bit position in the result that is 1. Definitely this bit position both the odd numbers have different bit values. i.e. one has a 0 and another has a 1 at this position. Let this position be x 4. XOR the elements that have 1 at x bit position and XOR the elements that have 0 at x bit position. The two XOR results would give the two odd count numbers.	2014-12-10 08:24:07		
1018	cfzie	6	How would you solve this in JAVA?	2014-12-10 08:24:07		
1019	ufdxg	6	Hey Satyajeet here you go. Should work without any change. Please let me know as I could not verify this.	2014-12-10 08:24:07		
1020	rdfeo	6		2014-12-10 08:24:07		
1021	sgiwy	6		2014-12-10 08:24:07		
1022	wbqzu	6	Time Complexity: O(n) Space Complexity: O(1)	2014-12-10 08:24:07		
1023	ufdxg	6	What does ;1 means in above code?? Plz ignore my ignorance..I am new to programming...	2014-12-10 08:24:07		
1024	vanul	6	That is a typo that came in automatically. remove the semicolons at both the places. It stays even after editing and updating.	2014-12-10 08:24:07		
1025	nhibd	6	My java solution in O(n):	2014-12-10 08:24:07		
1026	bexbp	6		2014-12-10 08:24:07		
1027	nwkeg	6		2014-12-10 08:24:07		
1028	dkebi	6	Output:	2014-12-10 08:24:07		
1029	ewigy	6		2014-12-10 08:24:07		
1030	sgiwy	6		2014-12-10 08:24:07		
1031	fowai	6		2014-12-10 08:24:07		
1032	azmjc	6		2014-12-10 08:24:07		
1033	ftfck	6	1. XOR all the numbers to get c = a^b 2. reiterate the array and get d = c^arr[i] & e = c^arr[i]' if (d = e') arr[i] is one number use the concept: d = (a^b)^a = b e = (a^b)^a' = b'	2014-12-10 08:24:07		
1034	xhgls	6		2014-12-10 08:24:07		
1035	krxlv	6		2014-12-10 08:24:07		
1036	fmzze	6	Next code in javascript returns array of two needed numbers (8,4)	2014-12-10 08:24:07		
1037	mrjku	6		2014-12-10 08:24:07		
1038	ufdxg	6		2014-12-10 08:24:07		
1039	eucmc	6		2014-12-10 08:24:07		
1040	azmjc	6		2014-12-10 08:24:07		
1041	krxlv	6	I had hard time understanding the solution(s) mentioned here. So if you guys are facing the same problem here is the link for better understanding. Upvote so everybody can see. geeksforgeeks.org/find-the-two-numbers-with-odd-occurences-in-an-unsorted-array/	2014-12-10 08:24:07		
1042	ewigy	6	last line of algorithm does not lead to result...so problem is, how could we find two numbers by knowing their XOR.	2014-12-10 08:24:08		
1043	plapd	6		2014-12-10 08:24:08		
1044	huiqq	6	If you really find some answer helpful, please up-vote. It helps people in finding valid answers. :)	2014-12-10 08:24:08		
1045	bexbp	6	@Expressions: Unregistered users cannot vote I believe. But there is a bigger problem. This should be a comment on the answer for which it was intended.	2014-12-10 08:24:08		
1046	plapd	6	My bad, failed to see the <anonymous/>	2014-12-10 08:24:08		
1047	bjsiw	7	First Let's see what all approaches we can take and then we check if it fits our requirement. 1. Brute Force: Select an element from 1 to N and check it frequency of occurrence. But this will be O(n2) and not O(n) . 2. XOR : but this technique won't work as question mentions an element can be repeated multiple times. so if element repeats 2 times or 4 times each time result of xor will be 0 so we cannot get the frequency of occurrences. 3. HashMap : We can create a HashMap in O(n) key will be elements and value will be their frequency of occurrence. But since we have to do it in O(1) space we cannot take this approach.  So we cannot opt for any of the above 3 approach. We have to check for some 4th approach.  Since we have range of numbers given to us we have to think in those lines. Array Index is from 0 to N-1 and range is from 1 to N. Can't we use the array as hash itself? where array "Index-1" represents the key (element) and value stored at index will represent the "frequency of occurrence".  But how will we take care that an element present at any index is not overwritten as this can cause problem? We can sort the array in that case value present at index i is I+1 itself.  What is the complexity of sorting the array? O(nlogn) if we opt for heap/merge/quick sort.  But since the range of element is given to us we can sort it in O(n).	2014-12-10 08:24:09		
1048	huiqq	7	It was not as simple as I thought in first go, but with a little thinking I was able to code it.	2014-12-10 08:24:09		
1049	tenuw	7		2014-12-10 08:24:09		
1050	bjsiw	7		2014-12-10 08:24:09		
1051	admin	7	you can check the complete executing code with explanation at : ms-amazon.blogspot.in/2013/07/you-are-given-array-of-n-integers-which.html	2014-12-10 08:24:09		
1052	dkebi	7	Nice solution varun. One correction after checking if(arr[pos]<=0) apart from incrementing pos a continue statement can be given to continue the loop process from the beggining i.e if(arr[pos] <= 0){ pos++; continue; } Am i right?	2014-12-10 08:24:09		
1053	bjsiw	7	counter example  {9,9,9,9,9,9,9,8,7,9,9}	2014-12-10 08:24:09		
1054	admin	7	@vishnu yes you are right, I missed it thanks for pointing out.  @algos It words for your example, just try introducing continue as vishnu suggested.  Output for your example: Element = 1 Frequency = 0 Element = 2 Frequency = 0 Element = 3 Frequency = 0 Element = 4 Frequency = 0 Element = 5 Frequency = 0 Element = 6 Frequency = 0 Element = 7 Frequency = 1 Element = 8 Frequency = 1 Element = 9 Frequency = 9 Element = 10 Frequency = 0 Element = 11 Frequency = 0	2014-12-10 08:24:09		
1055	gilit	7	Isn't it sorting in o(n) method will take o(n) extra space.???	2014-12-10 08:24:09		
1056	gilit	7	@sibendu If you are using counting sort then yes it will. Given range of array you can sort it in O(n) time.  And by range I mean no. of elements in range must be equal to the number of elements in array.  for eg. if we have 10 int array and range is (1,100) (any 10) then it is not possible but if range is (20,30) yes in this case it is possible.	2014-12-10 08:24:09		
1057	ewigy	7	@varun:im not talking about time complexity .Counting sort takes o(n) extra space which in that case is not allowed by the interviewer.	2014-12-10 08:24:09		
1058	dgjji	7	Sorry forgot to mention it will take O(1) space.  The simplest sorting algo with O(1) space and O(n) time complexity must have 2 conditions all elements must be in some range and all elements must be unique.  I believe this approach can be extended to arrays not satisfying the second condition, that will require some thinking.  In above I have not sorted instead manage to store the frequency without sorting, You can follow the other approach as well.	2014-12-10 08:24:09		
1059	rdfeo	7	@varun: Hi, Sibendu is asking you *how* you can sort the array in O(n) time with O(1) extra storage space. I am interested too. Please tell us how this is (roughly) possible... Thanks. Btw nice solution!	2014-12-10 08:24:09		
1060	zeice	7	@chih.chiu this is a separate question, I have coded it for the case where all elements are unique in array.  Complexity: Time : O(n) Space: O(1)	2014-12-10 08:24:09		
1061	plapd	7		2014-12-10 08:24:09		
1062	cfzie	7		2014-12-10 08:24:10		
1063	vanul	7	But giving a second thought to it, why do we even need to sort it when range is given? All element are unique, we should simply overwrite the values and continue moving forward in array.	2014-12-10 08:24:10		
1064	rrmeu	7	We can solve this in two scans Time complexity: o(n) ans space complexity o(1)  1) In first scan for each of occurrence of an element add the array size to that element. 2) In second scan Divide the element value by n gives frequency of occurrence.	2014-12-10 08:24:10		
1065	eucmc	7		2014-12-10 08:24:10		
1066	dkebi	7		2014-12-10 08:24:10		
1067	rdfeo	7	very nice solution venkatesh, +1 from my side.	2014-12-10 08:24:10		
1068	nhibd	7	can someone explain Venkatesh's solution?	2014-12-10 08:24:10		
1069	fowai	7	@varun, etc: While very clever, this is an O(n) space algorithm. You are relying on the fact that every integer has a free sign bit. In the general case, this is not true - the algorithm fails for instance with an array of 255 unsigned bytes. While this solution is quite valid in the case of a signed integer array, I feel standard complexity analysis labels it O(n); you need to "allocate" one bit per element as a flag for stating if the corresponding element is a count or input data.	2014-12-10 08:24:10		
1070	eucmc	7	@hj: both varun and venkatesh's solution are based on counting sort coupled with the fact that every element <= n-1. Thus if we divide any element by n, it is 0. So they use counting sort in-place and add n to elements. In the second pass, while dividing by n, the original content does not matter and we get the frequency. So we are not using any 'extra' space!	2014-12-10 08:24:10		
1071	ewigy	7	Alternative approach, encode fields which specify a normal value as positive, those that contain a count as negative, then proceed through the array. If the value we see is smaller than the index, simply decrement the field for the value (since we must already have removed any value there) if it is larger, then swap the value in that field currently with the current value and set the field value to -1, except if the field is already negative, in which case just decrement. Afterwards, the array is filled with negative values which are the counts, so just pop a minus in front of them and voila.  It's a little hard to follow, so here's the code:	2014-12-10 08:24:10		
1072	nhibd	7		2014-12-10 08:24:10		
1073	dkebi	7		2014-12-10 08:24:10		
1074	zeice	7	While very clever, this is an O(n) space algorithm. You are relying on the fact that every integer has a free sign bit. In the general case, this is not true - the algorithm fails for instance with an array of 255 unsigned bytes. While this solution is quite valid in the case of a signed integer array, I feel standard complexity analysis labels it O(n); you need to "allocate" one bit per element as a flag for stating if the corresponding element is a count or input data.	2014-12-10 08:24:10		
1075	admin	7	just store value as (val + count * N)	2014-12-10 08:24:10		
1076	wbqzu	7		2014-12-10 08:24:10		
1077	rrmeu	7		2014-12-10 08:24:10		
1078	dkebi	7	While very clever, this is an O(n) space algorithm. You are assuming you have additional free bits to add N in which may not be true. Standard complexity analysis would show this as O(n); you need to "allocate" one bit per element as a flag for stating if the corresponding element is a count or input data.	2014-12-10 08:24:10		
1079	sqzqo	7	If you can generate a sequence of primes P(1) to P(n) you can create single number that will represent a digest of the data set (there are formulas out there like f(n)=n^2n+41 that will do that for you). For example, you could use the prime sequence 3,5,7,11,13,17 to represent the set of numbers 1,2,3,4,5,6 where P(1)=3, P(2)=5, P(3)=7, P(4)=11, P(5)=13, P(6)=17.  Start with your digest as equaling 1 (call it D). Every time you see a 1, multiply it be P(1). Every time you see a 2, multiply it by P(2) etc... Thus if your sequence is: 1,2,4,5,1,1 the 'digest' is: D = P(1)*(2)*P(4)*P(5)*P(1)*P(1) or another wards D = 3 * 5 * 11 * 13 * 3 * 3  Then once you're done. Go through D and divide it with each P(n) in sequence and so long as you get a remainder 0 result you know there's another P(n) in there. In this example:  -Start dividing by 3, you will see that D divides by 3 exactly three times (hence the number 1 repeats exactly 3 times, print this information) -Then move onto the next prime 5 and you will see that D divides by 5 exactly once (so there is exactly one instance of 2 in the list, print this information) -Them move onto the next prime 7 and you will see that D divides by 7 zero times (so there are no 3's present in the list, print this information)  Continue doing this until the prime representing P(n) is reached. This entire process will require two passes through the data set, the initial construction of the digest D and the one more to print out the results. This solution will work so long as a number large enough to contain P(1)*(#occurrences of 1) ... * P(n) * P(1)*(#occurrences of n) can be allocated.	2014-12-10 08:24:10		
1080	ftfck	7	Clever, but not O(1) space. D is not constant sized, but rather a linear function of the input size. In particular, D may require N bits of storage.	2014-12-10 08:24:10		
1081	ftfck	7	Simple solution in java:	2014-12-10 08:24:10		
1082	nwkeg	7		2014-12-10 08:24:10		
1083	krxlv	7		2014-12-10 08:24:10		
1084	bexbp	7	This is O(n) space; you allocated a new array of the original's size.	2014-12-10 08:24:10		
1085	sgiwy	7	Solution goes like this....  {8,1,9,2,5,1,1,1,1} can be treated as the test data.....  {58,11,9,2,15,1,1,11,11} would be the processed data....  The process goes as follows.... 8 - > add 10 to location 8 {8,1,9,2,5,1,1,11,1} 1 -> add 10 to location 1 {18,1,9,2,5,1,1,11,1} 9 -> add 10 to location 9 {18,1,9,2,5,1,1,11,11} 2 -> add 10 to location 2 {18,11,9,2,5,1,1,11,11} 5 -> add 10 to location 5 {18,11,9,2,15,1,1,11,11} 1 -> add 10 to location 1 {28,11,9,2,15,1,1,11,11} 1 -> add 10 to location 1 {38,11,9,2,15,1,1,11,11} 11 -> special process ( if element is > 10) compute the modulo and add 10 to that location...11 % 10 = 1 ...so add 10 to location 1 {48,11,9,2,15,1,1,11,11} 11 -> special process ( if element is > 10) compute the modulo and add 10 to that location...11 % 10 = 1 ...so add 10 to location 1 {58,11,9,2,15,1,1,11,11}   {58,11,9,2,15,1,1,11,11} 58 - yields 58 / 10 times 1 and the original value is 58 % 10 and so on for each value....Array values are not lost....  Note : 10 is size of the array + 1...in code we have used 20 as our array size	2014-12-10 08:24:10		
1086	ftfck	7		2014-12-10 08:24:10		
1087	sgiwy	7		2014-12-10 08:24:10		
1088	bjsiw	7		2014-12-10 08:24:10		
1089	jippy	7		2014-12-10 08:24:10		
1090	mrjku	7		2014-12-10 08:24:10		
1091	plapd	7		2014-12-10 08:24:10		
1092	huiqq	7	Result:  Elements that don't exist in array A 1 2 3 4 5 6 11 Elements that exist in array A and their frequency 7: 1 8: 1 9: 8 10: 1	2014-12-10 08:24:10		
1093	ethan	7	I suspect this is impossible under strict definitions of O(1) space. There exist no sorting algorithms with worst-case parameters of O(n) time and O(1) space. Any solution to this problem would allow you to do a linear time, constant space counting sort where the range_of_numbers <= length of array. If you could do that, you should publish a paper.  As noted in comments I've made on other answers (e.g. storing negative numbers or a number larger than len(N) in an element), all solutions thus far provided stretch the definition of O(1) space and in the general sense are O(N).	2014-12-10 08:24:10		
1094	gilit	7	My solution is O(n) time and O(1) space. I did not sort the array.	2014-12-10 08:24:10		
1095	jippy	7	You have the same issue everyone else does. You are using numbers outside the domain, specifically negative numbers. Your algorithm requires an additional bit per element to store a sign bit.. N bits in total, meaning O(N) space complexity.	2014-12-10 08:24:10		
1096	fowai	7	My solution changes the input array. I did not use an extra array, so the amount of extra memory is constant.	2014-12-10 08:24:10		
1097	dkebi	7	@xuzheng:  To show that your algorithm (as a general algorithm) is O(n) space, let's use a simple counter-example. Java's a little weird in that you don't have unsigned types, so let's use C.   void elements(unsigned char * A) { ...  //Issue #1 A[i] = -1;  //Issue #2 A[A[i] - 1]--;   Let's say A has 255 elements; the domain for input numbers is 1-255. The issue #X lines both are problematic. You are going to underflow, as a negative is outside the domain. The subtraction creates a large positive number indistinguishable from your original input data -- causing the algorithm to fail.  This isn't so obvious if you use Java, as all integers in Java are signed. In this particular language, you just happen to have that an extra bit of unused space in each element in the input array which you can use for your purposes. But this is not true in general (as in the C example given above).  You cannot rely on such the input array being inefficiently stored. If it is efficiently stored (e.g. as an unsigned type), you must allocate N new bits to store that "count or input" flag.. making it an O(N) space algorithm.	2014-12-10 08:24:10		
1098	eucmc	7	The range 1 to n is a restriction on the input array, however this does not mean we can't change elements in the input array to an integer that is outside the range. Of course, this solution only works if I can make the assumption that the input is an array of signed integers.	2014-12-10 08:24:10		
1099	ewigy	7	How about that idea. If you encounter element on position i and it is not equal to i. Than you have to place value a[i] to position with index a[i] e.g a[a[i]] = a[i]. But if this position is already captured with right element you go forward. It is preproccessing made by O(n). The next cycle you just scan array, and if value of element with index i isn't equal to i it means that we haven't element with value i. Here is code of my solution.	2014-12-10 08:24:10		
1100	rrmeu	7		2014-12-10 08:24:10		
1101	rdfeo	7		2014-12-10 08:24:10		
1102	krxlv	7	Your solution is the same as my solution. I think it works well, but you forgot to print out the number of occurrences of the elements that do appear in the input array.	2014-12-10 08:24:10		
1103	fmzze	7	Yep,you are right. Your idea about counting is good))	2014-12-10 08:24:10		
1104	cfzie	7	This is solution on sorted array. Very basic but it is working fine.	2014-12-10 08:24:10		
1105	sqzqo	7		2014-12-10 08:24:10		
1106	tenuw	7		2014-12-10 08:24:10		
1107	admin	7	This is solution on sorted array. Very basic but it is working fine.	2014-12-10 08:24:10		
1108	zeice	7		2014-12-10 08:24:10		
1109	jippy	7		2014-12-10 08:24:10		
1110	gilit	7	My solution in c++ : we use the input array as a container for the counter. Elements i encoutered in the array is associated with a counter at position i-1.	2014-12-10 08:24:10		
1111	vanul	7		2014-12-10 08:24:10		
1112	nhibd	7		2014-12-10 08:24:10		
1113	eucmc	7	First, we need the array to store the count since space is limited at O(1). So we need A[i] to store the count for number i. But how can we distinguish the number itself and the count? We can use negative numbers to store the count. The O(1) space is a pointer to the array for the current number. The solution is raw, with O(1) space and O(n) time, without any sorting.  E.g.  [4, 3, 2, 3, 5] => [3,3,2,-1,5] => [2,3,-1,-1,5] => [3, -1, -1, -1,5] => [0, -1, -2 ,-1, 5] => [0,-1, -2, -1, -1]	2014-12-10 08:24:10		
1114	sgiwy	7		2014-12-10 08:24:10		
1115	fowai	7		2014-12-10 08:24:10		
1116	nhibd	7	my solution: {{ void prep(int arr, int n) { for(int i=0; i<n; ++i) { int v = arr[i]; if (!v || v > n) continue; arr[i] = 0; while(v && v<=n) { if (arr[v-1] > n || arr[v-1] == 0) { arr[v-1] += v; break; } else { int v1 = arr[v-1]; arr[v-1] = n+v; v = v1; } } } }  void print_dup(int arr[], int n) { for(int i=0; i<n; ++i) { if(arr[i]==0 || (arr[i]-n)/(i+1) == 1) continue; printf("pos[%d] dup times: %d\n", i+1, (arr[i]-n)/(i+1)); } } void print_missing(int arr[], int n) { for (int i=0; i<n; ++i) { if (!arr[i]) printf("%d missing\n", i+1); } }  }}	2014-12-10 08:24:10		
1117	ufdxg	7		2014-12-10 08:24:10		
1118	dgjji	7		2014-12-10 08:24:10		
1119	gilit	7	print missing is simple, check arr[i] == 0.	2014-12-10 08:24:11		
1120	jippy	7	{{ public static void findMissingNumbers(int array[]) { for(int i=0;i<array.length;++i) { if(array[i]!=(i+1) && array[array[i]-1]!=array[i]) { int temp = array[array[i]-1];  array[array[i]-1]=array[i];  array[i]=temp; --i; } } for(int i=0;i<array.length;++i) { if(array[i]!= i+1 ) { System.out.println("the number is not present " + (i+1) );  if(i==0) array[i] = ( i + 2); else { array[array[i]-1] = array[array[i]-1] + array[i]; } } }  for(int i=0;i<array.length;++i) {  if(array[i]/(i+1)>=2) { System.out.println("The number" + (i+1) + " repeated for " + array[i]/(i+1) ); } } } }}	2014-12-10 08:24:11		
1121	plapd	7		2014-12-10 08:24:11		
1122	nhibd	7		2014-12-10 08:24:11		
1123	sqzqo	7	}	2014-12-10 08:24:11		
1124	huiqq	7	package code_exercise;  public class CodeExercise5 { public static void main(String[] args) { // swap(a1, b1); int a[] = {10, 2, 2, 5, 3, 4, 9, 10, 9, 10, 5}; solve(a); }  public static void swap(Integer a, Integer b) { a ^= b; b ^= a; a ^= b; }  private static void solve(int [] a) { int tval = 0; // determine max val for (int i = 0; i < a.length; ) { if (a[i] > 0) { tval = a[a[i] - 1]; if (tval > 0) { if (a[i] - 1 == i) { a[a[i] - 1] = -1; } else { a[a[i] - 1] = -1; a[i] = tval; } } else if (tval <= 0) { a[a[i] - 1] += -1; a[i] = 0; i++; } } else { i++; } } for (int i = 0; i < a.length; i++) { System.out.println("NUM:" + (i+1) + ", OCC:" + Math.abs(a[i])); } } }	2014-12-10 08:24:11		
1125	tenuw	7	Clever, but I don't think the problem is fully defined. The size of the array is not specified as size N. If you were guaranteed values 1-n and an array specified as size n, then your solution would work. Still pretty clever.	2014-12-10 08:24:11		
1126	nhibd	7	It says that given an array of n integers. Below is the output generated for array arr[] = {6,4,1,4,3,2,5,2,1}; Element = 1 Frequency = 2 Element = 2 Frequency = 2 Element = 3 Frequency = 1 Element = 4 Frequency = 2 Element = 5 Frequency = 1 Element = 6 Frequency = 1 Element = 7 Frequency = 0 Element = 8 Frequency = 0 Element = 9 Frequency = 0	2014-12-10 08:24:11		
1127	ewigy	7	@someguy what does an array of N integers mean ?	2014-12-10 08:24:11		
1128	huiqq	7	My bad, was late misread	2014-12-10 08:24:11		
1129	nhibd	7	IS the array sorted??	2014-12-10 08:24:11		
1130	cfzie	7	#include<iostream> using namespace std; int main() { int a[]={3,3,2,1,1}; cout<<"repeated:"<<endl; for(int i=0;i<5;i++) { if((a[abs(a[i])-1]) > 0) { a[abs(a[i])-1]=- a[abs(a[i])-1];  } else { cout<<a[i]<<endl; } } cout<<"missing:"<<endl; for(int i=0;i<5;i++) { if(a[i]>0) cout<<i+1<<endl; } getchar(); return 0; }	2014-12-10 08:24:11		
1131	ufdxg	7	let's consider - 4,3,5,1,2,9,4,2,7,10 n = 10  start iterating the array like count sort with a slight modification that we add n^i to i-th array entry for each occurrence of i in th array- since n is 10 we will add 10^i so 4,3,5,1,2,9,4,2,7,10 will end up like - 4+10^1, 3+10^2+10^2, 5+10^3, 1+10^4+10^4, 2+10^5, 9+0, 4+10^7, 2+0, 7+10^9, 10+10^10  Now iterate the array from beginning dividing each entry by n^i, result will be the corresponding counts for integer i (0 will be for absent integers) - for index 1 - 4+10^1 mod 10 ^1 = 1 for index 2 - 3+10^2+10^2 mod 10^2 = 2 and so on resultant array is - 1,2,1,2,1,0,1,0,1,1 1 is present once, 2 is present twice ...6 and 8 are missing	2014-12-10 08:24:11		
1132	nwkeg	7		2014-12-10 08:24:11		
1133	ewigy	7		2014-12-10 08:24:11		
1134	zeice	7	I used the following algo in my code which the interviewer accepted at once ....  1.Start traversing the array . Let there be n elements and array be a[]. 2.if a[a[i]-1] > 0 and a[i] >0 , then make a[a[i]-1] negative . This will help to keep track of absent nodes . 3.else if a[i]>0 and a[a[i]-1] <0 , subtract n from a[a[i]-1] . This will help to keep the count of multiple visited nodes. 4. else if a[i]<0 and a[i] >= -n , subtract n from a[-a[i]-1]. 5. else if a[i] < -n , find subtract n from a[ (-a[i])%n-1 ] . 6. Now traverse the list and if any a[idx] is positive , that means number idx+1 isn't present in the array . 7. If a[idx] is between -n to -1 , that means idx+1 has occured only one time . 8. else if a[idx] is less than -n , that means idx+1 has occured ( int ) ( -a[idx]/n ) + 1 times .   P.S. I wasn't selected for the next round after telling this answer within 5 minutes .	2014-12-10 08:24:11		
1135	sqzqo	7	I had to clear 1 written 3 tech and 1 HR in total but I was ousted after the 2nd round of Interviews in which this question was asked .	2014-12-10 08:24:11		
1136	krxlv	7	campus placements for Blore team.	2014-12-10 08:24:11		
1137	nhibd	7	Voted up cause the solution is almost correct :) Please see note from <vishnuJayvel>, he is pointing out a very important case handling.	2014-12-10 08:24:11		
1138	dgjji	7	Use hash map.  it takes o(n) time and o(1) space. Correct me if i made mistake	2014-12-10 08:24:11		
1139	vanul	7		2014-12-10 08:24:11		
1140	plapd	7		2014-12-10 08:24:11		
1141	bjsiw	7	cheers Krishna	2014-12-10 08:24:11		
1142	fowai	7	You are using hashmap which is extra space, so O(1) space condition is violated.	2014-12-10 08:24:11		
1143	rdfeo	7	A very simple approach :	2014-12-10 08:24:11		
1144	sqzqo	7		2014-12-10 08:24:11		
1145	nhibd	7		2014-12-10 08:24:11		
1146	nhibd	7	little correction.. in the lower for loop condition will be : a[i]!=1+1	2014-12-10 08:24:11		
1147	nwkeg	7	little correction.. in the lower for loop condition will be : a[i]!=i+1	2014-12-10 08:24:11		
1148	rdfeo	7		2014-12-10 08:24:11		
1149	wbqzu	7	The solution you're suggesting is O(n) space due to aux array and the question states that there is O(1) solution.	2014-12-10 08:24:11		
1150	plapd	7	I don't know why this answer is downvoted.This seems to be correct answer.	2014-12-10 08:24:11		
1151	fowai	7		2014-12-10 08:24:11		
1152	mrjku	8	I presume that the probabilities of move up/donw/left/right are equal(0.25). Then P(x, y, n, step) = (P(x-1, y, n, step-1) + P(x+1, y, n, step-1) + P(x, y-1, n, step-1) + P(x, y+1, n, step-1)) / 4. (x, y) is the position. (n) is the size of island. (step) is the remaining step. The following code is my Java implementation with some simple tests. Dynamic Programming is also used.	2014-12-10 08:24:15		
1153	bexbp	8		2014-12-10 08:24:15		
1154	gilit	8		2014-12-10 08:24:15		
1155	wbqzu	8	How the probability for (0,0,1) be 0. As the (0,0) coordinate person can move to (0,1) or (1,0) in one chance. So according to the assumption of 0.25 probability for each move the total P = 0.50 (Person dies only in case he chooses (0,-1) or (-1,0))	2014-12-10 08:24:15		
1156	ethan	8	@ctrlV: dude u r calculating wrong..the code is correct... it is giving 0.5 probability.	2014-12-10 08:24:15		
1157	rdfeo	8	@ctrlV: (0, 0, 1) means the initial position is (0, 0) and the row/column of island is 1, which means the island contains only one position: (0, 0). Therefore (0, 1) and (1, 0) are also dead positions.	2014-12-10 08:24:15		
1158	azmjc	8	Idea of using DP with memorization is good, this should save us some time; btw, could we do it using tabulation approach? I am still thinking but couldn't make one yet.	2014-12-10 08:24:15		
1159	dgjji	8	What is complexity of this algorithm? O(n^2)?	2014-12-10 08:24:15		
1160	plapd	8	I think the time complexity for any solution to this problem should be exponential. Let me explain the mathematical way of calculating the probability here: The total number of outcomes are n^n. To calculate the number of outcomes which can lead to death of the person: For each of the four directions, check how many steps can lead to him going out of the matrix. Then, apply the high school probability formula. For e.g. suppose the total number of steps he can take are 5; (x, y) = (2,1) [indexing is 0-based]. So, he needs to take 3 steps in north dir. to fall out of island. Keeping them in a group: (NNN) and making other 2 steps as any of the 4 choices, we have the formula: 4*4*3. Similarly, for other 3 directions. Finally, the probality = (sum of the calculated death outcomes) / (total outcomes)  Hence, the complexity will be exponential.	2014-12-10 08:24:15		
1161	admin	8	the complexity should be O(n*N^2)	2014-12-10 08:24:15		
1162	ewigy	8	Make some simplification of Alva0930's code:	2014-12-10 08:24:15		
1163	wbqzu	8		2014-12-10 08:24:15		
1164	rdfeo	8		2014-12-10 08:24:15		
1165	azmjc	8	1. Generate NxN probability matrix P(x,y,1) for all (x, y) coordinates (x & y ranges from 0 to N-1). P(x,y,1) is the probability of staying alive after taking 1 step 2. Now using this, we need to calculate the NxN probability matrix P(x,y,2) for all x and y - will be P(x,y,1) * { {Valid among P(x+1, y, 1) + P(x, y+1, 1) + P(x-1, y, 1) + P(x, y-1, 1) } / num of valid adjascent slots }. Now we have P(x,y,2) probability matrix. 3. Using induction, we can calculate P(x, y, k) using P(x, y, k-1). Repeat this N times, we have our probability matrix after N steps	2014-12-10 08:24:16		
1166	qywrh	8		2014-12-10 08:24:16		
1167	bjsiw	8		2014-12-10 08:24:16		
1168	vanul	8	Believe this logic/code is correct. Please update if you find any issue	2014-12-10 08:24:16		
1169	rdfeo	8	Looks good. Also, there are lots of symmetries here that allow you to reduce storage. A simple way to cut the processing in half is to only consider squares where x <= y, and if you need P(x,y,n) where x > y, then just find P(y,x,n). You can also take advantage of horizontal and vertical reflections.	2014-12-10 08:24:16		
1170	cfzie	8	The N of the NxN matrix and the n of the n steps are different, I believe.  For large n (as compared to N) you might be better off using matrix multiplcation...	2014-12-10 08:24:16		
1171	sgiwy	8	Do we really have to store the values? static double probability(int x, int y, int n, int xmax, int ymax) { double result = 0.0; if (x < 0 || y < 0 || x >= xmax || y >= ymax) return result;  if (n == 0) return 1;  if ((x < xmax)) { result += .25 * probability(x + 1, y, n - 1, xmax, ymax); } if (x > 0) { result += .25 * probability(x -1, y, n - 1, xmax, ymax); } if (y > 0) { result += .25 * probability(x, y-1, n - 1, xmax, ymax); } if (y <ymax) { result += .25 * probability(x, y + 1, n - 1, xmax, ymax); } return result; }	2014-12-10 08:24:16		
1172	admin	8	I think , your answers are correct for 2,2 matrix the one you showed, but I doubt it will work for higher values. Just consider 3,3 matrix. The answer of the top left cell would be 0.1054 according to the induction but in reality its 0.28 (18/64). The number of possible moves is 64 and in only 18 (I counted) of them you will survive. Why 2,2 is working and the rest are not . What I think is this, again considering the top left cell, probability of surviving in two moves = probability of surviving in move1* probability of being in one of the two valid cells * probability of surviving in that cell in next move (probability of surviving in that cell in one move) + probability of surviving in move1* probability of being in the other valid cell * probability of surviving in that cell in next move (probability of surviving in that cell in one move) which is 0.5*0.5*0.75 + 0.5*0.5*0.75 which is the same thing you did.  But now (according to your algorithm) probability of surviving in top left cell in three moves = probability of surviving in that cell in two moves * probability of being in adjacent cell (which in your case we are always taking 0.5 (one of two valid cells) which is wrong because in two moves there are more valid cells that we can be in) * probability of surviving in that cell in two moves (which again does not make sense, you have already consider two moves , so now its two + two moves -- weird). The solution looks very impressive in the beginning which caught me for a long time but I still can't understand how its going to work for higher numbers.  Thanks	2014-12-10 08:24:16		
1173	fmzze	8	Actually found the correct equation  P(x,y,k) = P(x,y,1) * { {Valid among P(x+1, y, k-1) + P(x, y+1, k-1) + P(x-1, y, k-1) + P(x, y-1, k-1) }/ num of valid adjascent slots }. Note: The first term remain P(x,y,1) and not P(x,y,k-1) which means 1,1 matrix for the rest of soln. I guess you were saying the same thing. Anyways thanks for solution. I guess this is the only correct one we have so far.	2014-12-10 08:24:16		
1174	azmjc	8	@Arjun, see also: "Efficient Solution in Python (with tests)".	2014-12-10 08:24:16		
1175	eucmc	8	Is the complexity of this solution O(N^2 x n) ? We are calculating an NxN matrix n times. Please correct me if I'm wrong.	2014-12-10 08:24:16		
1176	ufdxg	8	Efficient Solution in Python (with tests)  This is a DP solution that only computes one octant of the matrix, since all the other octants are just reflections. It also defers dividing by powers of four until the end.	2014-12-10 08:24:16		
1177	wbqzu	8		2014-12-10 08:24:16		
1178	krxlv	8		2014-12-10 08:24:16		
1179	admin	8	The program's output shows that sample matrices for N=5.	2014-12-10 08:24:16		
1180	nwkeg	8		2014-12-10 08:24:16		
1181	gilit	8		2014-12-10 08:24:16		
1182	plapd	8	Please put in algo form for easy understanding of logic first.	2014-12-10 08:24:16		
1183	ewigy	8	you start with 1 at all the positions as in 0 steps all positions have 0 probability of dying.. then it uses the updation rule where val(x,y) = sum of all valids((val(x+-1,y+-1)) which is evaluating 1 step at a time	2014-12-10 08:24:16		
1184	sqzqo	8		2014-12-10 08:24:16		
1185	dgjji	8		2014-12-10 08:24:16		
1186	ethan	8	--> else if (n==0) return 1;  consider prob(0,0,1) = 1/2	2014-12-10 08:24:16		
1187	dkebi	8	Well my assumption was that n equals 1 meant no more steps allowed.. but yeah, 0 makes more sense, my bad.	2014-12-10 08:24:16		
1188	rrmeu	8		2014-12-10 08:24:16		
1189	vanul	8		2014-12-10 08:24:16		
1190	bjsiw	8	Exponential time complexity! Bad bad.	2014-12-10 08:24:16		
1191	sgiwy	8	@hello world you code fails in the very 1st section . ex (0,1,1) where ans should be 0.75 but your code will give 0.25. your if else conditions are intersecting among themselves...chk carefully	2014-12-10 08:24:16		
1192	bjsiw	8		2014-12-10 08:24:16		
1193	bexbp	8		2014-12-10 08:24:16		
1194	nhibd	8	Psuedocode for probabilityofdead :	2014-12-10 08:24:16		
1195	fowai	8		2014-12-10 08:24:16		
1196	nhibd	8		2014-12-10 08:24:16		
1197	nhibd	8	Hence ,probabilityofalive= 1- probabilityofdead	2014-12-10 08:24:16		
1198	eucmc	8	The probability can be higher than 1 in this case. You should divide by 4 to get the right answer	2014-12-10 08:24:16		
1199	nwkeg	8	Also, the recursive calls should use n-1 as a parameter. The probability of dying from a square in n steps when the first step is a neighbor involves the probability of dying in n-1 steps from the neighbor.	2014-12-10 08:24:16		
1200	ftfck	8	I am doing n--- check out..tht means n becomes n-1.	2014-12-10 08:24:16		
1201	jippy	8	A DP problem. Let's say the person is at (x0, y0) initially(instead of (x, y) in the question) Build a table W(n, N, N) whose entry W(k, x, y) is the number of ways to get to (x, y) from initial location(x0, y0) after k steps. Now, without considering the border,	2014-12-10 08:24:16		
1202	sqzqo	8		2014-12-10 08:24:16		
1203	zeice	8		2014-12-10 08:24:16		
1204	wbqzu	8	Then build W up to n steps, again, without considering the border. After that, just count the percentage of the locations (a, b) in W(n, a, b) that are out of the border, this is the probability.	2014-12-10 08:24:16		
1205	qywrh	8	can u write a pseudocode?	2014-12-10 08:24:16		
1206	fmzze	8	You have a to be a little careful about considering the border. Once you step off the island, you're dead, whereas if you only consider the water at the end of N steps, you can count situations where folks stepped into the water and out of the water.	2014-12-10 08:24:16		
1207	tenuw	8		2014-12-10 08:24:16		
1208	qywrh	8		2014-12-10 08:24:16		
1209	ethan	8	This can be solved using DP	2014-12-10 08:24:16		
1210	huiqq	8		2014-12-10 08:24:16		
1211	ewigy	8		2014-12-10 08:24:16		
1212	admin	8	can u elaborate more. this code doesnt seem to work for probability..	2014-12-10 08:24:16		
1213	qywrh	8	Dude, read question carefully. Do not jump immediately over writing the code!	2014-12-10 08:24:16		
1214	cfzie	8	Oh I am sorry. A little modification to the code. Please do let me know If I am making some mistake here. Starting from x,y, the initial inputs for the array will be x, y  int fall =0; int calProb(int n, int m, int **arr, int steps) {  if( m<0 || n< 0) { fall++; return 0; } else if(step ==0) return 1; else { return CallProb(n-1,m,**arr,step--) + CallProb(n,m-1,**arr, step--) + CallProb(n-1,m-1,**arr,step--); } }  Now we can calculate Let say the output of this function be livProb i.e. livProb = calProb(x,y, arr, n);  therfore living probability = livprob \ (livprob + fall)	2014-12-10 08:24:16		
1215	ufdxg	8		2014-12-10 08:24:16		
1216	wbqzu	8		2014-12-10 08:24:16		
1217	nwkeg	8	deadAkive is an array with two value: deadAlive[0] = number of times dead deadAlibe[1] = number of timesAlive	2014-12-10 08:24:17		
1218	rrmeu	8	change the order of helper base case:	2014-12-10 08:24:17		
1219	sqzqo	8		2014-12-10 08:24:17		
1220	azmjc	8		2014-12-10 08:24:17		
1221	jippy	8	Pseudo code  - Add x, y, N-x, N-y into sorted array - assume highest to lowest order is N-x, y, N-y, x for now - if n > N-x return 1 (means if person moves n steps at all any direction he will be dead) - if n < x return 0 ( means if person moves n steps any dir he will be alive) - if n is between N-x and y return .75 And so on	2014-12-10 08:24:17		
1222	wbqzu	8	My Idea : 1> For area outside the NXM, the death Prob is 1, what ever the step is. (step>=0) 2> For area inside the NxM and step=0, death Prob is zero. 3> For Other x, y, and step, probDeath(x,y,step)=1/4*(probDeath(x-1,y, step-1) + probDeath(x+1,y, step-1)+probDeath(x,y-1, step-1) +probDeath(x,y+1, step01)). Assume the person runs randomly. 4> The logic above also added a array to store the shared calculated result (as does dynamic programming) to save the computation time during the recursive call. 5> ProbLive(x,y, step)=1-ProbDeath(x,y,step).  My Code:	2014-12-10 08:24:17		
1223	eucmc	8		2014-12-10 08:24:17		
1224	eucmc	8		2014-12-10 08:24:17		
1225	nwkeg	8	Test Code: int main() { squareProb_t cb; double p1, p2, p3; squareProbInit(&cb, 2,2, 5); p1=squareProbDead(&cb, 0, 0, 1); p2=squareProbDead(&cb, 0, 0, 2); p3=squareProbDead(&cb, 0, 0, 5); printf("p1 is %f\n", p1); printf("p2 is %f\n", p2); printf("p3 is %f\n", p3);  }	2014-12-10 08:24:17		
1226	jippy	8	Test Result:Test Result of my code: p1 is 0.500000 p2 is 0.750000 p3 is 0.968750	2014-12-10 08:24:17		
1227	wbqzu	8		2014-12-10 08:24:17		
1228	plapd	8		2014-12-10 08:24:17		
1229	dgjji	8	This is Wrong:	2014-12-10 08:24:17		
1230	rrmeu	8		2014-12-10 08:24:17		
1231	eucmc	8		2014-12-10 08:24:17		
1232	rrmeu	8	Try making better use of O(n^3) space.	2014-12-10 08:24:17		
1233	nwkeg	8		2014-12-10 08:24:17		
1234	dgjji	8		2014-12-10 08:24:17		
1235	ethan	8	public static double prop2Alive(int x,int y, int N,int step){ if(x<0 ||y<0||x>=N||y>=N) return 0; else { if(step==0) return 1;  return (prop2Alive(x-1,y,N,step-1)+prop2Alive(x,y-1,N,step-1)+prop2Alive(x+1,y,N,step-1)+prop2Alive(x,y+1,N,step-1))/4; } }	2014-12-10 08:24:17		
1236	xhgls	8	This is my code, it could be optimized by only calling checkBoundary on the borders and exiting the main loop once you reach i==x && j==y && steps == n, but i was going for simplicity of the code here.	2014-12-10 08:24:17		
1237	xhgls	8		2014-12-10 08:24:17		
1238	ftfck	8		2014-12-10 08:24:17		
1239	gilit	8	Good Idea, but generalize your code where n != N. N: Size of matrix; n: no. of steps to take.	2014-12-10 08:24:17		
1240	fmzze	8	For below method, k: number steps. N: size of square matrix island.  Considering array alive[N][N][2], where each element in alive[i][j][steps%2] will keep count of the favourable cases. To calculate this count we just need the result from previous steps, i.e., top = alive[i-1][j][(steps-1)%2]; down = alive[i+1][j][(steps-1)%2]; left = alive[i][j-1][(steps-1)%2]; right = alive[i][j+1][(steps-1)%2];  So, favourable cases for alive[i][j][steps%2] = up + down + left + right;	2014-12-10 08:24:17		
1241	qywrh	8		2014-12-10 08:24:17		
1242	rrmeu	8		2014-12-10 08:24:17		
1243	sqzqo	8	update for last line:	2014-12-10 08:24:17		
1244	cfzie	8		2014-12-10 08:24:17		
1245	dkebi	8		2014-12-10 08:24:17		
1246	jippy	8	Model it as a graph search see how many nodes you visited and how many times you result in a death {{   def probabilityalive(x,y,nmoves,N): deaths,moves = getprob((x,y),nmoves,N,0,set()) return 1 - deaths/(1.0 * (moves - 1))  def getprob(xy,nmoves,N,depth,visited): if xy in visited or depth > nmoves: return 0,0 deaths = 0 x,y = xy if xy[0] > N-1 or xy[0] < 0 or xy[1] > N-1 or xy[1] < 0: return 1,1 moves = 1 visited.add(xy) successors = [(x,y+1),(x,y-1),(x-1,y),(x+1,y)] for s in successors: d,m = getprob(s,nmoves,N,depth+1,visited) deaths += d moves += m return deaths,moves  print probabilityalive(5,5,10,10)*100  }}	2014-12-10 08:24:17		
1247	rrmeu	8		2014-12-10 08:24:17		
1248	krxlv	8		2014-12-10 08:24:17		
1249	xhgls	8		2014-12-10 08:24:17		
1250	eucmc	8		2014-12-10 08:24:17		
1251	fowai	8	Create a quadrant decision tree from the current co-ordinate with depth = n. While you are constructing the tree, if a branch reached an out of bound condition, increase deadly branches count by 1. And then move backwards using recursion to construct the next branch and so on. The final count of the bad branches/ the total number of branches is your probability. This is similar to what is used in gaming.	2014-12-10 08:24:17		
1252	krxlv	8	public class Island { private int islandSize = N; public float getSurvivalProbability(int x, int y, int n) { if ( x < 0 || x > N - 1 || y < 0 || y > N - 1) { return 0; } else if (n == 0) { return = 1; } else { return 0.25 * getSurvivalProbability(x - 1, y, n -1) + 0.25 * getSurvivalProbability(x, y - 1, n -1) + 0.25 * getSurvivalProbability(x, y + 1, n -1) + 0.25 * getSurvivalProbability(x + 1, y, n -1); } } public float getDeathProbability(int x, int y, int n) { return 1 - getSurvivalProbability(x, y); } }	2014-12-10 08:24:17		
1253	rrmeu	8	This can be easily done using BFS. The equation I followed is as below: ProbAlive(after N steps) = ProbAlive(after 1 step) * ProbAlive(after 2 steps, given alive after 1 step) * * ... * ProbAlive(after N steps, given alive after N-1 steps)  To compute the term ProbAlive(after K steps, given alive after K-1 steps), BFS is used. When the BFS queue has only elements with positions for kth step, sample space is the queue-size. Iterate through all elements in the queue and if position is valid, add a probability of 1/queue-size to ProbAliveCurStep. During that time, enqueue all subsequent positions with step marked as k+1. Before processing queue with positions marked as k+1, update ProbAlive = ProbAlive * ProbAliveCurStep and reset ProbAliveCurStep.  e.g. For a 4x4 Matrix, max_step 2 and initial pos 0, 0 Iteration 1: Queue Contents: (x: 0, y: 0, step: 0) Pop Element: (0, 0, 0) Sample Space = 0; // Initial position is ignored for probability computation ProbAliveCurStep = 0; Enqueue Neighbours  Iteration 2: Queue Contents: (1, 0, 1), (-1, 0, 1), (0, 1, 1), and (0, -1, 1) Pop Element: (1, 0, 1) // Valid element, proceed Sample Space = 4 ProbAliveCurStep = 0.25 Enqueue Neighbours  Iteration 3: Queue Contents: (-1, 0, 1), (0, 1, 1) and (0, -1, 1) Pop Element: (-1, 0, 1) // Invalid element, continue ... ... After 13 iterations, ProbAliveCurStep for Step 1 = 0.5, ProbAliveCurStep for Step 2 = 0.75 ProbAlive = 0.357	2014-12-10 08:24:17		
1254	sgiwy	8		2014-12-10 08:24:17		
1255	dkebi	8		2014-12-10 08:24:17		
1256	nhibd	8	My solution in C++. We fill a matrix of size n*N*N in O(n*N^2) time :	2014-12-10 08:24:17		
1257	fowai	8		2014-12-10 08:24:17		
1258	admin	8		2014-12-10 08:24:17		
1259	vanul	8	Heres my attempt, not sure if its completely sound. Any advice would be greatly appreciated :)	2014-12-10 08:24:17		
1260	mrjku	8		2014-12-10 08:24:17		
1261	mrjku	8		2014-12-10 08:24:17		
1262	nhibd	8		2014-12-10 08:24:17		
1263	eucmc	8		2014-12-10 08:24:17		
1264	rrmeu	8		2014-12-10 08:24:17		
1265	bexbp	8		2014-12-10 08:24:17		
1266	tenuw	8		2014-12-10 08:24:17		
1267	nhibd	8		2014-12-10 08:24:17		
1268	dgjji	8	-----------------------------------  Unit tests:	2014-12-10 08:24:17		
1269	bjsiw	8		2014-12-10 08:24:17		
1270	plapd	8		2014-12-10 08:24:17		
1271	gilit	8		2014-12-10 08:24:17		
1272	nhibd	8		2014-12-10 08:24:18		
1273	mrjku	8		2014-12-10 08:24:18		
1274	sgiwy	8		2014-12-10 08:24:18		
1275	xhgls	8	Here is an O(1) solution:	2014-12-10 08:24:18		
1276	mrjku	8		2014-12-10 08:24:18		
1277	dkebi	8		2014-12-10 08:24:18		
1278	eucmc	8	Let the simplicity of the answer sink in.  Given a square matrix of size NxN, for any single direction, the probability of dying is 1/N -- that is to say, those on an edge will go into the water. There are four possible directions, each with the same probability, so 4*((1/4)(1/N)) still equals 1/N chance of death on any given turn, or (1 - 1/N) chance of survival.  To survive X times, we raise this probability to that power: (1 - 1/N)^X  Again, look at the code above. Not all problems need to be complex. If you get this problem, don't go right for the formula. Show a 1x1 grid and convince someone that the odds of survival are 0. Repeat this for a 2x2 and a 3x3. Do it for just one step. Why can we just multiply probabilities for subsequent steps? It's because there is an equal probability of landing on any square after a given round. This means that each round is independent, and we can reach back to our statistics classes wherein we learn the the probabilities of independent events can be multiplied to come up with the combined probability.	2014-12-10 08:24:18		
1279	mrjku	8	I like the way you're thinking but the question is the probability of dying when starting from a particular square. If I were the person on the island, I would pace in a circle or sit down so as not to fall off but apparently the movements are supposed to be random.	2014-12-10 08:24:18		
1280	fowai	9	Presuming a protocol exists that can ask three questions to each server:  * the score of a single url * the top 10 * the top n that satisfy score >= N  We program a two pass solution like so:  We denote the number of servers as S.  [First pass] (1) Ask every server for its own top ten  (2) merge the results. For all URLs in the merged set calculate correct values by asking all servers for their scores for each URL. Calculate a set of top ten from our sample.  (3) pick score of the now tenth URL as the threshold that we try to beat in the second round. We denote the threshold as T.  [Second pass] (4) Ask every server for all its top N that satisfy score >= T/S  (5) Merge these bigger samples again as in step (2)  (6) We now have the correct top ten with correct scores.	2014-12-10 08:24:23		
1281	jippy	9	I think they would expect a solution that spreads the work more uniformly among the different servers, which is hard with these constraints.  However, i think you have the merit of getting the right result. +1	2014-12-10 08:24:23		
1282	cfzie	9	Am not sure if this is going to work all the time. Please correct me if i am wong  X:Y Means Urls X has a count of Y We want top 2 uRLs  M/C A=> 1:100 2:96 7:98 M/C B=> 3:99 5:97 7:2 M/C C=> 4:98 6:95 7:2  1st Step A=>1,2 B=>3,5 C=>4,6  2nd Step Top two after merging 1,3 Urls are selected  3rd Step Threshold=99(Selected from url 3)  4th Step Score = 99/3=33 A=>1,2,7 B=>3,5 C=>4,6  5th Step Merging will again give us 1,3 when infact Url 7 has the highest count	2014-12-10 08:24:23		
1283	dgjji	9	Mihun, I think you're missing a step.  Step (2) says you merge the sets and *request* counts from all servers. This will give you the score of 102 for Url 7.	2014-12-10 08:24:23		
1284	wbqzu	9	Mithun, you made a mistake in your example and I think you misunderstood the suggested approach. M/C A=> 1:100 2:96 7:98 , so 1 and 7 would be the top 2.  Anyway, even if we change it to M/C A=> 1:100 2:96 7:94 M/C B=> 3:99 5:97 7:4 M/C C=> 4:98 6:95 7:4  Where 7 is the most visited site as you intended, the merging in 5th step implies that "For all URLs in the merged set calculate correct values by asking all servers for their scores for each URL", so we would get 102 as the count for url 7.	2014-12-10 08:24:23		
1285	krxlv	9	Oh okok.. got it.. So in the worst case if all URLs satisfy the score of > T/S, all the URLs will be sent to the server for merging right ?	2014-12-10 08:24:23		
1286	bjsiw	9	The approach is correct ... the only issue being that the solution will not scale and for a large number of machines the network traffic may be gargantuan. Consider an example with top ten counts in range of 1million and the number of servers in 10k range (which is not a big number considering the scale of amazon or google scale) so eventually you will ask for all URL which have count >= T/S which is 100 in this case. So you will end up sending a lot more data than is actually needed (as you will be sending URL for counts between 100 and 1 million). Also the bottleneck in such a solution would be central node processing this algorithm which wont scale but as I said earlier the solution is correct but not scalable.	2014-12-10 08:24:23		
1287	vanul	9	Thanks, vik, for your thoughts on scalability. I think this shows how open ended the question actually is. Without more knowledge about the topology of the machines, datacenters, loadbalancers, etc involved it is not possible to proof the quality and scalability of the algorithm in real life. A few things I would suggest to discuss about this:  - is it a typical weblog file? Typical weblogs have a steep declining start and a long flat tail, so the number of accesses on the tenth rank are usually high: if it is such a distribution, this algorithm is not bad.  - how biased are the loadbalancers? If the loadbalancers have a high degree of randomness built in, then the differences between the machines are statistically already similar enough that the first pass is quite good and the second pass is not much work.  - can clusters of machines be pre-merged? If racks or lines of racks can have a logserver that collects the full logs for the rack or line, then the number of servers to contact can be drastically reduced.  - how often are these calculations repeated? Which similar questions need to be answered? How often? How exact must the numbers be? How up-to-date? Each answer would influence the program and tuning we want to set up to produce fast and good numbers.	2014-12-10 08:24:23		
1288	sqzqo	9	Consider this example. Lets find the top 1 URL for now and we can extrapolate the question for top 10 URLs too.  3 Servers Server 1 : URL A-> 2 URL G->1 Server 2 : URL B->2 URL G -> 1 Server 3 : URL C -> 2 URL G -> 1  Wouldn't the above algo give URL A, B or C as the top visited URL where as the actual top URL should be G?	2014-12-10 08:24:23		
1289	vanul	9	Hi Izaaz, in your example the first pass finds the critical threshold T to be 2. The second pass would then calculate T=2 devided by S=3 and ask all servers for all URLs that have a score >= 2/3. In other words it would merge the complete set of URLs and thus get the URL G and the sum of the accesses to it in the second pass.	2014-12-10 08:24:23		
1290	bjsiw	9	Sorry if I miss something. But I don't think it's going to yield the correct result by selecting Top N with or without threshold. Considering the following case:  Server A Y1 - 11 Y2 - 11 Y3 - 11 Y4 - 10 Y5 - 10 Y6 - 9 Y7 - 9 Y8 - 9 Y9 - 9 Y10 - 9 ... G1  4  Server B M1 - 12 M2 - 12 M3 - 11 M4 - 11 M5 - 10 M6 - 10 M7 - 10 M8 - 10 M9 - 10 M10 - 10 ... G1 - 9   The threshold 10 / 2 = 5.  In the second pass, G1 in server A wont be included for tally. In fact, G1 with total 13 visits could be the top 1. But it does not even get into top 10 based on the method. Do I miss something?	2014-12-10 08:24:23		
1291	rrmeu	9	@aka777, G1 is not part of the top of server A but it will be part of the top of server B with visits >= 10 / 2. So, the algorithm will ask for all G1 occurrences in other servers and it will correctly put this as top1.  it will yield the correct result, with possibly the cost of multiple rounds.	2014-12-10 08:24:23		
1292	ftfck	9	Thanks, Miguel. I got it. Theoretically, the algorithm will yield correct result. But Google has more than one million servers. I don't know how this is gonna work out. (Threshold is gonna be very low like vik said.)	2014-12-10 08:24:23		
1293	dkebi	9	The constraints puzzle me a bit, especially the "using MapReduce directly, is not allowed" one. I would try to discuss what that means exactly in an interview. I'll give another shot at the question:  Denote N as the number of computers in our network.  1) Pick a good string hash function. This function must take urls as input and produce hash values uniformly in the range [0, MAX_HASH_VALUE]  2) Divide the hash range [0, MAX_HASH_VALUE] into N intervals with equal length MAX_HASH_VALUE / N, and assign each interval to 1 computer in the network, e.g. CPU_1) [0, length-1] CPU_2) [length, 2*length-1] CPU_3) [2*length, 3*length-1] ... CPU_N) [(N-1)*length, MAX_HASH_VALUE]  3) Each computer computes the hash values of its list of urls and sends the url and its visited information to the computer responsible by the hash of that url.  4) Each computer received a list of information url->visits for the urls in its hash interval. Now it must combine the visits of the urls and produce its top 10.  5) Each computer sends its top 10 to a central computer. This central computer will receive 10*N urls and compute the overall top 10.  Due to our good hash function, we expect that each computer will receive roughly the same amount of urls to process in the 4th step. I think this approach is the best we can do to distribute the work among the cluster.  About the constraints, they're not very clear. a) This is sending all urls over the network but not to a single computer. In order to produce an exact result, I think all approaches end up sending all urls over the network in the worst case. Again, we would need to discuss with the interviewer if this is ok (the "especially sending all of them to a central server" part).  b) This is similar to MapReduce. I think that by saying "using MapReduce directly is not allowed", the interviewer meant that we have to give a detailed explanation about how the work is distributed among the network of computers, instead of just saying "the MapReduce framework will distribute and combine the work for us".	2014-12-10 08:24:23		
1294	zeice	9	I think this is the only reasonable solution. The word "especially" in the phrase "especially to a central computer" seems to imply that sending the maps in a distributed manner might be acceptable, which is the only constraint this solution violates. It is the only solution that produces the correct result and is guaranteed (modulo the goodness of the hash function) to not send all the urls to the same server in the worst case.	2014-12-10 08:24:23		
1295	plapd	9	I think so as well. Someone -1 all my replies to this and a few other threads, for some reason, and I guess this reply was kind of forgotten.	2014-12-10 08:24:23		
1296	rrmeu	9	As you said , you are sending all of the urls on the network , which I guess is impossible as it's been said in the question. It works but it doesn't conform to the constraints.	2014-12-10 08:24:23		
1297	ewigy	9	This is the best solution I can come up with. It is effectively distribute the computations and traffic over the network. It does not need a central server.	2014-12-10 08:24:23		
1298	ufdxg	9	Isn't this similar to Map-reduce ?	2014-12-10 08:24:23		
1299	fmzze	9	what if two URLs have the same hash value??	2014-12-10 08:24:23		
1300	sgiwy	9	I don't think any of the suggested solutions are right. It is possible to imagine a situation where some url is ranked number 11 on every box, and so has very high visits overall, while every url in the top 10 on each individual box is seen nowhere else, so has low visits overall.  That said, I don't have any better ideas. This problem is hard!	2014-12-10 08:24:23		
1301	bexbp	9	The first pass gives you a lower bound. In the second pass, you will include that 11th url in your candidate set, since its overall visits is certainly greater than the 10th url found in the first pass.	2014-12-10 08:24:23		
1302	huiqq	9	Anon is correct. The second pass will not help. Take the following situation: 3 servers: SERVER A: URL #1 - #10 : 2 counts URL #0 : 1 count SERVER B: URL #11-#20: 2 counts URL #0: 1 count SERVER C: URL #21-#30: 2 counts URL #0: 1 count  now the first pass will find URL #1-#30 but not URL #0, this will be completely missed. Yet it is the winning URL, with 3 counts. Hence the whole strategy is flawed.	2014-12-10 08:24:23		
1303	plapd	9	langeolli: it the two pass solution I described, you miss rule number 4:  Ask every server for all its top N that satisfy score >= T/S  In your example, T=2 and S=3, so the threshold is < 1 and consequently all three servers will have to deliver their full logfiles and the result will find URL #0 to have 3 hits.	2014-12-10 08:24:23		
1304	gilit	9	I understand that with the given constraints it is not possible to get a trivial solution. but i thik we have to consider the senario where one url in the actual 10 top urls is visited by most of the machines but only a few times that will keep it out of the individual top 10 lists of each machine.  does that sound right?	2014-12-10 08:24:23		
1305	mrjku	9	I agree : This example would fail  Consider this example. Lets find the top 1 URL for now and we can extrapolate the question for top 10 URLs too.  3 Servers Server 1 : URL A-> 2 URL G->1 Server 2 : URL B->2 URL G -> 1 Server 3 : URL C -> 2 URL G -> 1  Wouldn't the above algo give URL A, B or C as the top visited URL where as the actual top URL should be G?	2014-12-10 08:24:23		
1306	bjsiw	9	You could possibly continually request the top urls until you have ten where the smallest value in the top10 list is not more then the highest value in any server using paginated sets. For example,:	2014-12-10 08:24:23		
1307	cfzie	9		2014-12-10 08:24:23		
1308	rdfeo	9		2014-12-10 08:24:23		
1309	ethan	9	Merge would keep no more than max values based on unique url and highest visits.	2014-12-10 08:24:23		
1310	plapd	9	I would recursively group the servers into sets of two and aggregate the URL's . Suppose there are 6 servers. a) Group s1s2, s3s4, s5s6. b) We know the entire map cannot be transmitted. Find out a safe message size for the network. Supposing n. Break the map in s1 into n size chunks and send over to s2. Similarly from s3-s4, s5-s6. c) This is the tricky part. The ques says we cannot do map-reduce directly. Does that mean map-reduce on the entire set? Is it allowed for individual machines? But it will be silly to solve this without ever getting a count of the URLs. So if map reduce is not allowed, write a procedure to sort the urls and track each one's count. This is done in s2, s4 and s6. d) Now, again group the machines. This time {s2s4}, {s6}. e) Repeat b, c . We will have s4, s6 left. Transmit from s4-s6 and perform a final count.	2014-12-10 08:24:23		
1311	ewigy	9	Lets assume, we can store count of k urls in the central machine. If the corpus is of size n, we get the top n/k elems from each server and send it to our central machine.  So, in our central machine, we have a set of k counters each initialized to 0 to start with. As we get our data from the stream, for every url, if it exists, we increment the counter. If not: case1: if there is size in our central machine to add the url, we add it and set its count case 2: if not, we delete the count of every url we have in the central machine. If there is any url that has a count of 0, we delete it.  Now, the moment we hit case 2 above, we record the max_count_so_far and take a snapshot of the top 10 elements.  We process the next set of top n/k elements from the machines and for every max_count_so_far elements we take a snapshot of the top 10 elements.  At some point, say after we have 10 such snapshots, we find the final top 10 elements from the snapshots we have so far	2014-12-10 08:24:23		
1312	plapd	9	On each server, we sort the urls based on their frequencies. Say total log file lines across all servers are N. Number of servers is s. Capacity of server is k. Now split the ranked urls such that there are k/s elems per group on each server. Label each group , there will be total N/(k/s) ids.  Now, from this set of ids, we randomly select s ids (i.e s groups) such that each id doesnt occur more than threshold times on one machine. (To keep it simple lets say threshold=1).  Now, we employ the following algorithm on the central machine: If there is size in our central machine to add the new group, we add it and set the count of each of the elems in the group. If not, we delete the count of every group/element in the group. We delete all urls that have a count of 0.  Now, one might argue that we might endup spending too much time on low frequency entries. We could then employ multiple iterations of elimination here. In the first pass, we can only consider frequencies that are above a certain threshold: say frequency above the median of the frequencies in each server. And divide those set of urls into groups. And consider random group from each server.	2014-12-10 08:24:23		
1313	bexbp	9	have a centralized counter. every time a new hit is recorded, recalc the centralized counter for that url with properly synced data structure. then compare it with the top10 hit stack by popping out the ones smaller than the current count result. keep updating the top 10 stack every time the new hit is recorded and you can always query the top 10 stack for the top 10 hits.	2014-12-10 08:24:23		
1314	nwkeg	9	I think that violates this "the maps are too large to transmit over the network (especially sending all of them to a central server "  there are too many visits to centralize a counter in one machine	2014-12-10 08:24:23		
1315	wbqzu	9	Lets say the number of servers is N. I think the solution requires 10 passes among the top ten scorers of each server. In each pass you can only identify one in the top ten. After each pass, the selected URL from the previous pass must be excluded from the evaluation in the subsequent passes, and the top ten scores from each server must be updated.  Think of the first pass. When all the top ten lists are considered, there must be at least one URL among these top tens which will land into the "real" top ten list. It is possible to generate scenarios where 9 of the real top ten list do not appear in the "current" top ten lists. But, there has to be at least one URL in the real top ten list which also appears in the 10N URLs that are collected from the servers' current top ten lists. Note that this is true only when N>=10. If N<10, all the real top ten list may not appear in the 10N URLs.  Also note that after collecting the 10N URLs, for some of them, you will have to ask the servers their frequencies so that you can sort the 10N URLs properly. Because, you want to sort the sum of visit frequencies of these URLs at each server.  After 10 such passes the real top ten list will emerge. The messaging complexity of each pass could be as bad as N^2 since you may have to collect the frequency values for each one of the 10N URLs. But, the computational complexity of each step is O(N) since you only need to find the max of 10N URLs.  If we were to design an algorithm that can find out not just 10 but the top K list. Then, we would be have to collect the top N scorers from each server .So, rather than 10N, we would bring together the top N^2 list at each pass. If K>N, this design is preferable.	2014-12-10 08:24:24		
1316	rdfeo	9	Here's a counter example where the top 3 does not appear in the top 3 of any of the 3 servers:  s1= { a:10, b:9, c:8, d:7, e: 6, f: 5 }, s2= { g:10, h:9, i:8, d:7, e: 6, f: 5 }, s3= { j:10, j:9, l:8, d:7, e: 6, f: 5 }  the top 3 is {d: 21, e: 18, f: 15 }, so that approach also does not guarantee 100% correctness	2014-12-10 08:24:24		
1317	wbqzu	9	Good example..  In the first pass, it will find a (or g or j). In the second pass, d will be in the first three of s1 since a is kicked out of s1's top three. So, the second pass will find d. The third pass will, in turn, find e. I can see, however, that f will not be included in the top three list after three passes.  We can update the algorithm as follows:  After a pass, if a new fellow is selected that places into an unexpected spot (i.e., item found in the i th pass places into a spot < i th place in the top items list), then we increase the total number of passes by one.  This should do it..  If not, I think making N^2 passes should do it.	2014-12-10 08:24:24		
1318	fmzze	9	Actually, even top N^2 may not do it.. :) Here is one more update to the algorithm I proposed:  Find the max value among all the lists: This should be easy to do. Findmax for all lists. Let's say that the max value is M.  Then, apply the iterative algorithm (with the extra check I described in my prev post) among the top lists of each server such that the top lists include all the values greater than or equal to M/N.	2014-12-10 08:24:24		
1319	sqzqo	9	Well, top N^2 lists will do it. :) But, cutting the top lists at M/N threshold will perform better on the avg case.	2014-12-10 08:24:24		
1320	qywrh	9	the logic is similar to tetris game algorithm. Or generalize voting algorithm.	2014-12-10 08:24:24		
1321	tenuw	9	We partition the work by using a hash on the url. The hash gives an address to an aggregator who is responsible counting a subset (as defined by the hash) of urls. Then we crawl through the aggregators and fill the top-ten list. As each url is mapped to exactly one aggregator the crawler only has to maintain a map with ten entries.  Step 1) send table with aggregator addresses: say we use 10k aggregators Step 2) on individual machine count all urls Step 3) on individual machine iterate through counted urls, find hash-key, modulo 10k gives you the address of responsible aggregator -> send to aggregator the count of said url. Step 4) aggregators accumulate the counts Step 5) initialize empty top-ten list, iterate through 10k aggregator machines and maintain the top-ten list	2014-12-10 08:24:24		
1322	ufdxg	9	The easy solution to solve this kind of problem is MapReduce. Since MapReduce is not allowed, the other alternative is to sort the string (url) ==> int (visits) in each machine independently such that it is the increasing order of visits. Then each server can send their top 10 visited URLs, Visit mapping to one of the server.  This single server would receive data from all the others for the top 10 visited sites and do a merge to decide on the top 10 sites. ( A n-way merge sort of the URL vs visits).	2014-12-10 08:24:24		
1323	nhibd	9	That's not correct. There could be a URL that is not in the top 10 for any one server, but is in the top 10 overall. See tony's response to Miguel Oliveira's answer.	2014-12-10 08:24:24		
1324	ethan	9	edit: this is does not guarantee 100% correctness  The question says we can't use MapReduce directly because the amount of data is too large. However, the overall top 10 sites are *expected* to be in the top 10 of at least one of the computers.  Hence, we can sort the logs of each computer and emit the top 10 of each computer in the mapping phase. Then, the reduce phase aggregates the number of visits for each site. The result will be the top 10 of the aggregate.	2014-12-10 08:24:24		
1325	ethan	9	This is wrong. Imagine the most frequent terms are	2014-12-10 08:24:24		
1326	vanul	9		2014-12-10 08:24:24		
1327	bexbp	9		2014-12-10 08:24:24		
1328	krxlv	9	Then the top three most frequent in the merged list should contain url4 as the top one though url4 is not the top three in any of the original lists.	2014-12-10 08:24:24		
1329	mrjku	9	yeah, Anon gave an example in his answer. These types of questions require some discussion with the interviewer. I don't see a way to do it in a very efficient way given the constraints, maybe those constraints were not so strict as it seems.	2014-12-10 08:24:24		
1330	qywrh	9	What if we manage a MaxHeap of top 10 sites at each node separately, and a heap of size 10 in central unit. The central heap can be updated according to :	2014-12-10 08:24:24		
1331	vanul	9		2014-12-10 08:24:24		
1332	cfzie	9		2014-12-10 08:24:24		
1333	bexbp	9	Then at every pre-specified interval, we can request updates from the nodes whose responses are the content of their respective MaxHeap.	2014-12-10 08:24:24		
1334	ftfck	9	the aggregated top 10 is not necessarily in the top 10 of a individual server. so it won't guarantee correctness	2014-12-10 08:24:24		
1335	nwkeg	9	We could use a BFS, visit every node and add sum of the integers to the master map that has all the URL's checking, if the URL is already present, then just add the integer orelse create a new key and put it into the map. Then traverse through the map to find the top ten values or just sort descending and return the first 10 values.	2014-12-10 08:24:24		
1336	sgiwy	9	"the maps are too large to transmit over the network (especially sending all of them to a central server (..)"  can't go that way	2014-12-10 08:24:24		
1337	tenuw	9	There are N number of machines, Determine top 10 in every machine. Each machine transmits its top 10 to every other machine i.e (n-1)10 urls This Implies each machine also recieves (n-1)10 urls  Process these and determine the top 10 in every machine.  Each machine now sends its Top 10 to a single place,(n*10) The top 10 among these (n*10) will be the most visited URL's  I do not know if there is any way to avoid not replicating the data on each machine. But will N*(N-1)*10 url's be too much traffic for the network to handle, cos that will be the total number of replications required.  Other possible solutions I could think of was using P-S pattern to publish count of URL's periodically.	2014-12-10 08:24:24		
1338	dgjji	9	that's quite similar to the approach i posted before. this does not guarantee 100% correctness. the aggregate top 10 does not need to be in the top 10 of any individual server.	2014-12-10 08:24:24		
1339	nwkeg	9	My bad, had not read any answers, before replying.	2014-12-10 08:24:24		
1340	azmjc	9	1. tag the nodes as n1, n2, n3..... nk 2. First n1 sorts its list of URLs to find top10 3. n1 sends this list to n2. n2 adds this list to the data set, and gets a top 10 4. now n2 sends its top10 (calculated in step 3) to n3 5. keep doing it till we reach nk  nk will have the cumulative top 10	2014-12-10 08:24:24		
1341	nhibd	9	it will not. check anon and tony's posts above.	2014-12-10 08:24:24		
1342	nwkeg	10	This can be solved using rope data structure. It's like a binary tree except that each node maintains the number of nodes in the left subtree+1 for itself. Whenever a new number is inserted, if the value is smaller than the node's number it goes to the left otherwise right. When it goes to the right, the value of the node is decreased by the value of the branch node. Ex Nodes: 6 5 4 3 2 1 values: 0 0 0 2 2 4 1. Make 6 as the root of the tree, its value = 1; 2. Insert 5. Value of 5(0) < value of 6(1) so it goes to the left. New value of 6 = 2, value of 5=1; 3. Insert 4, value of 4 < value of 6 so goes to the left; again goes to the left of 5. New values of 4 = 1, value of 5 = 2, value of 6 = 3 4. Insert 3, goes to the left of 6 but to the right of 5. New values 6 = 4, value of 3 = 1, rest unchanged 5. Insert 2, goes to the left of 6, right of 5 (value of 2 is decreased by value of 5 so its now 0), left of 3. New values of 3 = 2, value of 2 = 1, value of 6 = 5 6. Insert 1, goes to the left of 6, right of 5, right of 3. Do an in-order traversal of tree. It is imperative to insert the nodes in decreasing order	2014-12-10 08:24:28		
1343	azmjc	10	cool	2014-12-10 08:24:28		
1344	mrjku	10	very nice solution.	2014-12-10 08:24:28		
1345	bjsiw	10	why does a rope work here? doesn't seem very intuitive to use a rope...	2014-12-10 08:24:28		
1346	dkebi	10	Without balancing, the worst case is still O(n^2)	2014-12-10 08:24:28		
1347	sgiwy	10	Though I like the idea of sorting using the comparator as mentioned above by amitb2108 but below is the approach that came to my mind first. lets say height[] = {3,1,2,4} pos[] = {0,2,1,0}; //no of persons greater height than him 1. create an array of person struct of size n and fill the data from the above two arrays struct person { int height; int num; }; 2. Sort the person array with height as the key in decreasing order. o(nlgn) index 0,1,2,3 person[] = {4,3,2,1} {0,0,1,2} //person.num 3. Remember the index of array represents the no of persons greater in front of the current index. e.g. person with height 3 has array index 1, so 1 person is in front of him with greater height. But we need to have 0 no of person greater than 3, so swap it with index 0. person[] = {3,4,2,1} //after swapping 3 //2 has only one person in front but index of 2 is 2 currently there are 2 persons //swap it with index 1 person[] = {3,2,4,1} //1 has only 2 persons in front but index of 1 is 3, so currently there are 3 persons //swap it with index 2 person[] = {3,2,1,4} the idea is, previous index, has a person with greater height than current index. The previous index person's position is already set. Now if we move this previous index person towards right it doesn't impact the position of this person. e.g. person with height 4, if we move this person towards the right, still the no of persons with greater height will be 0. Total complexity = o(nlogn)	2014-12-10 08:24:28		
1348	fowai	10	I don't think your solution is O(nlogn).For instance: 4321 0011 as your idea step 1: 3421 step 2: 3241 step 3: It should be 3124. Then I realize that it shouldn't be swap. It's insert. Just insert person.height to arr[person.num] is ok. The insertion complexity = o(n^2)  Anyway, thanks for your idea!	2014-12-10 08:24:28		
1349	ethan	10	@dmxmails: The complexity can be further reduced if you use a clever data structure that supports fast insertion at an arbitrary position. This can be achieved using a modified skiplist (expected insertion time O(logN)) or a modified balanced binary tree for which we store the in each node the number of nodes in the subtree rooted at that node (worst case insertion time: O(logN)).  So, the final complexity of the algorithm would be O(N*log(N)).	2014-12-10 08:24:28		
1350	sqzqo	10	@dmxmails - in step 3, why it should be 3124? In 3124, 1 has only one person in front with greater height. But as per the input height[] = {3,1,2,4} pos[] = {0,2,1,0}, 1 should have 2 persons with greater height in front.	2014-12-10 08:24:28		
1351	azmjc	10	@dhiren.bhuyan my input is height[] ={4,3,2,1} pos[] = {0,0,1,1}	2014-12-10 08:24:28		
1352	dkebi	10	Newbie here. Can you explain how is the complexity O(n logn) ?	2014-12-10 08:24:28		
1353	fowai	10	If I understand correctly, you are swapping every element a with the element b in left holding a's actual position. But I guess just swapping will not work.you have to insert it in its proper position by shifting all elements from b to a.  try this example  9 9 8 7 5 4 3 2 0 0 0 3 0 5 1 7	2014-12-10 08:24:28		
1354	gilit	10	sort the person by the height if the count is not zero, swap the person on the right who is higher until the count become zero  time: O(n^2)  example 1  235461 020004  sort  123456 402000  swap 1  234516 020000  swap 3  245316 000000  example 2  3 1 2 4 0 2 1 0  sort  1 2 3 4 2 1 0 0  swap 1  2 3 1 4 1 0 0 0  swap 2  3 2 1 4 0 0 0 0	2014-12-10 08:24:28		
1355	dkebi	10	your solution does not work well for the example below, 235461 030004	2014-12-10 08:24:28		
1356	huiqq	10	You can sort the list of persons (person: height,numTallBeforePerson) using the following comparator:	2014-12-10 08:24:28		
1357	ftfck	10		2014-12-10 08:24:28		
1358	eucmc	10		2014-12-10 08:24:28		
1359	tenuw	10	The idea is that a shorter person standing after a taller one will have larger number of tall people before him than the taller person. Time complexity: O(n log n)	2014-12-10 08:24:28		
1360	azmjc	10	I don't think this problem can be solved in O(n log n). To indicate the bug in the above solution consider the following example. Assume people have heights from 1 to 20. Assume person with height 3 has rank 10 and person with height 5 has rank 9.  Then just by looking at 3 and 5 and their rankings you cannot conclude whether 3 is in front of 5 or 5 is in front of 3. It depends on where other elements are located. (You can actually construct two different examples where 3 is in front of 5 in one example and the other way around in the second example)	2014-12-10 08:24:28		
1361	sgiwy	10	i dont think the above solution for the input below I/P 235461 020004 O/P 245316	2014-12-10 08:24:28		
1362	krxlv	10	In two sequences below 5 and 3 have the same corresponding number in array B but their order is different. So the idea above is not correct (front of the array is the right side) 12435 12534	2014-12-10 08:24:28		
1363	fowai	10	>> You can sort the list of persons (person: height,numTallBeforePerson) Does this mean persons[i] = new Person(heights[i], count[i])? If it is the case, the solution is incorrect.  The simplest counter example: Input: A: [1, 2] B: [0, 1] The expected output should be: [2, 1] However, the solution outputs [1, 2]	2014-12-10 08:24:28		
1364	nwkeg	10	This is my code and this code can be used in any amount of integers in an array  public class class2 { public static void main(String args[]){ int arr1[]={3,5,1,6,7}; int arr2[]={0,1,1,2,3}; for(int i=0;i<arr1.length;i++){ for(int j=i+1;j<arr1.length;j++){ if(arr1[i]<arr1[j]){ int n=0; n=arr1[i]; arr1[i]=arr1[j]; arr1[j]=n; } } }  int arr3[]=new int[arr1.length]; int k=1; while(k<=arr3.length){  arr3[arr3.length-k]=arr1[arr2[arr3.length-k]]; arr1[arr2[arr3.length-k]]=0; for(int i=0;i<arr1.length;i++){ if(arr1[i]==0){ for(int j=i;j<arr1.length-1;j++){ arr1[j]=arr1[j+1]; } arr1[arr1.length-k]=0; break; } } k++; } for(int s=0;s<arr3.length;s++){ System.out.println(arr3[s]); } } }	2014-12-10 08:24:28		
1365	huiqq	10	Backtrack.  Let's say the first array is height array and the second is count array. Sort the count array from low to high (say [0,1,1]). Start from the first height 3 (corresponding to count 0), the root node of the backtrack tree is (3), then insert the second height 2, generating one child node (3,2). Then insert the third height 1, generating one child node (3,1,2). If a node does not generate any child node, then it is an dead end. In this case, backtrack to the upper level node to visit its next child node.  This way you can find all possible sequences satisfying the two arrays. And you can confidently know if there is no such sequence at all.	2014-12-10 08:24:28		
1366	nwkeg	10	My algorithm: Time -- O (N LOG N) & Space --O(N) .. please let me know your comments... it seems to work for all cases, let me know if I am missing something...  Approach:  (1) Sort the input in descending order of size -- O(N LOG N) (2) Use a stack based approach -- O(N) : (find below)  Given:  A[] = {1,2,3,4,5} b[]= {3,1,1,1,0}  Step 1: Sort A (and hence B) --> A[] = {5,4,3,2,1} B= {0,1,1,1,3} // Here, this is still O(N.LOG N)  Step 2: Stack based algorithm (Say have 2 stacks: S1->stack.new, S2->stack.new)	2014-12-10 08:24:28		
1367	ufdxg	10		2014-12-10 08:24:28		
1368	nhibd	10		2014-12-10 08:24:28		
1369	nwkeg	10	Let: A[] = {5, 4, 3, 2, 1} B[] = {0, 0, 0, 0, 0}  Then your solution is O(n^2)	2014-12-10 08:24:28		
1370	mrjku	10	@Marathon -- interesting observation :) ... let me check this and get back with some improvement !	2014-12-10 08:24:28		
1371	xhgls	10	all persons height are unique how about persons with the same height.	2014-12-10 08:24:28		
1372	nwkeg	10	int main (int arc, char * argv[]) { int arrHeight[] = {3,2,1}; int arrKeyGiven[] = {0, 1, 1};  int i, j, temp = 0, length = 0;  length = 3;//4;   /** LOGIC FOR RESETING THE POSITION ACCORING TO THE KEY GIVEN if Current position < keyPostion then : do one swap with teh previous one :) else : do one swap with the next one :) **/  for (i = 0; i < length; i++) { if ( arrKeyGiven[i] < i) { temp = arrHeight[i]; arrHeight[i] = arrHeight[i-1]; arrHeight[i-1] = temp; } } printf("REPOSITIONED ARRAY IS \n"); for (i = 0; i < length; i ++) printf("%d\t", arrHeight[i]);  return 0;  }	2014-12-10 08:24:28		
1373	ufdxg	10	THIS IS THE MODIFIED LOGIC:----- WORKS WELLL :) please have one try by assigning some logically correct values to arrHeight, and arrKeyGiven and see the result...if any issues plz revert to jitu059@gmail.com U need to edit, arrHeight/arrKeyGiven and length to test more problems ################################# int main (int arc, char * argv[]) { int arrHeight[] = {3,1,2}; int arrKeyGiven[] = {0, 2, 1};  int i, j, temp = 0, length = 0;  length = 3;//4;   /** LOGIC FOR RESETING THE POSITION ACCORING TO THE KEY GIVEN if keyPosition < Current Position then : do one swap with teh previous one :) else if keyPosition > Current Position then : do one swap with the next one :) else : DO NOTHING......current position is desired one :) **/  for (i = 0; i < length; i++) { if ( arrKeyGiven[i] < i) { printf("Swaping in process\n"); temp = arrHeight[i]; arrHeight[i] = arrHeight[i-1]; arrHeight[i-1] = temp; } else if( arrKeyGiven[i] > i) { temp = arrHeight[i]; arrHeight[i] = arrHeight[i+1]; arrHeight[i+1] = temp; } } printf("REPOSITIONED ARRAY IS \n"); for (i = 0; i < length; i ++) printf("%d\t", arrHeight[i]);  return 0;  }	2014-12-10 08:24:28		
1374	gilit	10	u code appears to be wrong for this input heights=[33 ,11 ,22 ,44 ,55 ]; rank=[0 ,2 ,1 ,1 ,0 ];  output=[33 ,22 ,11 ,55 ,44 ]	2014-12-10 08:24:28		
1375	wbqzu	10	Given Hight Arrays H[], Queue Arrays Q[], Return Output O[] 1. Sort H in desc order as H' 2.Loop while N--; pick Q[N] th element of H' as O[N]; adjuct H' // remove H'[Q[N]] in H'	2014-12-10 08:24:28		
1376	krxlv	10	Isn't the question incorrect: if the heights are 3,2,1 in some height-units, shouldn't the array be 0,1,2 - representing no one in front of 3, 1 guy in front of 2 and 2 guys in front of 1. Or maybe i am missing something that rest everyone is not - pls enlighten	2014-12-10 08:24:28		
1377	tenuw	10	The second array doesn't just indicate how many guys are standing in front of a particular guy, but specifically the number guys standing in front who are of *greater height*. So, even though guy of height 2 has two guys in front of him, there's only 1 guy in front of him of greater height.	2014-12-10 08:24:28		
1378	bexbp	10	I found that the max element is at the rightmost position(call pos) whose value is zero in the array b, so everytime I insert the max element of the remaining elements, and all the elements on the right of pos in b should decrement by one, because one max element is eliminated on the left, and carry on untill no elements left in a, and here is my code:(O(n^2), I think my algorithm supports duplicate heights)	2014-12-10 08:24:28		
1379	tenuw	10		2014-12-10 08:24:28		
1380	ftfck	10		2014-12-10 08:24:28		
1381	ethan	10	How about next idea. The last element of second array - let call it array of inversions in following, is always that we have in desc order. For example. 3 2 1. 2 0 1 1 - is element with index 1 in desc order. so it must be placed the in that way: * * 2 0 1 * so 1 - is element with 1 index in desc order without 2. it must be placed there * 1 2 and following 3 1 2  We process array from right to left. element i must be placed with element from first array without already processed element in desc order.	2014-12-10 08:24:28		
1382	fmzze	10	Use an order stastisc tree: - Insert all the heights into an order statistic tree - for i from B.length -1 to 0: - what is the B[i] order statistic value in the order statistic tree - remove that value from the tree and insert it into the results array at i  Time is nlogn (n queries for order statistics) Space is n (order statistic tree size)	2014-12-10 08:24:28		
1383	bexbp	10	Another O(n logn) time and O(n) space solution. Please correct me if there are issues.	2014-12-10 08:24:29		
1384	ewigy	10		2014-12-10 08:24:29		
1385	tenuw	10		2014-12-10 08:24:29		
1386	wbqzu	10	One solution: Every time, select the smallest number with front[] = 0. e.g. height[] = {3, 1, 2, 4}, front[] = {0, 2, 1, 0} 1) Find the smallest number from height[] that has 0 in front[], in this case it is 3, then 3 is 1st element in the queue. 2) For rest of the elements i in height[], if it is smaller than 3, then front[i] - 1, otherwise keep front[i] the same. Go back to 1)  This is pretty much like topological sorting; each time remove the node with indegree == 0.	2014-12-10 08:24:29		
1387	admin	10	Observe that in any arrangement of heights, the smallest element can have one and only one spot to go.  eg. { 3, 1, 2, 4 } {1, 2, 2, 0}  1 is the smallest element and needs to have 2 elements ahead of it. All other elements are larger, so it must only be able to go into ar[2]. After placing 1 in ar[2], count 2 empty spaces, skip 2 because it's taken and place 2 into ar[3]. 3 needs 1 empty space and goes into ar[1] and 4 into ar[0].  Fail if there are no available spots. Collisions or cases like  { 3, 1, 2, 4, 1 } {1, 2, 2, 0, 2}  are handled elegantly by the space counting.  Unoptimized this is O(n^2).	2014-12-10 08:24:29		
1388	cfzie	10	Here is a python code that runs in O(n logn) time. If you use some sorting algorithm, say radix sort, that runs in O(n) time, then this algorithm will take O(n) time.	2014-12-10 08:24:29		
1389	dgjji	10		2014-12-10 08:24:29		
1390	xhgls	10		2014-12-10 08:24:29		
1391	tenuw	10	Consider line[] array where people have to be placed.  Assumption : all people have distinct height from 0 to N-1. so sort A and hence B array (along with A) in increasing order.  Now A=[0,1,2,3,4...].  So, now we can ignore A[] and only consider B[] ans array where B[i] is = number of people with greater height in front that person of height i.  Now, in line[], 0th person will be at index B[0] since there are exactly B[0] person > than 0th person. For second largest person if B[1] < B[0] 1 ahead of 0th person in line[]. else after 0th person. Eg  if B=[3,2,....] line = [--10-------] - is space to be taken by others. 0th person took 4th free seat. 1st took 3rd free  if B=[3,3,....] line = [---01------] => 0th person took 4th free seat. 1st took 4th free seat, after 0 took its seat. so 1 basically took 5th seat  notice how 1 after 0 in line.  So basically you have a set of free seats and each person comes and takes whatever is left.  So Algo : put 0th person at index B[0] in line[]. remove B[0] index from line[] from free seat list. next for ith person, traverse whatever free spaces are left in line[] from index 0 and place them there. pseudo code :	2014-12-10 08:24:29		
1392	ufdxg	10		2014-12-10 08:24:29		
1393	bjsiw	10		2014-12-10 08:24:29		
1394	tenuw	10	Above is O(N*N)  can be reduced to O(N) is we can find out in O(1) which seat index a person will get currently if he has to skip x seats  O(nlogn) : Consider line as a skip linked list. node has value 0 to N-1. for each person , given x seats to skip - find xth node using bin search on skip list. delete that node. update skip list.  O(nlogn) : See line as a balanced BST. nodes have value of index 0 to N-1. each node also has the value 'number of nodes in this tree' in tree rooted at it.  construct N node such balanced BST in O(N) (yes, find out how this can be constructed in O(N) yourself) (or to simplify , make in O(logn))  Sort A hence B in inc order. Take B[i] for ith smallest person. Delete B[i]th "number" (not value) of node from the tree. this nodes value = persons index in line. Also update 'number of nodes in this tree' for all nodes effected by delete - O(logn) per person. total nlogn.	2014-12-10 08:24:29		
1395	ewigy	10	My take on this  1. we need to arrange the numbers based on the index difference given {3,2,1}->{0,1,1} means {3} has none taller in front, {2} has 1 taller, {1} has 1 taller so {3}>{1}>{2} or (3 greater than 1 greater than 2)  2. {5,4,3,2,1}->{0,0,0,0,0} means {5} has none taller in front, {4} has none taller in front, {3} has none taller in front, ... so {1}>{2}>{3}>{4}>{5}  3. {5,4,3,2,1}->{0,1,2,3,4} means {5}>{4}>{3}>{2}>{1}  4. looking at the options above we can easily build an iteration to move the person to the index on the second array, taken the example {3,2,1}->{0,1,1}, steps are -move {3} to position 0 - nothing to do -move {2} to position 1 - nothing to do -move {1} to position 1 - move {1} to position 1, {2} will need to move 1 position down  algorithm is quite simple	2014-12-10 08:24:29		
1396	huiqq	10		2014-12-10 08:24:29		
1397	cfzie	10		2014-12-10 08:24:29		
1398	zeice	10	Below should be true	2014-12-10 08:24:29		
1399	vanul	10		2014-12-10 08:24:29		
1400	krxlv	10		2014-12-10 08:24:29		
1401	plapd	10	Variant of tree travel/shortest path/bfs. with number of element in front as level. and on each level shortest first. or just sort the elements by value and then stable sort on number of elements greater	2014-12-10 08:24:29		
1402	bexbp	10	My solution is in O(2n)	2014-12-10 08:24:29		
1403	eucmc	10		2014-12-10 08:24:29		
1404	tenuw	10		2014-12-10 08:24:29		
1405	gilit	10	C++	2014-12-10 08:24:29		
1406	nwkeg	10		2014-12-10 08:24:29		
1407	qywrh	10		2014-12-10 08:24:29		
1408	rdfeo	10		2014-12-10 08:24:29		
1409	krxlv	10		2014-12-10 08:24:29		
1410	ftfck	10	O(n^2) 1. sort persons by height and num greater before 2. find place for each person (from short to high)	2014-12-10 08:24:29		
1411	eucmc	10		2014-12-10 08:24:29		
1412	jippy	10		2014-12-10 08:24:29		
1413	xhgls	10	O(n^2) 1. sort persons by height and num greater before 2. find place for each person (from short to high)	2014-12-10 08:24:29		
1414	tenuw	10		2014-12-10 08:24:29		
1415	huiqq	10		2014-12-10 08:24:29		
1416	sgiwy	10	I think an elegant solution to this problem would be to sort the array of heights and also put array B in that order O(nlogn)  Make another array of size n as our position array. Then get the element of the smallest height and see how many people are in front of him and place him into the index of that our position array.  Keep taking the next smallest element with x people in front of him. Start from the beginning of the array and count x non filled spaces in the array and place it there.  This is because the non filled spaces in the array will have height greater than that of our element while the filled spaces will have height less than our element so we can ignore those elements.  So our overall complexity is O(nlogn)	2014-12-10 08:24:29		
1417	cfzie	10	With checking each element of the array if it has filled or not for all n elements would take O(n^2). could someone think of a way to make checking filled spaces O(logn)?	2014-12-10 08:24:29		
1418	ftfck	10	I have a very simple O(nlogn) solution I'm finding difficult to explain  Calculate a prefix big enough so that it's bigger than every other number prefix = pow(10, ciel(log10(n)) + 1))  now create an array where each cell's value is height + prefix * number_heigher_infront  Now, sort the new array ascending and remove from each number (prefix * number_heigher_infront)  Voila!	2014-12-10 08:24:29		
1419	bexbp	10	My solution in C++. The list of (Heights, Count of people in front) is sorted based on the height. Then each person is added - in order - at the position given by the count of people in front of him. We maintain a "jump" table at each step in order to jump over position occupied by a smaller person. The algorithm time complexity is O(n log n). Reviews are welcome :	2014-12-10 08:24:29		
1420	plapd	10		2014-12-10 08:24:29		
1421	bexbp	10		2014-12-10 08:24:29		
1422	qywrh	10	There is a bug in my previous answer in the way the jump list is maintained. Here is a better solution using a binary search tree to maintain the available positions set (I used a C++ set<int> which relies on a BST). This solution has O(n log n) time complexity.	2014-12-10 08:24:29		
1423	rrmeu	10		2014-12-10 08:24:29		
1424	rdfeo	10		2014-12-10 08:24:29		
1425	nhibd	10	for the case vector<int> Heights; Heights.push_back(6); Heights.push_back(1); Heights.push_back(11); Heights.push_back(5); Heights.push_back(10); Heights.push_back(4); vector<int> Counts; Counts.push_back(2); Counts.push_back(4); Counts.push_back(0); Counts.push_back(1); Counts.push_back(0); Counts.push_back(0);  your ans return 4,5,6,10,1,11; but the right answer is 4,10,5,11,1,6.	2014-12-10 08:24:29		
1426	admin	10	I solved it by recursive form. These are persudo code.	2014-12-10 08:24:29		
1427	tenuw	10		2014-12-10 08:24:29		
1428	zeice	10		2014-12-10 08:24:29		
1429	dgjji	10	solution: create a binary tree using following steps: consider second array the one with no of peoples having more height as a priority for the first array.. now move one by one in array 1 and insert elements like this 1.if priority is greater move to right or less move to left 2.if priority is same move to right if height is greater else move left 3.balance the tree O(nlogn) ....... inorder is the answer...	2014-12-10 08:24:29		
1430	zeice	10	I'm using LinkedList for the this. Sort the tallCount[] in ascending order and accordingly re-position the items in heights[]. This is capable of handling the duplicate elements also.	2014-12-10 08:24:29		
1431	vanul	10		2014-12-10 08:24:29		
1432	tenuw	10		2014-12-10 08:24:29		
1433	azmjc	10	I get a O(N^3) algorithm. The idea is just search all possible arrangements, upon number of taller violation, backtrack.	2014-12-10 08:24:30		
1434	huiqq	10		2014-12-10 08:24:30		
1435	wbqzu	10		2014-12-10 08:24:30		
1436	dkebi	11	int atoi(char *p) { int total = 0; int i=0; while(p[i] != '\0') { total *= 10; total += p[i] - '0'; i++; } return total; }	2014-12-10 08:24:31		
1437	bjsiw	11	Not bad as long as you don't pass in a sign, or null, or characters other than digits. :) Granted an interviewer is probably just looking for what you did.	2014-12-10 08:24:31		
1438	mrjku	11	last time I got an interview with Microsoft. The interviewer pointed out that you need to take care the sign, the base and actually need to handle every error case.	2014-12-10 08:24:31		
1439	dgjji	11	int isDigit16(char* p) { return isDigit10(p) || ((*p) >= 'a' && (*p) <= 'f') || ((*p) >= 'A' && (*p) <= 'F'); }  int atoi(char* p) { int cur; int sign = 1; int base = 10; int total = 0;  if (!p || !p[0]) return 0;  while (p[cur] == ' ' || p[cur] == '\t') cur++;  if (!p[cur]) return 0;  if (p[cur] == '-') { sign = -1; cur++; }  if (p[cur] == '0') { if (p[cur+1] == 'x' || p[cur+1] == 'X') { base = 16; cur += 2; } else { base = 8; cur++; } }  while (p[cur]) { switch(base) { case 8: if (isDigit8(&p[cur]) { total = total * 8 + p[cur] - '0'; break; } else return sign*total; case 10: if (isDigit(&p[cur]) { total = total * 10 + p[cur] - '0'; break; } else return sign*total; case 16: if (isDigit16(&p[cur]) { int d = (p[Cur]<='9')?(p[cur]-'0'):(((p[cur]<='F')?p[cur]-'A':p[cur]-'a')+10); total = total * 16 + d; break; } else return sign*total; } cur++; } return sign*total; }	2014-12-10 08:24:31		
1440	sgiwy	11	forget to copy some of the prerequisites int isDigit10(char* p) { return (*p) >= '0' && (*p) <= '9'; }  int isDigit8(char* p) { return (*p) >= '0' && (*p) <= '7'; }	2014-12-10 08:24:31		
1441	dgjji	11	damn, forget to handle the overflow	2014-12-10 08:24:31		
1442	plapd	11	check the official atoi spec, out of range result in undefined behavior. So the above implementation should be fine.	2014-12-10 08:24:31		
1443	gilit	11	Language: C++ Method: - Get the length of the cstring - Based on the length, we can figure out the base to start with. For example '123', gives a size of 3, therefore the starting base will be pow(10,3); - In the for-loop, we decrease base as we go down the char array - Multiply each (ascii code - ascii code ('0')) with the base; - Add the result to the variable temp (that keeps incrementing as we add values);	2014-12-10 08:24:31		
1444	ethan	11		2014-12-10 08:24:31		
1445	xhgls	11		2014-12-10 08:24:31		
1446	qywrh	12	I can think of two approaches:  First approach - A naive approach using an adjacency map  The adjacency map is a Map whose keys are vertices and whose values are sets of vertices which are all the neighbors of the key vertex. For every vertex, we'll check for every pair of its neighbors whether there is an edge between them and increment the triangle counter if so.  The total number of triangles will be the number of triangles we counted divided by 6 (we count each triangle 6 times).  Code:	2014-12-10 08:24:33		
1447	ufdxg	12		2014-12-10 08:24:33		
1448	rdfeo	12		2014-12-10 08:24:33		
1449	ewigy	12	Complexity: The overall run-time complexity is O(n*d^2) where n is the number of vertices and d is the maximum degree of a vertex in the graph. This is a good approach for graphs with small maximum vertex degree. But if the graph contains a vertex whose degree is O(n) then the overall complexity in this case would be O(n^3).    Second approach - Using matrix multiplication  Suppose A is the graph's adjacency matrix (A[i][j] = 1 if and only if there is an edge between i and j in the graph). It can be shown that trace(A^3)/6 is the number of triangles in the graph (using the fact that A^k[i][j] is the number of paths with k edges from i to j). This means that all we need to know the number of triangles is to calculate the matrix A^3 and its trace.  This means that our algorithm complexity would depend on the complexity of the matrix multiplication algorithm: Naive: O(n^3) Strassen: O(n^{2.8074}) Coppersmith-Winograd: O(n^{2.3729})  I can post a code for this approach using Strassen matrix multiplication but it's rather long and isn't pretty.	2014-12-10 08:24:33		
1450	gilit	12	Wow man, that matrix approach is brilliant!	2014-12-10 08:24:33		
1451	rrmeu	12	Matrix approach is standard. But agree, it is brilliant.	2014-12-10 08:24:33		
1452	fmzze	12	You must pay attention to the fact that Strassen and the other matrix multiplication algorithms are great asymptotically speaking but have a big overhead. You don't want to use them for matrices with size below 1000. I don't know if this practical consideration was part of the question, but in real life, one should keep this in mind before choosing to implement the "best" complexity algorithm. Personally I would stick to the naive approach which is way more readable.	2014-12-10 08:24:34		
1453	dgjji	12	1. The undirected graph can be represented as: class Vertex { List<Vertex> Adjacents; } 2. Traverse the undirected graph as BFS - Use a queue to traverse - Use a hash to track the vertices already visited 3. if current = current vertex - get all adjacent vertices to current - count the number of common vertices in current.adjacents (I remove the processed adjacent node to avoid counting the same vertex twice)	2014-12-10 08:24:34		
1454	sgiwy	12		2014-12-10 08:24:34		
1455	bjsiw	12		2014-12-10 08:24:34		
1456	qywrh	12	Nice one! But your solution assumes that no three vertices will be on same line. And also there is no notion of length ( the question does not have this notion also )	2014-12-10 08:24:34		
1457	ewigy	12	deep-first search. record the last two steps to judge the triangle.	2014-12-10 08:24:34		
1458	krxlv	12	Hi can you explain your approach in a little more detail.	2014-12-10 08:24:34		
1459	rdfeo	12	Let me explain. If there is a triangle then its a closed loop. So from any vertex if i go 3 steps and reach it back then there is a closed loop of 3 edges => triangle. Now Since you will do this for all vertices of the graph final output will be number of triangles you found / 3 The scanning of the graph is done by DFS for this problem.	2014-12-10 08:24:34		
1460	bjsiw	12	Total amount of visited edges is O(E), triangles is about O(V^3).	2014-12-10 08:24:34		
1461	xhgls	12	Does not work.	2014-12-10 08:24:34		
1462	admin	12		2014-12-10 08:24:34		
1463	vanul	12		2014-12-10 08:24:34		
1464	zeice	12	There are two things not explained in the problem: 1) Nodes have no X-Y locations. In Theory, there is no way to check it is a thriangle or not. In a Line or Not? 2) Is the memory a bottleneck?  Assume the two are not issues. Then the solution comes: A: Using Matrix to store Graph in the Memory. (it is always faster). B: The algorithm is: 1) New an empty std::unordered_set<std::string> to keep all triangles. ---------------- 2) Loop each node (v1) in V. [Big-O: O(n)] 3) For each pair of connected nodes (v2 and v3). [Big-O: O(d^2), d is the average node degree] 4) Check whether v2 and v3 are connected. [Big-O: O(1)] 5) If 4) get 'YES', then sort the node IDs and push the new triangle into unordered_set. [Big-O: O(1)] ---------------- 6) Finally, output triangles in the unordered_set. [Big-O: O(n)]  Thus, the total cost is Big-O: O(n * d * d), where d is the average node degree. In a complete graph, it is n^3; In a tree, it is O(n); (even through tree does not make sense in this problem)	2014-12-10 08:24:34		
1465	dkebi	12	std::unordered_set<std::string> is a bad design. Should use objects here: std::unordered_set<Triangle>	2014-12-10 08:24:34		
1466	ufdxg	12	I would use the BFS. a. Color root gray and push it into a queue. b. Pop from queue one by one. Scan the neighbours of current node based on BFS. If the node to which it is connected is in same level and the node is not black yet add one to count. c. Color current scnned node to black.	2014-12-10 08:24:34		
1467	xhgls	12		2014-12-10 08:24:34		
1468	sgiwy	12		2014-12-10 08:24:34		
1469	tenuw	12	Steps  1) Create Adjacency List for nodes.  As in given example graph is undirected so adj list will look like this 0 -> 1,2 1->0,2 2-->0,1 4-->1  2) Pick one edge and get adj list for both nodes. 3) Count number of common elements in adj list 4) Repeat step 2 and 3 for all the edges  Number of triangles= (Number of common elements)/6 as it's undirected graph for directed graph it will be divided by 3	2014-12-10 08:24:34		
1470	nwkeg	12	Steps  1) Create Adjacency List for nodes.  As in given example graph is undirected so adj list will look like this 0 -> 1,2 1->0,2 2-->0,1 4-->1  2) Pick one edge and get adj list for both nodes. 3) Count number of common elements in adj list 4) Repeat step 2 and 3 for all the edges  Number of triangles= (Number of common elements)/6 as it's undirected graph for directed graph it will be divided by 3	2014-12-10 08:24:34		
1471	ethan	12		2014-12-10 08:24:34		
1472	bjsiw	12		2014-12-10 08:24:34		
1473	sqzqo	12	Here is an updated version using c#  int FindTriangles(Edge[] edges) { // Build Adjacent list SortedDictionary<int, List<int>> nodes = new SortedDictionary<int, List<int>>(); foreach (Edge e in edges) { if (nodes.Find(e.v1)) { nodes[e.v1].Add(e.v2); } else { nodes.add(e.v1, new List<int>(e.v2)); } if (nodes.Find(e.v2)) { nodes[e.v2].Add(e.v1); } else { nodes.add(e.v2, new List<int>(e.v1)); } }  int count = 0; foreach (KeyValuePair kv in nodes) { foreach(int i = 0; i < kv.Value.Length - 1; ++i) { if (kv.Value[i] < kv.Key) continue; foreach (int j = i + 1; j < kv.Value.Length; ++j) { if (kv.Value[j] < kv.Key) continue; if (nodes[kv.Value[i]].IndexOf(kv.Value[j]) != -1) { count++; } } }  return count; }	2014-12-10 08:24:34		
1474	ewigy	12	Finding the number of cycles with three nodes can give us the result.	2014-12-10 08:24:34		
1475	huiqq	12		2014-12-10 08:24:34		
1476	ethan	12		2014-12-10 08:24:34		
1477	dkebi	12	The following is an example in Java of using matrix multiplication to find the number of triangles. A separate class Connections keeps track of the nodes that can be reached after a specific number of steps (multiplication by adjacency matrix).	2014-12-10 08:24:34		
1478	vanul	12		2014-12-10 08:24:34		
1479	dgjji	12		2014-12-10 08:24:34		
1480	eucmc	12	HI i would do something like this :-  Do a union find algorithm (reason to choose this is that this algo is used to find loops in a graph and remember a triangle is a loop). While doing union-find do following steps as well - 1) for every vertex or node maintain a count as to how far is it from the parent. ( after doing the path compression and rank in algorithm) 2) if an edge comes that creates a loop check the attribute i.e. the height from parent and if it's the same then it's a triangle else skip that edge and continue.	2014-12-10 08:24:34		
1481	plapd	12	a basic idea is to have 3 nested loops i, j, and k, then test if i,j,k can form a triangle, cost is o(n^3). with hashset, you can improve it to o(n ^ 2), because based on the first two edges, you can find if the set has the required remaining edge with a lookup.	2014-12-10 08:24:34		
1482	bjsiw	12		2014-12-10 08:24:34		
1483	wbqzu	12		2014-12-10 08:24:34		
1484	bjsiw	12	using BFS algorithm, find the number of triangles for each level, and sum them up, divided by 6. public static void main(String[] args){ Node n0 = new Node(0); Node n1= new Node(1); Node n2 = new Node(2); Node n3 = new Node(3); Node n4 = new Node(4);  n0.connections.add(n1); n0.connections.add(n2);  n1.connections.add(n0); n1.connections.add(n2);  n2.connections.add(n0); n2.connections.add(n1); n2.connections.add(n4);  n4.connections.add(n1); n4.connections.add(n2);   ArrayList<Node> list = new ArrayList<Node>(); list.add(n0); list.add(n1); list.add(n2); list.add(n3); list.add(n4);  int triangle = findTotalTrangle(list, 5); triangle = triangle/6;  System.out.println("the number of triangle is "+ triangle); }  public static int findTotalTrangle(ArrayList<Node> root, int size){ int count =0; ArrayList<Node> visited = new ArrayList<Node>(); ArrayList<Node> queue = new ArrayList<Node>(); ArrayList<Node> second = new ArrayList<Node>(); queue.addAll(root); while(!queue.isEmpty()){ second.clear(); queue.removeAll(visited); count += findTrangleByLevel(queue, second); for(Node node: queue){ if(!visited.contains(node)){ visited.add(node); } } queue.clear(); queue.addAll(second); if(visited.size() == size ){ break; } } return count; }  public static int findTrangleByLevel(ArrayList<Node> list, ArrayList<Node> second){ int count = 0; //ArrayList<Node> second = new ArrayList<Node>(); //find all the neighbors of the list. ArrayList<Node> third = new ArrayList<Node>(); //find all the neighbors of the second list. for(Node node: list){ for(Node neigh : node.connections){ if(!second.contains(neigh)){ second.add(neigh); } } } if(!second.isEmpty()){ for(Node node: second){ for(Node neighb : node.connections){ if(list.contains(neighb)){ count++; }  } } }  return count; //this is the triangle number begining with the node in the first list. }	2014-12-10 08:24:34		
1485	qywrh	12	Suppose that a graph has been constructed as follows: - All nodes are ordered by its value. - Each node has an sorted list of edges. - An edge belongs to only at a single node with less value among two nodes.  For example, the above graph will be represented by 0: {1, 2} 1: {2, 4} 2: {} 4: {}  Then, the number of triangles can be obtained by counting the number of common nodes between every pair of nodes (n0, n1) where n0 < n1.	2014-12-10 08:24:34		
1486	krxlv	12		2014-12-10 08:24:34		
1487	nwkeg	12		2014-12-10 08:24:34		
1488	ewigy	12	The time complexity of this algorithm consists of two parts. First, constructing the graph will be inserting each edge to the proper node. Each insertion of an edge takes O(E/N). (Assume that the number of edges connected for each node is even). So, graph construction takes O(E*log(E/N)). Second, counting the number of triangles takes O(N * E/N * E/N). The outer loop and inner loop iterate N and E/N times, respectively, and countIntersection takes O(E/N).  If we assume dense graph, i.e., E=O(N^2), then the time complexity is O(N^3). If it is sparse, i.e., E=O(N), then O(N).	2014-12-10 08:24:34		
1489	mrjku	12		2014-12-10 08:24:34		
1490	ethan	12		2014-12-10 08:24:34		
1491	wbqzu	12		2014-12-10 08:24:35		
1492	wbqzu	12		2014-12-10 08:24:35		
1493	dkebi	12	Some of the codes above are so complex .Heres the easiest solution.	2014-12-10 08:24:35		
1494	nwkeg	12		2014-12-10 08:24:35		
1495	cfzie	12		2014-12-10 08:24:35		
1496	huiqq	12	It doesnt work..  01 2 3 1 2  out put - 1 --> wrong	2014-12-10 08:24:35		
1497	rrmeu	12	This solution is by using the adjacency matrix. if a[0][1]==1 and a[1][2]==1 then we check if a[0][2]==1 then one triangle exists We scan the matrix just downwards in the upper half of the marix for example if we have 5 nodes then scan starts from 0th node from a[0][1] and check starts from a[1][2] And then 1st node from a[1][2] and compared with next node from a[2][3] and so on In this way we avoid making duplicates  #include<iostream> using namespace std; int main() { int n,i,j,k,entries,no=0; cout<<"enter no of nodes:\n"; cin>>n; int a[n][n]; cout<<"enter no of entries:\n"; cin>>entries; for(i=0;i<n;i++) { for(j=0;j<n;j++) a[i][j]=0; } for(i=0;i<entries;i++) { cin>>j>>k; a[j][k]=1; a[k][j]=1; } for(i=0;i<n;i++) { for(j=i+1;j<n;j++) { if(a[i][j]==1) { for(k=j+1;k<n;k++) { if(a[j][k]==1) { if(a[i][k]==1) no++; } } } } } cout<<"no of triangles="<<no<<endl; return 0; }	2014-12-10 08:24:35		
1498	dkebi	12		2014-12-10 08:24:35		
1499	bjsiw	12		2014-12-10 08:24:35		
1500	bexbp	12	I simply used BFS and checked if the value of the node I was visiting at that moment existed in the list of Nodes left to visit.  This scenario occurs when a triangle is present because of the following: Suppose nodes 1, 2, and 3 are connected to each other. Start at node 1. - Node 1 is visited, adding 2 and 3 to the list of nodes to visit. - Node 1 is marked as visited. - Node 2 is visited, adding 3 to the list of nodes to visit (only add nodes that have not been visited, so node 1 is skipped). - Node 3 is visited, node 3 observes that it is still on the list of nodes to visit. Mark 3 as visited and incrementing triangles count. Also remove the duplicate node 3 entry from the to visit list.  Code:	2014-12-10 08:24:35		
1501	bexbp	12		2014-12-10 08:24:35		
1502	dgjji	12		2014-12-10 08:24:35		
1503	nhibd	12	Complexity is O(n^2) as each node must check the list of nodes yet to visit.	2014-12-10 08:24:35		
1504	azmjc	12	public int getNumberOfTriangles(int[] v){ HashMap<Integer, HashSet<Integer>> edges = new HashMap<Integer, HashSet<Integer>>(); int result = 0;  for(int i = 0; i < v.length / 2; i++){ int i1 = v[2 * i]; int i2 = v[2 * i + 1];  HashSet<Integer> hs1 = edges.get(i1); if(hs1 == null){ hs1 = new HashSet<Integer>(); edges.put(i1, hs1); }  HashSet<Integer> hs2 = edges.get(i2); if(hs2 == null){ hs2 = new HashSet<Integer>(); edges.put(i2, hs2); }  for(Integer test : hs1){ if(hs2.contains(test)){ result++; } }  hs1.add(i2); hs2.add(i1); }  return result; }	2014-12-10 08:24:35		
1505	sqzqo	12		2014-12-10 08:24:35		
1506	dgjji	12		2014-12-10 08:24:35		
1507	wbqzu	12		2014-12-10 08:24:35		
1508	azmjc	12		2014-12-10 08:24:35		
1509	xhgls	12	Dont know why people write this mammoth code for simple problems. Will google appreciate this and will you have enough time on blackboard to explain all these ..	2014-12-10 08:24:35		
1510	bexbp	12		2014-12-10 08:24:35		
1511	sqzqo	12		2014-12-10 08:24:35		
1512	cfzie	12	A minor modification, mark the visited node ..	2014-12-10 08:24:35		
1513	fmzze	12		2014-12-10 08:24:35		
1514	azmjc	12		2014-12-10 08:24:35		
1515	sqzqo	12	We can do that in O(n^2) and no BFS / DFS	2014-12-10 08:24:35		
1516	qywrh	12		2014-12-10 08:24:35		
1517	bjsiw	12		2014-12-10 08:24:35		
1518	rrmeu	12	1we have a two-dimensional array to represent the adjacent between two vertexes; also each vertex have a adjacent list of vertexes whose id are larger than the vertex itself; 2For every vertex list,we check its adjacent vertex pair,and find the reasonable pairs through the 2-dim array; Time complexity is min(O(edge^2),O(n*d^2));(d represent the degree of the vertex),but I think my solution avoid the redundant computation. A little better than the first solution.	2014-12-10 08:24:35		
1519	nwkeg	12	For each vertex traverse all its edges in pairs. For each edge pair see if the vertices are connected, if so its a triangle. Since the same triangle will be reported 3 times (for each vertex), divide the result by 3. This algorithm is O(n) complexity.  For example above:  0 1 2 1 0 2 4 1  Vertex 0 edge pair (0,1) and (0,2) , select any of the 2 connected vertices and see if there is an edge between them. There is (2,1) so add 1 to traingle count.  Repeat for vertices 1,2,4. your triangle count will be 3. Divide by 3 and you will get 1 which is the answer.	2014-12-10 08:24:35		
1520	nhibd	13	solution : having complexity O(n)(time)+O(height of BST)(space) observation : if we are given a sorted array instead of a BST and the same question was asked then so solve this problem in O(n)+O(1) complexity, we keep two indexes one at start and 2nd one at end, and apply following algo.	2014-12-10 08:24:43		
1521	xhgls	13		2014-12-10 08:24:43		
1522	sgiwy	13		2014-12-10 08:24:43		
1523	gilit	13	so we apply the same concept here, because we don't have data stored in an array faction, so we need some space, now one way is tot store the data into an array and apply the same, but this require O(n) space, but if you think carefully, then we only require at max 2*height_of_BST, in first array of size height_of_BST, we store all elements which comes from	2014-12-10 08:24:43		
1524	bjsiw	13		2014-12-10 08:24:43		
1525	jippy	13		2014-12-10 08:24:43		
1526	ewigy	13	and in 2nd array we store	2014-12-10 08:24:43		
1527	vanul	13		2014-12-10 08:24:43		
1528	huiqq	13		2014-12-10 08:24:43		
1529	ethan	13	and we start with the last element of these two array, these array's are actually stack. now we get two element do we do the same comparison here also	2014-12-10 08:24:43		
1530	wbqzu	13		2014-12-10 08:24:43		
1531	qywrh	13		2014-12-10 08:24:43		
1532	xhgls	13	Do we need multi threads here? I have the same logic as you. But I think I am not able to implement with single thread. Plz write code if possible	2014-12-10 08:24:44		
1533	ufdxg	13	we don't actually, we apply while loop here, and store node into stack(not just values), and in each loop we do above check, (mean updating the stacks), I will write single threaded code of it on this thursday, as i have some quizzes in this week.	2014-12-10 08:24:44		
1534	gilit	13	I think it is great solution~	2014-12-10 08:24:44		
1535	rrmeu	13	A very good solution.	2014-12-10 08:24:44		
1536	huiqq	13	Someone please provide java code or explanation for this BST (after each iteration, with contents of S1, S2) -	2014-12-10 08:24:44		
1537	gilit	13		2014-12-10 08:24:44		
1538	jippy	13		2014-12-10 08:24:44		
1539	jippy	13	I want to search for sum=5.2	2014-12-10 08:24:44		
1540	krxlv	13	let s1 and s2 are two stack initially s1 contain : [3,2] and s2 contain : [5,8,9] we sum 2 and 9 and compare then with 5.2 and 11 is bigger then 5.2 so we look for left child of 9 which is not there, so we pop 9 from s2 now stacks contains s1 : [3,2] s2 : [5,8] again 2+8 > 5.2 so we pop 8 and push 6 now stacks contain : s1 : [3,2] s2 : [5,6] now again 2+6 > 5.2, we pop 6 from it now stacks contain : s1 : [3,2] s2 : [5] again 2+5 > 5.2 so we pop 5 from it and push [3,4] into it now stacks are : s1 : [3,2] s2 : [3,4] again 2+4 > 5.3 so we pop 4 and push 3.1 into it now stacks contains : s1 : [3,2]; s2 : [3,3.1] here 2+3.1 < 5.2 so we pop 2 from s1 and push 2.1 into it now stack contains : s1 : [3,2.1] s2 : [3,3.1] now 2.1 + 3.1 = 5.2 we get our answer, we print 3.1 and 2.1, if there is a possibility of having multiple pairs, then we won't stop here we go upto the condition that element of s1 is smaller then element of s2.	2014-12-10 08:24:44		
1541	gilit	13	Test3:	2014-12-10 08:24:44		
1542	dkebi	13		2014-12-10 08:24:44		
1543	ufdxg	13		2014-12-10 08:24:44		
1544	sqzqo	13	Your solution didn't seem to work when the left tree only contains one node.  e.g. create the tree with 7, 20, 2, 12, 17, 22 with target 37 s1 = [2] s2 = [7,20,22] 2 + 22 < 37 so you pop 2 .. now what? it has no right subtree - you can't check the left/right elements as the condition of your loop.	2014-12-10 08:24:44		
1545	eucmc	13	I forgot one thing to write here which is that root node is included in both the stacks, as i am checking the condition which is that stack1's element should be smaller then stack2's element, so this will not create any problem, but it solve problems like yours, thanks for that, here is the execution : s1 = [7,2] s2 = [7,20,22] 2+22 < 37 s1 = [7] s2 = [7,20,22] 7+22 < 37 s1 = [20,12] s2 = [7,20,22] 12+22 < 37 s1 = [20 17] s2 = [7,20,22] 17+22 > 37 s1 = [20,17] s2 = [7,20] 17+20 = 37;	2014-12-10 08:24:44		
1546	bexbp	13	thanks - this code seems to work then:	2014-12-10 08:24:44		
1547	ethan	13		2014-12-10 08:24:44		
1548	rrmeu	13		2014-12-10 08:24:44		
1549	sgiwy	13	In ur code if(A[1st_index] + A[2nd_index] < x) it this is true then there will be no two values with the required sum x.....then why are u subtracting 2nd_index--......	2014-12-10 08:24:44		
1550	rdfeo	13	To readers,  FOR THE OBSERVATION PART (above): ===============================  Array example is considered to be sorted in non-increasing fashion.  " observation : if we are given a sorted array instead of a BST and the same question was asked then so solve this problem in O(n)+O(1) complexity, we keep two indexes one at start and 2nd one at end, and apply following algo.	2014-12-10 08:24:44		
1551	mrjku	13		2014-12-10 08:24:44		
1552	dkebi	13		2014-12-10 08:24:44		
1553	gilit	13	"	2014-12-10 08:24:44		
1554	nwkeg	13	Good work with printTwoNodeValueEqualToX()	2014-12-10 08:24:44		
1555	azmjc	13	I think the code 'printTwoNodeValueEqualToX()' will fail to the following test case: {1, 2, 2, 10}, sum = 4 I think it should not use 'while (leftStack.peek().item < rightStack.peek().item);', because in the above example, the answer is {2, 2}, with the same value in the pair. I think it should use 'while (leftStack.peek() != rightStack.peek());'.  BTW, the follwoing is my Java implementation together with some simple tests, I'd appreciate any bug if you found:	2014-12-10 08:24:44		
1556	cfzie	13		2014-12-10 08:24:44		
1557	huiqq	13		2014-12-10 08:24:44		
1558	sqzqo	13	Isnt it like we are comparing the inorder and reverse inorder elements? This solution is pretty good.	2014-12-10 08:24:44		
1559	plapd	13	@Alva0930 what is the running time and space for your solution? Could you please tell us?	2014-12-10 08:24:44		
1560	xhgls	13	Are your comparison operators flipped in the original post? I get the logic, based on later comment examples. However, when I look at the original post, it seems like I want to be doing the opposite of what each 'if statement' suggests to do.	2014-12-10 08:24:44		
1561	mrjku	13	Since the above code implementing @sonesh's idea is not clear enough, I submit the following simple implementation in Java:	2014-12-10 08:24:44		
1562	vanul	13		2014-12-10 08:24:44		
1563	krxlv	13		2014-12-10 08:24:44		
1564	xhgls	13	}	2014-12-10 08:24:44		
1565	fmzze	13	My fifty cents (full C++ solution, O(h) space complexity, O(n log n) time complexity) :	2014-12-10 08:24:44		
1566	jippy	13		2014-12-10 08:24:44		
1567	krxlv	13		2014-12-10 08:24:44		
1568	nhibd	13	//simple code for comparing using left and right stack //which is basically in order traversing using stack, //when you are traversing in left subtree using left stack, every //time pops, push the right child of the current node and all the //left child of the right child.   Stack left; while(root!=null){//initialize left.push(root.l); root=root.l;}  node root=left.pop();//when comparing using left stack if(root.right!=null){ left.push(root.r); root=root.r} while(root!=null){ left.push(root.l); root=root.l;}	2014-12-10 08:24:44		
1569	sqzqo	13		2014-12-10 08:24:44		
1570	nwkeg	13		2014-12-10 08:24:44		
1571	ftfck	13	good but brute!!!	2014-12-10 08:24:44		
1572	cfzie	13	Here is solution as per space complexity, but high time complexity. If any one get soln with less complexity will be better.	2014-12-10 08:24:44		
1573	vanul	13		2014-12-10 08:24:44		
1574	wbqzu	13		2014-12-10 08:24:44		
1575	nwkeg	13	Logic : How do you find two values whose sum equal to X in a sorted array. - keep one pointer at start and another at end of an array and move your pointers according as per sum.  Used same logic, however instead of array, think how to do it in BST.	2014-12-10 08:24:44		
1576	rdfeo	13		2014-12-10 08:24:45		
1577	gilit	13		2014-12-10 08:24:45		
1578	ewigy	13	/* Complexity O(nlogn) time. O(log n) space. Logic -- If(root < sum) find in tree sum - root. if( no answer found in previous step) repeat this algorithm for left subtree of root. move to the right subtree of root. if (root > sum) move to left subtree.. since all of the values in right subtree and root are useless  */ Code	2014-12-10 08:24:45		
1579	nwkeg	13		2014-12-10 08:24:45		
1580	nhibd	13		2014-12-10 08:24:45		
1581	cfzie	13	Find the least element in BST. Let it be x. Let y = k-x. Find the element that is equal to y or less than y. Traverse in inorder manner from x and in reverse inorder manner from y till either x+y = k or x==y. Use iterative inorder traversal method.	2014-12-10 08:24:45		
1582	jippy	13	G, great solution	2014-12-10 08:24:45		
1583	fowai	13	And the iterative (or rather, lazy) traversal can be implemented using yield. (Generator/Coroutines, as some other answer put it).	2014-12-10 08:24:45		
1584	fmzze	13	But shouldn't we take into account every possible value of x up till k? That would shoot up the complexity.	2014-12-10 08:24:45		
1585	ufdxg	13		2014-12-10 08:24:45		
1586	ftfck	13		2014-12-10 08:24:45		
1587	plapd	13	the additional space is not O(height).Your solution will be work in just array	2014-12-10 08:24:45		
1588	nwkeg	13	Test1:	2014-12-10 08:24:45		
1589	tenuw	13		2014-12-10 08:24:45		
1590	bjsiw	13		2014-12-10 08:24:45		
1591	gilit	13	Test2:	2014-12-10 08:24:45		
1592	xhgls	13		2014-12-10 08:24:45		
1593	dkebi	13		2014-12-10 08:24:45		
1594	azmjc	13		2014-12-10 08:24:45		
1595	cfzie	13		2014-12-10 08:24:45		
1596	gilit	13	bool find2Node(Node* root,double targetV,Node*& n1,Node*& n2){ if(root==NULL)return false;  n1=root,n2=root; stack<Node*> st1,st2;  bool hasFound=false; while(true){ while(n1!=NULL){ st1.push(n1); n1=n1->left; } while(n2!=NULL){ st2.push(n2); n2=n2->right; } if(st1.top()==st2.top())break; double nowV=st1.top()->v+st2.top()->v; if(nowV<targetV){ n1=st1.top()->right; st1.pop(); }else if(nowV>targetV){ n2=st2.top()->left; st2.pop(); }else{hasFound=true;n1=st1.top();n2=st2.top();break;} } return hasFound; }	2014-12-10 08:24:45		
1597	dgjji	13		2014-12-10 08:24:45		
1598	tenuw	13		2014-12-10 08:24:45		
1599	ewigy	13	Solution: anandtechblog.blogspot.in/2010/07/given-binary-search-tree-of-n-nodes.html	2014-12-10 08:24:45		
1600	rrmeu	13	BST data not modified but BST is converted to a Doubly Linked List.  O(n) time solution with O(BST_DEPTH) space as stack is consumed.	2014-12-10 08:24:45		
1601	huiqq	13	One simpler solution is follow same practice as in Array of elements, for moving to previous element, use InOrderPredcessor to find previous element.	2014-12-10 08:24:45		
1602	eucmc	13	Brillant idea of sonesh, and here is my implementation code in C++:	2014-12-10 08:24:45		
1603	nhibd	13		2014-12-10 08:24:45		
1604	bexbp	13		2014-12-10 08:24:45		
1605	huiqq	13	My solution in C#	2014-12-10 08:24:45		
1606	azmjc	13		2014-12-10 08:24:45		
1607	fowai	13		2014-12-10 08:24:45		
1608	ewigy	13	--  Indra Bayu Vrije Universiteit Brussel	2014-12-10 08:24:45		
1609	plapd	13	Here is the logic for the case where all node values are positive. Starting from root node, IF (x <= root node value), then required two nodes with sum of values equals to x, if exists, will definitely be in left sub-tree of root ELSE required two nodes can be in either of left or right sub-tree, in which case, find node with value (x - root.value) in tree rooted at root.	2014-12-10 08:24:45		
1610	rdfeo	13	WRONG!!	2014-12-10 08:24:45		
1611	huiqq	13	coroutines!	2014-12-10 08:24:45		
1612	ufdxg	13	People who don't understand should not downvote. This is an excellent (though cryptic) answer.	2014-12-10 08:24:45		
1613	ewigy	13	Yes, and to be specific, generators. Some languages like python and C# have support for it: yield.	2014-12-10 08:24:45		
1614	huiqq	13		2014-12-10 08:24:45		
1615	huiqq	13		2014-12-10 08:24:45		
1616	qywrh	13	its like doing Nested Inorder inside Inorder and searching the element sum-X. (X= every node of the element)Complexity((logn)(log(n)) without extra apace ...	2014-12-10 08:24:45		
1617	bjsiw	13	Your code have many bugs. Also I think your code will loop infinitely. As both functions are calling each other.	2014-12-10 08:24:45		
1618	zeice	13	@nitin : it is just a kind of an algo..not proper code..so all boundary value cases not handled....Please let me know if any issue with Logic of an Algo..	2014-12-10 08:24:45		
1619	vanul	13	@ravisingh: for every node you are checking the left and right subtree to see if it is equal to sum - current_node. I think it will fit the bill.	2014-12-10 08:24:45		
1620	sgiwy	13	@raviSingh - In method Nested_find_node(), you need to add check to ensure that (temp != head).  This brute force logic is coded well by	2014-12-10 08:24:45		
1621	ftfck	13		2014-12-10 08:24:45		
1622	jippy	13		2014-12-10 08:24:45		
1623	mrjku	13	after your post.	2014-12-10 08:24:46		
1624	tenuw	13	[CORRECTION]: Sorry not 'annn' but 'Shashi'. My bad.	2014-12-10 08:24:46		
1625	wbqzu	13		2014-12-10 08:24:46		
1626	fowai	13	but the size of you hash is O(n) while there is a space restriction O(height of the tree)	2014-12-10 08:24:46		
1627	ewigy	13	Nice logic though.	2014-12-10 08:24:46		
1628	rrmeu	13	You don't need a hash, use two iterators one inorder (starts at min) and one reverse inorder (starts at max). Here is the C++ code, the operators ++ just return the successor in the given order. You can change the code to output one pair, unique pairs, all pair	2014-12-10 08:24:46		
1629	dkebi	13		2014-12-10 08:24:46		
1630	ewigy	13		2014-12-10 08:24:46		
1631	ethan	14	Assumption: All numbers are distinct (otherwise, you need to tell us about the BST insertion algorithm).  One solution (but essentially same as the tree compare solution in spirit): you can do something like quicksort:  Given Arrays A and B, check if A[0] = B[0] (if not, return false).  Now construct A_more, A_less and B_more, B_less where A_more contains elements of A which are > A[0] (and appear in the same order as they appear in A). This is basically the partition step in quicksort. Note that you need the partition to be stable. It is possible to do that in-place, but is very complex.  Now, recursively compare A_more, B_more and compare A_less and B_less. You can add optimizations to compare lengths of arrays to bail out quicker.	2014-12-10 08:24:59		
1632	nhibd	14	quick sort works .. but there is a catch .. For the first time, we take first element as pivot from both arrays and divided the arrays.. For the 2nd iteration onwards, we have to take the same element as pivot in both arrays .. this needs O(n) time or we have to do some kind of pre-processing ...  Second approach is not accepted as it was stated in the question itself that we should give answer without constructing BSTs.	2014-12-10 08:24:59		
1633	krxlv	14	@Bharath: The catch is that you need a stable partition: The relative ordering of elements must not change. Once you do that, you can do recursively, by comparing the first elements of the two partitions you get. You don't have to do any other preprocessing.  If you actually look to take the same element as pivot (as you seem to suggest), then you will get wrong answers, counterexample:  1 2 3 1 3 2	2014-12-10 08:24:59		
1634	wbqzu	14	How about using O(n) extra space to do partition in-place? Let quicksort's partition algorithm decide the correct position of an element only (Create a backup of original array before passing it to partition algorithm, then use it to partition stably). Time complexity would be O(nlogn) which is same as original algorithm and space complexity would be O(n).	2014-12-10 08:24:59		
1635	xhgls	14	@Epic_coder: Then by definition it is not in-place. The point of an in-place algorithm is to save space...	2014-12-10 08:24:59		
1636	azmjc	14	Very nice idea with partitioning, I was thinking about recursive check for left and right children, but qsort partitioning will do the work	2014-12-10 08:24:59		
1637	wbqzu	14	coders-stop.blogspot.in/2012/03/compare-bsts.html	2014-12-10 08:24:59		
1638	rrmeu	14	does not work for case  8 14 11 9 13 20 16 22 8 14 20 22 16 11 13 9	2014-12-10 08:24:59		
1639	ftfck	14	@blackfever: the bsts formed with the sequences u gave are not same, try to represent them in the form of tree based on order.	2014-12-10 08:24:59		
1640	zeice	14	I *think* this should work. When we're inserting any given key, it is always 'perfectly' inserted, that is it is inserted right after the maximum key that is still less than this key. Given that, we can go through the array and for each value from each array see if we've already inserted it in the other array, and if so if the insertion point is still the same. If not, we know that we would produce two different trees. If so, then we keep looking.  Right now I'm not checking to make sure that both trees contain the same elements, but that should be easy to add.  Also right now the findInsertAfter method does a brute-force search which makes the algorithm n^2, but if you replace that with a sorted data structure and binary search for the optimal element it should be n*log(n).	2014-12-10 08:24:59		
1641	admin	14		2014-12-10 08:24:59		
1642	zeice	14		2014-12-10 08:24:59		
1643	eucmc	14	Could you please explain what you are trying to do, in English?  I think an O(nlog n) algorithm will exist, but I haven't thought about it fully. Perhaps you have one.	2014-12-10 08:24:59		
1644	wbqzu	14	The basic idea is that when we're adding to a BST, a node is always added after the next-largest key. So if a given BST contains the values 1,2,3, then the value 4 will be added to the right of 3 no matter what the tree's shape.  So we can verify whether two trees are the same by checking for every value that its next-smallest value is the same as in the other tree.  There was a bug in my code, the corrected version is below: """ static boolean willMakeSame(int [] arr1, int [] arr2) { if(arr1.length != arr2.length || arr1[0] != arr2[0]) return false;  Map <Integer, Integer> insertedAt = new HashMap<>(); Set <Integer> insertedSetA = new HashSet <>(); Set <Integer> insertedSetB = new HashSet <>();  for(int at = 0; at < arr1.length; at++) { if(!insertedAt.containsKey(arr1[at])) { int insertAfter = findInsertAfter(insertedSetA, arr1[at]); insertedAt.put(arr1[at], insertAfter); } else { int insertAfter = findInsertAfter(insertedSetA, arr1[at]); if(insertAfter != insertedAt.get(arr1[at])) { return false; } } if(!insertedAt.containsKey(arr2[at])) { int insertAfter = findInsertAfter(insertedSetB, arr2[at]); insertedAt.put(arr2[at], insertAfter); } else { int insertAfter = findInsertAfter(insertedSetB, arr2[at]); if(insertAfter != insertedAt.get(arr2[at])) { return false; } } insertedSetA.add(arr1[at]); insertedSetB.add(arr2[at]); } return true; }  private static int findInsertAfter(Set<Integer> keySet, int i) { int maxThatIsSmaller = -1; for(int item : keySet) { if(item > maxThatIsSmaller && item < i) { maxThatIsSmaller = item; } } return maxThatIsSmaller; } """	2014-12-10 08:24:59		
1645	sgiwy	14	Actually, the assumption that next highest will be the right child is valid only for the root.  For instance consider  2 1 3  2 3 1  both these give the same tree, but I believe your algorithm will say no.	2014-12-10 08:24:59		
1646	tenuw	14	Actually it works, since for 1 the next-smallest in both cases is none and for 3 the next-smallest in both cases is 2.	2014-12-10 08:25:00		
1647	krxlv	14	It works, since 2 follows 1 in both cases and 3 follows 2. Code including some test cases is up here: shrib.com/5ULdxAua	2014-12-10 08:25:00		
1648	rrmeu	14	I had to modify your code to run it (probably java version assumptions). I gave it a test input where I thought it might fail, but it didnt!  So, now I am not sure what your algorithm is.  What exactly is next-smallest? Can you please define it and give a couple of examples?  Thanks.  EDIT: This is a failing test case	2014-12-10 08:25:00		
1649	ewigy	14		2014-12-10 08:25:00		
1650	admin	14		2014-12-10 08:25:00		
1651	ethan	14	prints true, instead of false.	2014-12-10 08:25:00		
1652	nhibd	14	Hello loler, as I mentioned in my original post right now it doesn't check that both have the same elements, but a simple set comparison will take care of that (I've already got both items in sets, so just check whether they completely overlap).  The next-smallest is the largest item currently in the array that is still smaller than the item we're trying to insert. So when inserting 5 into 1,2,4, the next-smallest is 4. If we were inserting 3, the next-smallest would be 2. For 0, the next-smallest is none. When you insert into a BST, the element always gets inserted after the next-smallest unless that space is already filled. However, if that space is already filled, then the algorithm will detect the error for the node that filled the space in one tree and not in the other.	2014-12-10 08:25:00		
1653	ewigy	14	For the record, this should fix the test case you mentioned:	2014-12-10 08:25:00		
1654	huiqq	14		2014-12-10 08:25:00		
1655	ethan	14		2014-12-10 08:25:00		
1656	admin	14	Just stick it right before the return true.	2014-12-10 08:25:00		
1657	sqzqo	14	Ok, I had misunderstood you earlier. This works, and guaranteed O(nlog n). Good job!  I believe I have a proof, brief attempt below:  Given a permutation P of 1,2,3...,n, Call the signature S_P of P, the function f which maps {1,2,...,n} to {0,1,2..., n-1} such that f(k) = next-smallest according to your definition (replacing None by 0).  The claim is that two permutations P1 (a1,a2, ..,an) and P2 (b1,b2, ...,bn) give rise to the same binary tree if and only if S_P1 is identical to S_P2.  Assume S_P1 = S_P2  First we show that the first element of P1 and P2 must be same. Suppose b1 = aj for some j > 1. Then since S_P2(aj) = 0, we must have that a1 > a_j. So we must have that S_P1(a1) = 0 but S_P2(a1) >= aj as a1 appears after aj in P2.  Now we can parittion and show for the subtrees.  DIdn't try proving the other way.	2014-12-10 08:25:00		
1658	ewigy	14	What does "making bst from array" mean? More details!	2014-12-10 08:25:00		
1659	nwkeg	14	Take first element as root and insert from then onwards in BST... Ex: A1[]={2,1,3} 2 1 3  A2[]={2,3,1} 2 1 3	2014-12-10 08:25:00		
1660	wbqzu	14	@Bharat: Then don't 1,2,3 and 1,3,2 give different trees?	2014-12-10 08:25:00		
1661	vanul	14	@Bharath: Why don't you edit the question to also add what make BST from array means?	2014-12-10 08:25:00		
1662	fowai	14	Simple solution (few assumptions made, obviously as question is quite vague):  Input: 2 int arrays Output: boolean - whether BST constructed from either array will be same  Idea: - first element has to be equal - loop till the end of array - if there is 1 more element left in both arrays, they have to be equal - advance 1 place - if there are 2 more elements in the array, they have to be equal when sorted - if swapped around, each must be on either side of the first element (i.e root of the BST)	2014-12-10 08:25:00		
1663	nhibd	14		2014-12-10 08:25:00		
1664	wbqzu	14		2014-12-10 08:25:00		
1665	fowai	14	}	2014-12-10 08:25:00		
1666	fmzze	14	{#include<stdio.h> #include<stdlib.h> #define size 20 int check(int a1[],int a2[],int l,int r) { if(r==-1) return 1; if(a1[l]!=a2[l]) return 0; if(l==r) return 1; int b1[r-l+1],b2[r-l+1],b3[r-l+1],b4[r-l+1],k1=-1,k2=-1,k3=-1,k4=-1,i,pivot; pivot=a1[l]; for(i=l+1;i<=r;i++) { if(pivot<a1[i]) b1[++k1]=a1[i]; else b2[++k2]=a1[i]; if(pivot<a2[i]) b3[++k3]=a2[i]; else b4[++k4]=a2[i]; } if(k1==k3 && k2==k4 && check(b1,b3,0,k1) && check(b2,b4,0,k2)) return 1; else return 0; } void main() { int a1[]={3,1,0,2,5,4,6}; int a2[]={3,5,6,1,2,4,-1}; int n=sizeof(a1)/sizeof(int); printf("%d\n",check(a1,a2,0,n-1)); }} Can we do like this? Here I used extra space. Everytime I am selecting a pivot and putting the elements less than pivot in first array and the elements greater than the pivot in the second array, and recursively checking these arrays.	2014-12-10 08:25:00		
1667	krxlv	14	and for in-place sorting this would work #include<stdio.h> void in_place(int a[],int n) { int save,i,j,k,pivot; pivot=a[0]; for(i=1;i<n;i++) { if(a[i]<pivot) { save=a[i]; for(j=i;a[j]!=pivot;j--); for(k=i-1;k>=j;k--) a[k+1]=a[k]; a[j]=save; } } } void main() { int a[]={3,7,8,2,5,4,9,1,6,0}; int n=sizeof(a)/sizeof(int); in_place(a,n); int i; for(i=0;i<n;i++) printf("%d ",a[i]); printf("\n"); }	2014-12-10 08:25:00		
1668	gilit	14	Idea is based on qsort-partitioning where order of elements is preserved and done *in place*. As input function takes 2 arrays, applies partitioning on them and recursively processes each of 2 sub arrays.	2014-12-10 08:25:00		
1669	ewigy	14		2014-12-10 08:25:00		
1670	mrjku	14		2014-12-10 08:25:00		
1671	ethan	14	For following test case, it is showing as false... but it should be true. {8,2,0,4,1,3,6,5,7,14,11,9,13,20,16,22} {8,14,20,22,16,11,13,9,2,4,6,7,5,3,0,1}	2014-12-10 08:25:00		
1672	rdfeo	14	Thanks for pointing that out, I forgot to check the case when first indexes are bigger than last indexes, of course it should lead to TRUE	2014-12-10 08:25:00		
1673	cfzie	14	the algo i thought...i will call a fn with 2 arrays A and B with same length n say with min=INT_MIN and max=INT_MAX,index1=0,index2=0 1. now starting from index1 in A and index2 in B,find 1st element in both arrays greater than min and less than max.If no such element in both the arrays,return true...If such element is only in 1 array return false.let index of such element in array A is i1 and array B is i2. If both elements are not same return false 2. call the same fn twice return isSameBST(A,B,A[i1],max,i1+1,i2+1) && isSameBST(A,B,min,A[i1],i1+1,i2+1).	2014-12-10 08:25:00		
1674	krxlv	14	only recursion stack used and time complexity is o(n*height of BST)	2014-12-10 08:25:00		
1675	nhibd	14		2014-12-10 08:25:00		
1676	wbqzu	14		2014-12-10 08:25:00		
1677	krxlv	14	My solutions in C++:	2014-12-10 08:25:00		
1678	xhgls	14		2014-12-10 08:25:00		
1679	nhibd	14		2014-12-10 08:25:00		
1680	rdfeo	14	"A1[]={2,1,3} 2 1 3  A2[]={2,3,1} 2 1 3"  How are these really the same? Depending on the rules, the second number could always be the left parent and the third number could be the right parent. According to my rules, it would be  2 1 3  2 3 1  Totally different.	2014-12-10 08:25:00		
1681	nwkeg	14	It's a binary search tree. The left child is always smaller, and the right child is always larger.	2014-12-10 08:25:00		
1682	azmjc	14		2014-12-10 08:25:00		
1683	plapd	14		2014-12-10 08:25:00		
1684	dgjji	14	Please share feedback on this approach 1. Check length of both the arrays. 1. if both are of equal length, sort them (we can do it in lg n) and then compare each element. If we find a mismatch, then both BSTs are not identical.	2014-12-10 08:25:00		
1685	plapd	14	Please share feedback on this approach 1. Check length of both the arrays. 1. if both are of equal length, sort them (we can do it in lg n) and then compare each element. If we find a mismatch, then both BSTs are not identical.	2014-12-10 08:25:00		
1686	xhgls	14	2 bsts would not be identical	2014-12-10 08:25:00		
1687	ftfck	14	2 bsts would not be identical	2014-12-10 08:25:00		
1688	ewigy	14	First Element and size of both array should be same. All the element smaller than first element should be in same Order in both array. Slly: all the element greater than first element should be in same Order in both array.  (Assuming : all different element in array n1:- size of A1 n2:- size of A2 )	2014-12-10 08:25:00		
1689	ewigy	14		2014-12-10 08:25:01		
1690	tenuw	14		2014-12-10 08:25:01		
1691	rdfeo	14	This will fail for  4 2 3 1 7  and  4 2 1 3 7	2014-12-10 08:25:01		
1692	dkebi	14	1) check whether the size of both the arrays are equal. 2)if equal, then simply sort both arrays. 3)compare both the element in linear order.see a flag to track all the elements are equal are not.	2014-12-10 08:25:01		
1693	tenuw	14	Step may be useful between 1 and 2 1.1) find sum of both of the array... in case not same return FALSE else proceed with step 2.	2014-12-10 08:25:01		
1694	krxlv	14	dont think this will give correct answer. Once you sort both arrays, you have lost original order. Without the original order BST shape would be impossible to find and compare...	2014-12-10 08:25:01		
1695	sgiwy	14		2014-12-10 08:25:01		
1696	ethan	14	This approach gives false positives .. Ex: 123, 132 --> don't form same BSTs but , sorted order is same....	2014-12-10 08:25:01		
1697	rrmeu	15		2014-12-10 08:25:02		
1698	plapd	15		2014-12-10 08:25:02		
1699	vanul	15	Good, very clean	2014-12-10 08:25:02		
1700	plapd	15	Logic is outstanding... though the logic fails if N = 0. But thats a small change.	2014-12-10 08:25:02		
1701	ethan	15	I am not very clear on the question itself. Could anyone please elaborate more?	2014-12-10 08:25:02		
1702	xhgls	15	good logic. it can be enhanced further with a return status on printRec to reduce some unnecessary traversing	2014-12-10 08:25:02		
1703	krxlv	15	N=1000 is just an example, the code works only for N=1000.	2014-12-10 08:25:02		
1704	ethan	15	I tried this in javascript code, doesn't work-- i dont see any difference in my code: function printTopN_inStringComparisonORder(n) { var printNum = function(str, n) { if (parseInt(str) > n) return console.log(str) for (j=0;j<10;j++) { printNum(str + j, n) } } for(var i=1; i<10; i++) { printNum(""+i, 1000); } }	2014-12-10 08:25:02		
1705	plapd	15		2014-12-10 08:25:02		
1706	fowai	15	DFS comes to our rescue. if you observe a little you can find out that there is a nice pattern Start with a char 1-9 in that order (9 iterations). Add a 0-9 to right of string one at a time and recursively do dfs. if value<=n print it. recursively keep on adding char to the right. when value>n. return from dfs call.  Here is the fully working code in C++	2014-12-10 08:25:02		
1707	nhibd	15		2014-12-10 08:25:02		
1708	wbqzu	15		2014-12-10 08:25:02		
1709	eucmc	15	Same idea but just try to avoid over-generate the sequence and atoi in every loop	2014-12-10 08:25:02		
1710	eucmc	15		2014-12-10 08:25:02		
1711	bexbp	15		2014-12-10 08:25:02		
1712	qywrh	15	Can you please elaborate your question ? When N=1000, why you selected only these number and only that sequence ? 1, 10, 100, 1000, 101, 102, ... 109, 11, 110,	2014-12-10 08:25:02		
1713	rrmeu	15	An iterative solution that doesn't use strings, so there's no dynamic memory allocation behind the scenes (except, possibly, for printing on the screen).	2014-12-10 08:25:02		
1714	huiqq	15		2014-12-10 08:25:02		
1715	huiqq	15		2014-12-10 08:25:02		
1716	dgjji	15		2014-12-10 08:25:02		
1717	azmjc	15		2014-12-10 08:25:02		
1718	jippy	15	Nice one with no strings involved!	2014-12-10 08:25:02		
1719	qywrh	15		2014-12-10 08:25:02		
1720	wbqzu	15		2014-12-10 08:25:02		
1721	mrjku	15		2014-12-10 08:25:03		
1722	azmjc	15		2014-12-10 08:25:03		
1723	bexbp	15		2014-12-10 08:25:03		
1724	sgiwy	15		2014-12-10 08:25:03		
1725	krxlv	15	To make DFS more understandable just think about a tree with root 1. Root 1 has children 10,11,...,19. 10 has children 100,101,102,...,109. 11 has children 110,111,...,119. Do a DFS and if the node value is under given threshold print it.	2014-12-10 08:25:03		
1726	qywrh	15		2014-12-10 08:25:03		
1727	wbqzu	15		2014-12-10 08:25:03		
1728	zeice	15		2014-12-10 08:25:03		
1729	xhgls	15		2014-12-10 08:25:03		
1730	jippy	15	Python solution	2014-12-10 08:25:03		
1731	qywrh	15		2014-12-10 08:25:03		
1732	wbqzu	15		2014-12-10 08:25:03		
1733	sqzqo	15		2014-12-10 08:25:03		
1734	azmjc	15		2014-12-10 08:25:03		
1735	qywrh	15	/* Output top N positive integer in string comparison order. For example, let's say N=1000, then you need to output in string comparison order as below: 1, 10, 100, 1000, 101, 102, ... 109, 11, 110, ... */  #include "stdafx.h" #include <iostream> #include <conio.h> #include <algorithm> #include <map> #include <vector> #include <list> #include <iterator> #include <math.h> #include <numeric> #include <sstream> #include <stack> #include <string>  using namespace std;  struct Node { Node( int nValue ) { this->m_nValue = nValue; memset( this->m_SubTree, 0, sizeof( Node * ) * 10 ); }  int m_nValue; Node * m_SubTree[10]; };  class Solution { public: static void AddToTree( int nValue, Node * & pTree) { vector<int> vecTreePath; int nValueCopy = nValue; while ( nValueCopy > 0 ) { vecTreePath.push_back( nValueCopy % 10 ); nValueCopy /= 10; }  Node * pParent = pTree; { for ( size_t i = vecTreePath.size() - 1; i > 0; i -- ) pParent = pParent->m_SubTree[ vecTreePath[i] ]; }  pParent->m_SubTree[ vecTreePath[0] ] = new Node(nValue); }  static void CreateTree( int nValue, Node * & pTree ) { if ( nValue <= 0 ) return; pTree = new Node( 0 ); for ( int i = 1; i <= nValue; i ++ ) AddToTree( i, pTree ); }  static void PrintTreeInDFS( Node * pTree ) { if ( !pTree ) return;  // skip zero if ( pTree->m_nValue ) printf( "%d ", pTree->m_nValue);  for ( int ii = 0; ii < 10; ii ++ ) { if ( pTree->m_SubTree[ ii ]) PrintTreeInDFS( pTree->m_SubTree[ ii ] ); } }  static void DeleteTree( Node * & pTree ) { for ( int i = 0; i < 10; i ++ ) { if ( pTree->m_SubTree[i] ) DeleteTree( pTree->m_SubTree[i]); } delete pTree; pTree = NULL; } };   int _tmain(int argc, _TCHAR* argv[]) { Node * pTree = NULL;  Solution::CreateTree( 1000, pTree ); Solution::PrintTreeInDFS( pTree ); Solution::DeleteTree( pTree );  _getch();  return 0; }	2014-12-10 08:25:03		
1736	rrmeu	15		2014-12-10 08:25:03		
1737	bexbp	15		2014-12-10 08:25:03		
1738	nwkeg	15	two files:  Data class contains the integer and compares like string:	2014-12-10 08:25:03		
1739	qywrh	15		2014-12-10 08:25:03		
1740	ewigy	15		2014-12-10 08:25:03		
1741	fmzze	15	----------------------------------------------------------------  Main function:	2014-12-10 08:25:03		
1742	huiqq	15		2014-12-10 08:25:03		
1743	qywrh	15		2014-12-10 08:25:03		
1744	jippy	15	String comparison done on the numbers will give the expected results.	2014-12-10 08:25:03		
1745	ufdxg	15		2014-12-10 08:25:03		
1746	qywrh	15		2014-12-10 08:25:03		
1747	sqzqo	15	convert the int to char using a 1000*4 char array, then do radix sort.	2014-12-10 08:25:03		
1748	tenuw	15		2014-12-10 08:25:03		
1749	rrmeu	15		2014-12-10 08:25:03		
1750	vanul	15	Simple C++ solution.	2014-12-10 08:25:03		
1751	nhibd	15		2014-12-10 08:25:03		
1752	rrmeu	15		2014-12-10 08:25:03		
1753	krxlv	15		2014-12-10 08:25:03		
1754	azmjc	15		2014-12-10 08:25:03		
1755	ftfck	15		2014-12-10 08:25:03		
1756	ftfck	15		2014-12-10 08:25:03		
1757	azmjc	16	#include<stdio.h> int check(int); main() { int N;   printf("\n Enter the N:"); scanf("%d",&N); if(check(N)) { printf("\n[%d] Perfect Square:\n",N);  }  else {  printf("\nNot perfect Square\n");  } } int check(int n) { int i=1;  while(n>0) { n-=i; printf("[%d]",n); i+=2;   } if(n==0) return 1;  return 0;  }  complexity:O(logn)in some cases and <o(n)	2014-12-10 08:25:11		
1758	huiqq	16	@NAX: Though you have written the program and it works pretty well, but it is of no consequence to anyone as the logic behind this (i.e. how it works?) is not mentioned by you and is not apparent either, which is by the way is very important rather than this code!!!People can write code in whatever language they want if they know the strategy, can't they?  Strategy: As we all know what is Arithmetic progression right?If not, then have a look at this en.wikipedia.org/wiki/Arithmetic_progression, so basically the logic used here comes from this arithmetic progression. What NAX is doing is this: He is increasing the counter(i+=2) in such a way that it becomes an arithmetic progression and which he is cleverly subtracting (n-=i) with the given number such that if the number is a square then the end result becomes 0.  To put in succinctly : N=25 Output of the program: [25] 1 = 24 (25-1) [24] 3 = 21 [21] 5 = 16 [16] 7 = 9 [9] 9 = 0 and if you notice properly- 1,3,5,7,9 is arithmetic progression and it sums up to (5*(1+9))/2=25 So effectively we are subtracting 25 from 25 and showing the results, however it will not work for non-square number right?Hope you understood why it won't work for non-square number.	2014-12-10 08:25:11		
1759	tenuw	16	The complexity is not O(log n). It's O(sqrt(n)), if n is the number to verify.	2014-12-10 08:25:11		
1760	huiqq	16	if the sum becomes negative just return the result that its not a perfect square, why won't it work?	2014-12-10 08:25:11		
1761	ufdxg	16	@aka +1. Thank you aka, most of us here to learn and understand these things, so I really appreciate the explanation.  @eugene.yarovoi +1. It's true. The programs runs O(sqrt(n)), which is bigger than O(log(n)).	2014-12-10 08:25:11		
1762	sgiwy	16	See this image: en.wikipedia.org/wiki/Square_number#Properties	2014-12-10 08:25:11		
1763	ftfck	16		2014-12-10 08:25:11		
1764	wbqzu	16		2014-12-10 08:25:12		
1765	mrjku	16	Thus we can say that the sum of series >>> (1+3+5+7+9+ ... upto n terms) = n^2	2014-12-10 08:25:12		
1766	mrjku	16		2014-12-10 08:25:12		
1767	mrjku	16	STRONG NO HIRE (yes, those are Microsoft terms).	2014-12-10 08:25:12		
1768	sqzqo	16	So give us logarithmic solution which uses only addition and substraction.	2014-12-10 08:25:12		
1769	plapd	16	Sum of first n odd numbers is n^2. So we can keep adding odd numbers. If we reach the number its a perfact square.	2014-12-10 08:25:12		
1770	wbqzu	16	thats what the first answer is about	2014-12-10 08:25:12		
1771	rrmeu	16	simply we can also keep on summing all odd numbers till we get desired num. If sum ends up with given number then it is perfectly square number otherwise if sum exceeds given number, number is not perfectly square and will return false.  all Square numbers are: 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289  If we see the difference among these numbers, following figure we get: 3, 5, 7, 9, 11, 13, 15, 17, 19, 21  So, you see, every consecutive square number is Arithmetic progression. So if we can add number of this series to get desired result. Complexity will be O(sqrt(n)) As in case of square root of 25, we need 5 iteration of addition.	2014-12-10 08:25:12		
1772	ufdxg	16		2014-12-10 08:25:12		
1773	rrmeu	16		2014-12-10 08:25:12		
1774	sqzqo	16	Nice. +1 for good explanation and simple, clean code.	2014-12-10 08:25:12		
1775	cfzie	16	Just to add a little mathematical explanation..  (n+1)square - n square=2 n+1, so if he have a perfect square number n, then the next perfect square number will be 2n+1 more than n.  Now for all n, 2n+1,4n+1,6n+1 will be always in Arithmetic Progression.	2014-12-10 08:25:12		
1776	tenuw	16	@pawan: nice explanation.	2014-12-10 08:25:12		
1777	mrjku	16	here is the code:	2014-12-10 08:25:12		
1778	nwkeg	16		2014-12-10 08:25:12		
1779	zeice	16		2014-12-10 08:25:12		
1780	dgjji	16	for an integer i > 0, compute the sum by summing up i for i times; compare the sum with the given number  when doing the summing up for each i, the complexity can be O(log i).	2014-12-10 08:25:12		
1781	krxlv	16	this solution has greater complexity. but the solution required should have min complexity	2014-12-10 08:25:12		
1782	admin	16	Could you elaborate? How do you chose i? How does this even work? Let's say for n=25. You have: i=1 -> 1 i=2 -> 3 i=3 -> 6 i=4 -> 10 i=5 -> 15 i=6 -> 21 i=7 -> 28  I think it should be for integers i > 1 add a number "i" times. For instance: i=2 -> 2+2=4 i=3 -> 3+3+3=9 i=5 -> 5+5+5+5+5=25 End when sum >= our number.  Use cache for lookup? Still pretty slow.	2014-12-10 08:25:12		
1783	dkebi	16	yes. it should be what you wrote. my bad. i'll edit my answer.	2014-12-10 08:25:12		
1784	ewigy	16	Why we can't simply store all the perfect squares in an array(What do you think about this size of array-it won't be big me thinks). Now all we need to do is to find out if the given number exist in the array or not.That can be simply done by binary search. array[] - {2,4,16,25,36,49,64,81,100,121,169,196,225.......} This would be the fastest but I think this is not the answer your interviewer was looking for or is it?	2014-12-10 08:25:12		
1785	mrjku	16	This is a not bad solution when you want to perform this operation multiple times (you do need to calculate them the first time) and storage is not an issue.	2014-12-10 08:25:12		
1786	ufdxg	16	Linear time complexity. O(N)	2014-12-10 08:25:12		
1787	zeice	16		2014-12-10 08:25:12		
1788	xhgls	16		2014-12-10 08:25:12		
1789	rdfeo	16	@m@}{ : how this is different from below approach mentioned earlier?	2014-12-10 08:25:12		
1790	sqzqo	16		2014-12-10 08:25:12		
1791	bjsiw	16		2014-12-10 08:25:12		
1792	ufdxg	16	The complexity is O(N) not O(lgN).	2014-12-10 08:25:12		
1793	ewigy	16	You could also use binary like search for possible square. Time should be less then O(N).	2014-12-10 08:25:12		
1794	krxlv	16		2014-12-10 08:25:12		
1795	plapd	16		2014-12-10 08:25:12		
1796	dgjji	16		2014-12-10 08:25:12		
1797	cfzie	16		2014-12-10 08:25:12		
1798	huiqq	16	There are some errors regarding the scope, but its fairly evident. Please take note of rectifying that.	2014-12-10 08:25:12		
1799	nwkeg	16	in for loop...float z= num/i;here 1st time i=0 and z=num/0 gives infinite...	2014-12-10 08:25:12		
1800	rdfeo	16	package com.rakesh.topcoder;  import java.util.Scanner;  public class PerfectSquareWithAddition {  /** * @param args */ public static void main(String[] args) {  Scanner input = new Scanner(System.in); System.out.println("Enter a numer.."); int n = input.nextInt(); int finalval = findPerfectSquare(n); if(finalval == 0) System.out.println( n + " is a Perfect Square " ); else System.out.println(n + " is not a perfect square "); }  public static int findPerfectSquare(int n){ int a=1;  while(n>0){ n -= a; a += 2; }  return n; }  }	2014-12-10 08:25:12		
1801	qywrh	16	To find out if 25 is a perfect square, i have to find a number which is greater than 1 but less than n=25 which n= 25 will be divisible by and when that number is multiplied by itself then it should be equal to n=25;  in my method; n = value the number that n should be divisible by = div; so div * div == value and value%div == 0; the for loop accomplishes div*div using addition instead; complexity root n * root n = n (not sure on this one, help is appreciated);	2014-12-10 08:25:12		
1802	gilit	16		2014-12-10 08:25:12		
1803	krxlv	16		2014-12-10 08:25:12		
1804	nhibd	16	oh and the editor changes the code for this line for(int i=div; i>;0 ; i--) resulting in wrong java syntax when i post it right, not sure why.  i have improved my solution to be root n complexity; the solution is based on that 4+5 = 9 , 9+7 = 16,16+9 = 25,25+11 = 36 and so on..	2014-12-10 08:25:12		
1805	fowai	16		2014-12-10 08:25:12		
1806	nwkeg	16		2014-12-10 08:25:12		
1807	rrmeu	16	use dynamic programming 1^2 = 1 (n+1) = n^2 + 2n + 1  calc 1^2 , 2^2 until n^2 >= value  the time complexity is O(n^0.5)	2014-12-10 08:25:12		
1808	zeice	16	hey you fool you cant use power. you can onlu use add &sub	2014-12-10 08:25:13		
1809	dgjji	16	Be careful, Anon, people can easily understand that fool is YOU. (a+b)^2 = a^2 + 2ab + b^2. 1^2 = 1. Starting from the next line, b = 1 always => 2ab = (a+a) 2^2 = 1 + (1+1) + 1 = 4 3^2 = 4 + (2+2) + 1 = 9, etc. The complexity is sqrt(n), same as odds sum	2014-12-10 08:25:13		
1810	admin	16		2014-12-10 08:25:13		
1811	wbqzu	16		2014-12-10 08:25:13		
1812	cfzie	16	Regarding the complexity of the arithmetic-progression algorithm, it is sqrt(n) in relation to the value of n, but it is n^2 to the size of n (for example, the size of 100 is 3 [3 digits] but it takes 10 arithmetic operations).	2014-12-10 08:25:13		
1813	rrmeu	16		2014-12-10 08:25:13		
1814	bexbp	16		2014-12-10 08:25:13		
1815	qywrh	16	read the question please ...	2014-12-10 08:25:13		
1816	nhibd	16	static public boolean checkPerfectSquare(int n) {  int i = 0; int j = 1;  while (i < n) { i +=j; if (i == n) return true; j+=2; }  return false; }	2014-12-10 08:25:13		
1817	tenuw	16	use this: f(x)=x^2 because (x+1)^2=x^2+2*x+1, so, f(x+1)=f(x)+2*x+1 the code is like below:	2014-12-10 08:25:13		
1818	qywrh	16		2014-12-10 08:25:13		
1819	fmzze	16		2014-12-10 08:25:13		
1820	qywrh	16		2014-12-10 08:25:13		
1821	azmjc	16		2014-12-10 08:25:13		
1822	wbqzu	16	With the same logic as discussed above by adding values (2n+1) with preceding values eg. 1, 4(1+(1+2)), 9(4+ (3+2)), 16(9+ (5+2)).... and comparing with given value. Ruby Code -	2014-12-10 08:25:13		
1823	rrmeu	16		2014-12-10 08:25:13		
1824	bexbp	16		2014-12-10 08:25:13		
1825	eucmc	16	With the same logic as discussed above by adding values (2n+1) with preceding values eg. 1, 4(1+(1+2)), 9(4+ (3+2)), 16(9+ (5+2)).... and comparing with given value. Ruby Code -	2014-12-10 08:25:13		
1826	sgiwy	16		2014-12-10 08:25:13		
1827	nhibd	16		2014-12-10 08:25:13		
1828	zeice	16	With the same logic as discussed above by adding values (2n+1) with preceding values eg. 1, 4(1+(1+2)), 9(4+ (3+2)), 16(9+ (5+2)).... and comparing with given value. Ruby Code -	2014-12-10 08:25:13		
1829	tenuw	16		2014-12-10 08:25:13		
1830	fmzze	16		2014-12-10 08:25:13		
1831	xhgls	16	I think this is most compact solution in C-style languages. O(sqrt(n)) complexity. C# code:	2014-12-10 08:25:13		
1832	ewigy	16		2014-12-10 08:25:13		
1833	bjsiw	16		2014-12-10 08:25:13		
1834	cfzie	16	Here is a Ruby solution using the rule of odd deltas:	2014-12-10 08:25:13		
1835	rdfeo	16		2014-12-10 08:25:13		
1836	nhibd	16		2014-12-10 08:25:13		
1837	ftfck	16	Hi there! Here is my code, the easiest way to solve this problem:	2014-12-10 08:25:13		
1838	nwkeg	16		2014-12-10 08:25:13		
1839	sqzqo	16		2014-12-10 08:25:13		
1840	bexbp	16	In O( sqrt(n) )	2014-12-10 08:25:13		
1841	cfzie	16	In a real interview you don't have the enough time to write huge codes like other solutions. This solution takes you only a few seconds to write in the whiteboard :)	2014-12-10 08:25:13		
1842	azmjc	16	gab i think you missed the part where they said only addition or subtraction....so no multiplication. your solution was also my first instinct but went back and looked at the problem again because i was suspicious as to why someone hadnt thought of it yet when it is so simple.	2014-12-10 08:25:13		
1843	bexbp	17	Typed it in directly... so expect bugs (or plain incorrectness :P ) BFS initiated from all guard positions and +1 for reaching a naked position (a '0') and add it to queue to keep the BFS search going.	2014-12-10 08:25:16		
1844	dkebi	17		2014-12-10 08:25:16		
1845	cfzie	17		2014-12-10 08:25:17		
1846	eucmc	17	Lol treat G as 1 inside while loop	2014-12-10 08:25:17		
1847	ewigy	17	So, the queue keeps both position of G, and naked position '0'?	2014-12-10 08:25:17		
1848	bexbp	17	^^^ Yes, because all growing shortest paths start at a G and go through a '0' (they do not revisit a numbered node again).  My "Lol" comment above was referring to this fix:	2014-12-10 08:25:17		
1849	tenuw	17		2014-12-10 08:25:17		
1850	krxlv	17		2014-12-10 08:25:17		
1851	qywrh	17	should be	2014-12-10 08:25:17		
1852	azmjc	17		2014-12-10 08:25:17		
1853	vanul	17		2014-12-10 08:25:17		
1854	vanul	17	Got it! Thanks.	2014-12-10 08:25:17		
1855	ethan	17	Can this algorith ensure that the distance is from the nearest Guard point, I think we have to write like this :	2014-12-10 08:25:17		
1856	bexbp	17		2014-12-10 08:25:17		
1857	gilit	17		2014-12-10 08:25:17		
1858	qywrh	17	I think the algorithm didn't handle the nearest gaurd points case. Your algorithm might return the longest routes to all the 0 from a given set of gaurds. What if the gaurd point you are starting is not the right candidate for a '0' zero node. There is a possibility that this '0' node can be reached from another gaurd point which is much close.  So we need to correct the logic to take the min( existing a[i][j] and new a[i][j])	2014-12-10 08:25:17		
1859	wbqzu	17	This solution doesn't check if the cell is a obstacle and can not be crossed.	2014-12-10 08:25:17		
1860	gilit	17	Below is my code, I did some test. -2 for block, -1 for gurad.	2014-12-10 08:25:17		
1861	nwkeg	17		2014-12-10 08:25:17		
1862	rdfeo	17		2014-12-10 08:25:17		
1863	sqzqo	17	DFS goes deep as far as it can in one direction, before trying others.	2014-12-10 08:25:17		
1864	mrjku	17	@AngryAlgorist, that's true. But is there anything wrong with my code?	2014-12-10 08:25:17		
1865	sgiwy	17	I am not sure :( How can you guarantee that "step" is always the shortest path reachable from that guard? Can you explain it?	2014-12-10 08:25:17		
1866	mrjku	17	Well, you can think this as some kind of paint-fill algorithm.	2014-12-10 08:25:17		
1867	gilit	17	Paint fill is boolean filling of nodes...so dfs vs.bfs has same effect because u are just visiting all suitable nodes.  This is shortest distance filling... So dfs usually does not work.	2014-12-10 08:25:17		
1868	rrmeu	17	Well, you can write some test cases to see if this works,LOL	2014-12-10 08:25:17		
1869	ufdxg	17	@Mem, took a closer look, and I see what you are doing here. You are repeatedly trying all paths, even if they reuse the same spots, so long as going through the spot is cheaper than any previous path through that spot.  Cool idea!  The idea should work but it worst case complexity should be large.	2014-12-10 08:25:17		
1870	eucmc	17	BFS from every guard. However: once you reach node whose distance from guard you do not improve, ignore it. If the matrix has N cells and G guards the complexity is O(NG);	2014-12-10 08:25:17		
1871	jippy	17		2014-12-10 08:25:17		
1872	xhgls	17		2014-12-10 08:25:17		
1873	fowai	17	bfs...	2014-12-10 08:25:17		
1874	ftfck	17	Yes, bfs. But interviewer said there is an optimal solution with O(n^2), which I haven't figured out. :(	2014-12-10 08:25:17		
1875	mrjku	17	I think we can use bfs twice to solve this problem, from node (0,0) to (n,n), then reverse from (n,n) to (0,0)	2014-12-10 08:25:17		
1876	plapd	17	bfs... initiate the queue with all "G" cells.	2014-12-10 08:25:17		
1877	cfzie	17	Could there be anything possibly wrong with using BFS and putting G nodes into the priority queue?	2014-12-10 08:25:17		
1878	jippy	17	Here's another approach, Find the coordinate of the G nodes. For each node, find the Manhattan distance between the Coordinates and the G nodes, assign the value as the smallest manhattan distance. This takes O(n^3) though. The BFS technique with all G nodes in the Priority queue should be the fastest (as someone else suggested)	2014-12-10 08:25:17		
1879	tenuw	17		2014-12-10 08:25:17		
1880	gilit	17		2014-12-10 08:25:18		
1881	ethan	17	time o(n) space o(n), get all the guard nodes to a min-heap and expand them to adjacent nodes, keep adding them to the min-heap if reachable. assuming obstacle is -2, guard is -1 for easy processing.	2014-12-10 08:25:18		
1882	tenuw	17		2014-12-10 08:25:18		
1883	xhgls	17		2014-12-10 08:25:18		
1884	dgjji	17		2014-12-10 08:25:18		
1885	ewigy	17		2014-12-10 08:25:18		
1886	tenuw	17	public void setMatrix(char[][] matrix) { for (int i=0; i<matrix.length; i++) { for(int j=0; j<matrix[0].length; j++) { if (matrix[i][j] != 'B' && matrix[i][j] != 'G' && matrix[i][j] != '0') continue; matrix[i][j] = findDistanceToGuardFrom(matrix, new Point(i, j)); } } }  private int findDistanceToGuardFrom(int[][] matrix, Point n) { if (isGuard(n)) { return 0; } int result; for (Point ns : getNeighbors(matrix, n)) { result = 1 + findDistanceToGuardFrom(matrix, ns); if (matrix[n.x][n.y] == 0 || result < matrix[n.x][n.y]) { matrix[n.x][n.y] = result; } } return result; }	2014-12-10 08:25:18		
1887	xhgls	17	Time Complexity O( n^2 log(n) )..... I have check for various test cases it gives perfect answer. input matrix will be like:	2014-12-10 08:25:18		
1888	cfzie	17		2014-12-10 08:25:18		
1889	xhgls	17		2014-12-10 08:25:18		
1890	eucmc	17	where 2 means Guard and 1 mean blocked or obstacle distance matrix is the output matrix, in which Max value means cant reach, 0 means, you are a guard otherwise other numeric values.  We keep checking whether the distance of any u, u_c has changed, if yes then we re-compute the distance matrix.	2014-12-10 08:25:18		
1891	nwkeg	17		2014-12-10 08:25:18		
1892	cfzie	17		2014-12-10 08:25:18		
1893	zeice	17	Find the all the guards first, populate all the surrounding empty rooms at distance 1, keep track of these rooms. 1.Find the G cells 2.Update the distance of surrounding cells found in step 1 to 1, use a list to keep track these cells been updated 3.Distance+1, repeat step 2, if the cell's distance is already there, that's definitely the shortest distance, skip this cell  public static int[][] nearestGuard(char[][] input) { int[][] result = new int[input.length][input[0].length]; ArrayList<int[]> current = new ArrayList<int[]>(); for (int i = 0; i < input.length; i++) { for (int j = 0; j < input[0].length; j++) { if (input[i][j] == 'G') current.add(new int[] { i, j }); } } int distance = 1; while (!current.isEmpty()) { ArrayList<int[]> next = new ArrayList<int[]>(); for (int[] c : current) { guradHelper(input, c[0] + 1, c[1], distance, result, next); guradHelper(input, c[0] - 1, c[1], distance, result, next); guradHelper(input, c[0], c[1] + 1, distance, result, next); guradHelper(input, c[0], c[1] - 1, distance, result, next); } current = next; distance++; } return result; }  public static void guradHelper(char[][] input, int i, int j, int distance, int[][] result, ArrayList<int[]> next) { if (i < 0 || j < 0 || i >= input.length || j >= input[0].length || input[i][j] == 'G' || input[i][j] == 'B' || result[i][j] != 0) return; result[i][j] = distance; next.add(new int[] { i, j }); }	2014-12-10 08:25:18		
1894	dgjji	17	Dijkstra's algorithm should be better. And it has O(n^2) complexity.	2014-12-10 08:25:18		
1895	sqzqo	17	Dijkstra's is not needed as this is a "every move/edge is 1 unit of weight" problem.	2014-12-10 08:25:18		
1896	ftfck	17	What about find shortest path from all guards? Just put them into one queue initially.	2014-12-10 08:25:18		
1897	rdfeo	17	Could you please elaborate a bit more. Interviewer does mention to start from G, and then bfs from there. but I've run out of time by then. Thanks	2014-12-10 08:25:18		
1898	nwkeg	17	This is what I thought, start from every G, go 4 direction, if we find current cell is B or another G we return, or if it is a number that smaller than the step we have from Current G, we also return other wise add 1 to current step and put it into current cell. Do the same recursion for current cell until no move can made. Do the same process for all G.	2014-12-10 08:25:18		
1899	ufdxg	17	@Mem, recursion would go deep in one direction before trying others (i.e., DFS).	2014-12-10 08:25:18		
1900	rrmeu	17	@AngryAlgorist. Yes, I admit that, but it is not possible here?	2014-12-10 08:25:18		
1901	gilit	17	What I actually have meant is to run breadth first search from all guards.	2014-12-10 08:25:18		
1902	rrmeu	17		2014-12-10 08:25:18		
1903	ewigy	17		2014-12-10 08:25:18		
1904	sqzqo	17	}	2014-12-10 08:25:18		
1905	gilit	17	Could the person who down vote the answer care to explain ?	2014-12-10 08:25:18		
1906	sqzqo	17	Could the person who wrote the answer, care to explain what the frack he is trying to do, first?	2014-12-10 08:25:18		
1907	ethan	17	Mr. frack,  The code uses dynamic programming to find the minimum distance to the nearest guards. For example: Consider 3 points A, B, C  Distance: B to C = 3 (shortest distance) Distance: A to B = 2 (shortest distance) Distance: A to C = ?  Option 1: find shortest distance from A to C by traveling from A to C Option 2: Add shortest distance from A to B and shortest distance from B to C.  Above code uses Option 2.  Next time you down vote an answer, have a better reason than being lazy. Also please provide a test case that fails.  if you are at point A and you want to goto point C, and you re	2014-12-10 08:25:18		
1908	krxlv	17	I have hard coded the dimension as 3. -1 will represent block, -2 will represent guard.	2014-12-10 08:25:18		
1909	huiqq	17		2014-12-10 08:25:18		
1910	bjsiw	17		2014-12-10 08:25:18		
1911	wbqzu	17	if you are posting actual compilable code , then why is your only comment "param args" ?????	2014-12-10 08:25:18		
1912	nwkeg	18	In this problem the rates at which glasses get filled in are rational numbers, whose numerators form the binomial coefficients and denominators are powers of 2 - specifically 2 raised to the power of level at which glasses are present.  A litre of water (overflowed from previous level) gets distributed among the glasses at each level as follows:	2014-12-10 08:25:22		
1913	xhgls	18		2014-12-10 08:25:22		
1914	zeice	18		2014-12-10 08:25:22		
1915	fmzze	18	The above distribution pattern provides with a partial progress towards the actual algorithm that finds the amount of water in jth glass of ith row. The algorithm gets tricky because all the glasses at a level might not be completely filled yet, before water starts getting filled up in levels below (albeit, in an inverted triangle fashion).  ---------------------------------------------------------------------------- The above observation apart, a DP-like algorithm below(that remembers quantities in glasses of the previous row) to find out the amount of water in jth jug of ith row can solve the problem.  0. For each glass, maintain 2 variables - the amount of water it holds and the amount of water it overflows. 1. For a glass at index i in the given row, look up two glasses in the previous row at index i-1 & i. (Boundary cases of indices need to be checked though) 2. The inflow into the current glass = half of outflow of glass in the previous row at i-1 + half of outflow of glass in the previous row at index i 3. Based on the inflow, volume held in the current glass = min(1, inflow) and the overflow at the current glass = inflow - volume held by the current glass 4. Repeat steps 1 to 3 until we reach the required glass.  An implementation in java goes like the below:	2014-12-10 08:25:22		
1916	dgjji	18		2014-12-10 08:25:22		
1917	fmzze	18		2014-12-10 08:25:22		
1918	ftfck	18	"glass 5 will get water from both 2nd glass and 3rd glass"  level 0: 1 level 1: 1/2 1/2 level 2: 1/4 2/4 1/4 level 3: 1/6 2/6 2/6 1/6 level 4: 1/8 2/8 2/8 2/8 1/8	2014-12-10 08:25:22		
1919	admin	18	The denominator should be 2*level not level^2, what happens when there's 7 liters and you want glass 8?	2014-12-10 08:25:22		
1920	fmzze	18	@camelcase  While a solution for this problem is explored, there are several ways to look at this problem. My posting describes "the *rate* at which a particular glass(based on its position in the row) gets filled when a liter of water gets overflowed from all of the glasses above."  However, if only a few of the glasses in a row are overflowing at a given time, the above mentioned distribution pattern will not hold for a row beneath it.  Finally, the actual implementation of an algorithm to solve the problem has a different approach altogether than a mathematical way of looking at the problem.  About your argument, on what basis are you saying that denominator should be 2*level.Give reasons.	2014-12-10 08:25:22		
1921	ufdxg	18	I believe the problem was not correctly interpreted: a glass can only fill the one below it *if* it is full! Therefore it can never happens some glass 5 is non-empty while glass 2 and 3 are only half filled.	2014-12-10 08:25:22		
1922	jippy	18	@ Chih.Chiu.19  You are not quite correct. You haven't completely understood my statements. For the above configuration, work out what happens when the volume of water X = 5 & 6 and look at glass numbers 4, 5, 6 & 7, 8, 9, 10  At 5 liters you will see the following configuration, where the numbers in brackets denote the volume held.  At X= 5 4(1/2) 5(1) 6(1/2) 7(0) 8(0) 9(0) 10(0)  At X=6 4(3/4) 5(1) 6(3/4) 7(0) 8(1/4) 9(1/4) 10(0)  Do you now see that glass numbers 4 & 6 are not completely filled, yet glass numbers 8 & 9 get some volume inflow into them? That is what I mean when I say the all the glasses in the current row might not be completely filled, yet some glasses from lower row starts getting filled up.	2014-12-10 08:25:22		
1923	zeice	18	@Ayahuasca Ok I see what you did now. You are right :) I was just confused by your "flow chart" table at the beginning, since for no situations will we have a configurations like that. Anyway, I see now that your solution is correct, thanks.	2014-12-10 08:25:22		
1924	dgjji	18	C# Code	2014-12-10 08:25:22		
1925	ewigy	18		2014-12-10 08:25:22		
1926	tenuw	18		2014-12-10 08:25:22		
1927	sqzqo	18		2014-12-10 08:25:23		
1928	krxlv	18		2014-12-10 08:25:23		
1929	cfzie	18	A little modified version with 2D array	2014-12-10 08:25:23		
1930	nwkeg	18		2014-12-10 08:25:23		
1931	rdfeo	18		2014-12-10 08:25:23		
1932	bexbp	18	#include<stdio.h>  void main(){ int noOfLiters = 0; int n = 0; //number of rows to print int j = 0; int i = 0; int presentRow = 0; int nextRow = 0; float boundary = 0; float middle = 0; float temp = 0;  printf("Enter the value of noOfLiters\n"); scanf("%d",&noOfLiters); printf("how many rows\n"); scanf("%d",&n);  i = 0; //row on which water is poured is taken as i =0 or zeroth row while(i<n){ presentRow = i*(i+1)/2; nextRow = (i+1)*(i+2)/2; if(presentRow < noOfLiters && nextRow <= noOfLiters){ printf("row %d has 1 liter\n",i); }  else if(presentRow > noOfLiters){ printf("row %d has no water \n",i); } else{ temp = noOfLiters; for(j = 0;j<i;j++){ temp = (temp-1)/2; } boundary = temp;  middle = noOfLiters - i*(i+1)/2 - 2*boundary; middle = middle/(i-1); printf("row %d has %f liters on boundary columns and %f liters in middle columns\n",i,boundary,middle); } i++; } }	2014-12-10 08:25:23		
1933	dkebi	18	#include<iostream> int main() { int glass,ltr,rows=1; std::cout<<"INPUT:\nNo of glasses\namt of water\n"; std::cin>>glass>>ltr; while(glass>0) { glass=glass-rows; rows++; } rows--; std::cout<<"\n\tRows: "<<rows<<"\t"<<ltr<<"\n"; float arr[rows][rows];  for(int i=0;i<rows;i++) { for(int k=4-i;k>0;k--) { std::cout<<"\t"; } for(int j=0;j<=i;j++) {  arr[i][j]=0; std::cout<<arr[i][j]<<"\t"; } std::cout<<"\n"; } arr[0][0]=ltr; std::cout<<"1 : "<<arr[0][0]; for(int i=0;i<rows;i++) { for(int j=0;j<=i;j++) { std::cout<<"."<<i<<j; if(arr[i][j]>1) { arr[i+1][j]=arr[i+1][j]+(arr[i][j]-1)/2; arr[i+1][j+1]=arr[i+1][j+1]+(arr[i][j]-1)/2; arr[i][j]=1; }  } }  std::cout<<"\n"; for(int i=0;i<rows;i++) { for(int k=4-i;k>0;k--) { std::cout<<"\t"; } for(int j=0;j<=i;j++) {  std::cout<<arr[i][j]<<"\t"; } std::cout<<"\n"; } return 0;  }	2014-12-10 08:25:23		
1934	plapd	18	#include "stdafx.h" #include "stdlib.h" void find(int i, int j, int water) { int x,y; float **jug; float remain; jug=(float**)calloc(i,sizeof(float *)); for (x=0;x<i;x++) { jug[x]=(float*)calloc(i,sizeof(float));  }  jug[0][0]=(float)water; for (x=0;x<i;x++) { for(y=0;y<=x;y++) { if (jug[x][y]>1) { remain=jug[x][y]-1; jug[x][y]=1; remain/=2; if ((x+1+1)<=i) { jug[x+1][y]+=remain; jug[x+1][y+1]+=remain; } }   } }   for(x=0;x<i;x++) { printf("\n"); for(y=0;y<i;y++) { printf("\t %f",jug[x][y]); } } printf("ith jth jug value=%f",jug[i-1][y-1]);  }  int main(int argc, _TCHAR* argv[]) {  int i,j; int water; printf ("Enter ith "); scanf("%d",&i); printf ("Enter jth value"); scanf("%d",&j); if (j>i) { printf ("values are not correctly entered (i>=j)"); return -1; } printf ("Enter the amount of water"); scanf("%d",&water);  find(i,j,water);  return 0; }	2014-12-10 08:25:23		
1935	ufdxg	18	Isn't it related to Pascal's triangle?	2014-12-10 08:25:23		
1936	zeice	18	This is an interesting problem, but it can be resolved with just math.  The total amount of water to completely fill the glasses up to the nth row is:  f(n) = n * (n + 1) / 2  The number of glasses in the ith row is really simple:  c(i) = i  Assuming the glass isn't completely full, the total water for a glass in the ith row is:  g(i) = (X - f(i - 1)) / c(i)  I'm going to be lazy and not reduce, but the only missing piece is including a stepwise function for X - f(i - 1) as well as g(i) because a glass can't be less than empty or greater than full. In pseudocode:  g(i) = min(1, (max(0, X - f(i - 1)) / c(i))	2014-12-10 08:25:23		
1937	krxlv	18	#include<stdio.h> #include<stdlib.h>  float min(float a, float b) { return a<b?a:b; } float winePour(int start, int dest, float qty,int k) {  float a=0,b=0; if(start > dest || qty < 0) return 0; if(start == dest) { printf("Start == destination \n"); return min(1,qty); }   qty=qty-1; printf("%d %d %f\n",start+k,dest,qty/2); a+=winePour(start+k,dest,qty/2,k+1); printf("%d %d %f\n",start+k+1,dest,qty/2); b+=winePour(start+k+1,dest,qty/2,k+1);  return min(1,a+b); } int main() { int glass=5; float qty=3.5; float x=0.0; x=winePour(1,glass,qty,1); printf("%f \n",x); return 0; }	2014-12-10 08:25:23		
1938	tenuw	18	Here is the code in c++	2014-12-10 08:25:23		
1939	sgiwy	18		2014-12-10 08:25:23		
1940	zeice	18		2014-12-10 08:25:23		
1941	mrjku	18	public String findwater(int n ,int i, int j) { int temp =i*(i+1)/2; int left = n -temp; if(left > 0) { if((2(i-1) ) > left) return ""+1; else { float a=left/2(i-1) if(j==1 || j ==i) return ""+float/2; else return ""+float; } }  }	2014-12-10 08:25:23		
1942	ewigy	18	public String findwater(int n ,int i, int j) { int temp =i*(i+1)/2; int left = n -temp; if(left > 0) { if((2(i-1) ) > left) return ""+1; else { float a=left/2(i-1) if(j==1 || j ==i) return ""+float/2; else return ""+float; } } }	2014-12-10 08:25:23		
1943	dkebi	18	The problem is similar to pascal triangle. Only a little modification required for boundary conditions.	2014-12-10 08:25:23		
1944	mrjku	18		2014-12-10 08:25:23		
1945	dkebi	18		2014-12-10 08:25:23		
1946	plapd	18		2014-12-10 08:25:23		
1947	jippy	18		2014-12-10 08:25:23		
1948	fowai	18	I think this check is wrong x > totalGlassesUptoPreviousLevel . May be u have assumed that water reaches the next level only after the current level is full, which is wrong.	2014-12-10 08:25:23		
1949	xhgls	18	I think it's just a dynamic programming. My code is as follows: #include <iostream> #include <string.h> using namespace std; #define GLASSES_NUM 100 #define TO_INDEX(i, j) (0.5 * (i) * (i - 1) + (j))  double f[GLASSES_NUM]; int water; double calculate(int i, int j) { int index = TO_INDEX(i, j); if (f[index] - 0.0 > 1.0e-6) { return f[index]; } else { if (i == 1 && j == 1) { f[index] = water; return f[index]; } else { double m1 = 0.0, m2 = 0.0; if ( j >= 2) { double temp = calculate(i-1, j-1); m1 = temp > 1 ? (temp - 1) : 0; } if (j <= 0.5 * i * (i -1)) { double temp = calculate(i-1, j); m2 = temp > 1 ? (temp - 1) : 0; } f[index] = 0.5 * (m1 + m2); return f[index]; } } } int main() { int i, j; memset(f, 0.0, sizeof f); cout << "Input the total water(L):" << endl; cin >> water; while(1) { cout << "Which glass do you want to know?" << endl; cout << "i = "; cin >> i; cout << "j = "; cin >> j; if (j > i) { cout << "j must not be bigger than i" << endl; continue; } double result = calculate(i, j); cout << "answer is " << (result > 1 ? 1 : result) << endl; } return 1; }	2014-12-10 08:25:23		
1950	mrjku	18	#include<stdio.h> void main() { float r,c,n; scanf("%f%f%f",&r,&c,&n); if(((r-1)*(r/2))>=n) printf("0"); else if(r*((r+1)/2)==n) printf("1"); else printf("%f",(float)((n-((r-1)*(r)/2))/r)); }	2014-12-10 08:25:23		
1951	huiqq	18	#include<stdio.h> void main() { float r,c,n; printf(" enter row no and col no and total water") scanf("%f%f%f",&r,&c,&n); if(((r-1)*(r/2))>=n) printf("total amt of water is 0"); else if(r*((r+1)/2)==n) printf("total amt of water is 1"); else printf("total amt of water is %f",(float)((n-((r-1)*(r)/2))/r)); }	2014-12-10 08:25:23		
1952	ufdxg	18	Very similar idea, more OO way of implementation,  each Glass class is responsible for maintaining obtained water and how much overflow/spillover is from this glass.  Parent glass will just pour water to its children.	2014-12-10 08:25:23		
1953	huiqq	18		2014-12-10 08:25:23		
1954	jippy	18		2014-12-10 08:25:23		
1955	dkebi	18		2014-12-10 08:25:23		
1956	nhibd	18		2014-12-10 08:25:23		
1957	dkebi	18		2014-12-10 08:25:23		
1958	mrjku	18		2014-12-10 08:25:23		
1959	bjsiw	18	Sorry, wrong code.Why? See Ayahuasca answer above. =(	2014-12-10 08:25:23		
1960	admin	18	TL;DR; so lets see how the water flows down evel 0: 1 level 1: 1/2 1/2 level 2: 1/4 2/4 1/4 level 3: 1/6 2/6 2/6 1/6 level 4: 1/8 2/8 2/8 2/8 1/8 and so on.  So by analysing the above data a simple formula can be designed for the 2 different cases that we will have Case 1. if the glass is the outer most, either on left or on right. Case 2. if the glass is as inner glass.  For case 1 the formula will be: Amount of water in Glass(Y) = (X - (1+2+i-1)) / (2 * (i-1)) where i is the row and X is the total amount of water being poured.  And for case 2 just multiply the value of case 1(Y) by 2. and we have our desired output.	2014-12-10 08:25:23		
1961	mrjku	18	If x=6, i=4 and j=2, your solution gives 0 as output and correct answer is 0.25 (first litre fills (1,1) glass, next two fills (2,1) and (2,2) glasses, next two liters distributed between (3,1), (3,2) and (3,3) glasses as 0.5, 1.0 and 0.5, so glass (3,2) is filled. Now we put last liter, that distributes as 0.25, 0.25, 0.25, 0.25 between (3,1), (4,2), (4,3) and (3,3))	2014-12-10 08:25:23		
1962	admin	18	The numerator should be the value in pascal's triangle.	2014-12-10 08:25:23		
1963	tenuw	18	Yes, here the rate at which the glasses are filled has also to taken into consideration. I strongly think this can be taken care by a formula, rather hen some complex code.	2014-12-10 08:25:23		
1964	qywrh	18		2014-12-10 08:25:23		
1965	sgiwy	18		2014-12-10 08:25:23		
1966	azmjc	18		2014-12-10 08:25:23		
1967	jippy	18		2014-12-10 08:25:24		
1968	dgjji	18	The approach seems right but there are many issues in your code	2014-12-10 08:25:24		
1969	dgjji	18	bu kadar basit gencler dagln	2014-12-10 08:25:24		
1970	eucmc	18		2014-12-10 08:25:24		
1971	fmzze	18		2014-12-10 08:25:24		
1972	fowai	18		2014-12-10 08:25:24		
1973	qywrh	18		2014-12-10 08:25:24		
1974	dgjji	18		2014-12-10 08:25:24		
1975	ufdxg	18	Well sorry my bad.Haven't read the question properly.	2014-12-10 08:25:24		
1976	sgiwy	19	Don't know why your question got voted down- this is a reasonable design question to be asked during an interview. You sir get a +1.	2014-12-10 08:25:26		
